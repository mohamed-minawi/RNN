{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from numpy import newaxis\n",
    "from keras import losses\n",
    "from tensorflow import set_random_seed\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import keras\n",
    "import math\n",
    "\n",
    "random.seed(7)\n",
    "np.random.seed(7)\n",
    "set_random_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importData(path):\n",
    "    data = []\n",
    "    with open(path, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if 'S&P 500' not in row:\n",
    "                data.append(float(row[1]))\n",
    "    return data\n",
    "\n",
    "def new_dataset(dataset, step_size):\n",
    "    data_X, data_Y = [], []\n",
    "    for i in range(len(dataset)-step_size-1):\n",
    "        a = dataset[i:(i+step_size), 0]\n",
    "        data_X.append(a)\n",
    "        data_Y.append(dataset[i + step_size, 0])\n",
    "    return np.array(data_X), np.array(data_Y)\n",
    "\n",
    "def preprocessData(sc, data, sequence):\n",
    "    data = np.array(data).reshape(-1, 1)\n",
    "    data = sc.fit_transform(data)\n",
    "\n",
    "    train_size = int(len(data) * 0.8)\n",
    "    test_size = len(data) - train_size\n",
    "    train = data[0:train_size,:]\n",
    "    test = data[train_size:len(data),:]  \n",
    "\n",
    "    X_train, y_train = new_dataset(train, sequence)\n",
    "    X_test, y_test = new_dataset(test, sequence)\n",
    "    \n",
    "    X_train = np.asarray(np.reshape(X_train, (X_train.shape[0], sequence, 1)))\n",
    "    X_test = np.asarray(np.reshape(X_test, (X_test.shape[0], sequence, 1)))\n",
    "    \n",
    "    return X_train, y_train , X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = importData(\"data10.csv\")\n",
    "sequence = 10\n",
    "\n",
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "X_train4, y_train4, X_test4, y_test4 = preprocessData(sc, data4, sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(LSTM(32,input_shape=(sequence,1),return_sequences = True))\n",
    "model4.add(LSTM(16))\n",
    "model4.add(Dense(1))\n",
    "model4.add(Activation('linear'))\n",
    "model4.compile(optimizer = \"adam\", loss = 'mean_squared_error')\n",
    "\n",
    "checkpoint4 = ModelCheckpoint(\"Test3216-B10-LB10-D03.hdf5\", monitor='loss', verbose=1, save_best_only=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1680/2011 [========================>.....] - ETA: 1s - loss: 0.0056"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-823f0e9b073b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history4 = model4.fit(X_train4, y_train4, epochs=10, batch_size=10,verbose=1, callbacks=[checkpoint4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0081\n",
      "\n",
      "Epoch 00001: loss did not improve\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0081\n",
      "\n",
      "Epoch 00002: loss did not improve\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0082\n",
      "\n",
      "Epoch 00003: loss did not improve\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0079\n",
      "\n",
      "Epoch 00004: loss did not improve\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0082\n",
      "\n",
      "Epoch 00005: loss did not improve\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0078\n",
      "\n",
      "Epoch 00006: loss did not improve\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0090\n",
      "\n",
      "Epoch 00007: loss did not improve\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0086\n",
      "\n",
      "Epoch 00008: loss did not improve\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0078\n",
      "\n",
      "Epoch 00009: loss did not improve\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0076\n",
      "\n",
      "Epoch 00010: loss improved from 0.00767 to 0.00764, saving model to Test3216-B10-LB10-D03.hdf5\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.0078\n",
      "\n",
      "Epoch 00011: loss did not improve\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0075\n",
      "\n",
      "Epoch 00012: loss improved from 0.00764 to 0.00748, saving model to Test3216-B10-LB10-D03.hdf5\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0077\n",
      "\n",
      "Epoch 00013: loss did not improve\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0080\n",
      "\n",
      "Epoch 00014: loss did not improve\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0074\n",
      "\n",
      "Epoch 00015: loss improved from 0.00748 to 0.00745, saving model to Test3216-B10-LB10-D03.hdf5\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0090\n",
      "\n",
      "Epoch 00016: loss did not improve\n",
      "Epoch 17/200\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.0068\n",
      "\n",
      "Epoch 00017: loss improved from 0.00745 to 0.00681, saving model to Test3216-B10-LB10-D03.hdf5\n",
      "Epoch 18/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0087\n",
      "\n",
      "Epoch 00018: loss did not improve\n",
      "Epoch 19/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0077\n",
      "\n",
      "Epoch 00019: loss did not improve\n",
      "Epoch 20/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0075\n",
      "\n",
      "Epoch 00020: loss did not improve\n",
      "Epoch 21/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0074\n",
      "\n",
      "Epoch 00021: loss did not improve\n",
      "Epoch 22/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0072\n",
      "\n",
      "Epoch 00022: loss did not improve\n",
      "Epoch 23/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0075\n",
      "\n",
      "Epoch 00023: loss did not improve\n",
      "Epoch 24/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0073\n",
      "\n",
      "Epoch 00024: loss did not improve\n",
      "Epoch 25/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0077\n",
      "\n",
      "Epoch 00025: loss did not improve\n",
      "Epoch 26/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0080\n",
      "\n",
      "Epoch 00026: loss did not improve\n",
      "Epoch 27/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0083\n",
      "\n",
      "Epoch 00027: loss did not improve\n",
      "Epoch 28/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0087\n",
      "\n",
      "Epoch 00028: loss did not improve\n",
      "Epoch 29/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0087\n",
      "\n",
      "Epoch 00029: loss did not improve\n",
      "Epoch 30/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0078\n",
      "\n",
      "Epoch 00030: loss did not improve\n",
      "Epoch 31/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0074\n",
      "\n",
      "Epoch 00031: loss did not improve\n",
      "Epoch 32/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0075\n",
      "\n",
      "Epoch 00032: loss did not improve\n",
      "Epoch 33/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0074\n",
      "\n",
      "Epoch 00033: loss did not improve\n",
      "Epoch 34/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0072\n",
      "\n",
      "Epoch 00034: loss did not improve\n",
      "Epoch 35/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0097\n",
      "\n",
      "Epoch 00035: loss did not improve\n",
      "Epoch 36/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0085\n",
      "\n",
      "Epoch 00036: loss did not improve\n",
      "Epoch 37/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0084\n",
      "\n",
      "Epoch 00037: loss did not improve\n",
      "Epoch 38/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0095\n",
      "\n",
      "Epoch 00038: loss did not improve\n",
      "Epoch 39/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0076\n",
      "\n",
      "Epoch 00039: loss did not improve\n",
      "Epoch 40/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0080\n",
      "\n",
      "Epoch 00040: loss did not improve\n",
      "Epoch 41/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0074\n",
      "\n",
      "Epoch 00041: loss did not improve\n",
      "Epoch 42/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0071\n",
      "\n",
      "Epoch 00042: loss did not improve\n",
      "Epoch 43/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0071\n",
      "\n",
      "Epoch 00043: loss did not improve\n",
      "Epoch 44/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0070\n",
      "\n",
      "Epoch 00044: loss did not improve\n",
      "Epoch 45/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0071\n",
      "\n",
      "Epoch 00045: loss did not improve\n",
      "Epoch 46/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0069\n",
      "\n",
      "Epoch 00046: loss did not improve\n",
      "Epoch 47/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0071\n",
      "\n",
      "Epoch 00047: loss did not improve\n",
      "Epoch 48/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0072\n",
      "\n",
      "Epoch 00048: loss did not improve\n",
      "Epoch 49/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0079\n",
      "\n",
      "Epoch 00049: loss did not improve\n",
      "Epoch 50/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0083\n",
      "\n",
      "Epoch 00050: loss did not improve\n",
      "Epoch 51/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0086\n",
      "\n",
      "Epoch 00051: loss did not improve\n",
      "Epoch 52/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0080\n",
      "\n",
      "Epoch 00052: loss did not improve\n",
      "Epoch 53/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0082\n",
      "\n",
      "Epoch 00053: loss did not improve\n",
      "Epoch 54/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0095\n",
      "\n",
      "Epoch 00054: loss did not improve\n",
      "Epoch 55/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0082\n",
      "\n",
      "Epoch 00055: loss did not improve\n",
      "Epoch 56/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0094\n",
      "\n",
      "Epoch 00056: loss did not improve\n",
      "Epoch 57/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0076\n",
      "\n",
      "Epoch 00057: loss did not improve\n",
      "Epoch 58/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0075\n",
      "\n",
      "Epoch 00058: loss did not improve\n",
      "Epoch 59/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0074\n",
      "\n",
      "Epoch 00059: loss did not improve\n",
      "Epoch 60/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0069\n",
      "\n",
      "Epoch 00060: loss did not improve\n",
      "Epoch 61/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0069\n",
      "\n",
      "Epoch 00061: loss did not improve\n",
      "Epoch 62/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0069\n",
      "\n",
      "Epoch 00062: loss did not improve\n",
      "Epoch 63/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0069\n",
      "\n",
      "Epoch 00063: loss did not improve\n",
      "Epoch 64/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0068\n",
      "\n",
      "Epoch 00064: loss improved from 0.00681 to 0.00680, saving model to Test3216-B10-LB10-D03.hdf5\n",
      "Epoch 65/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0067\n",
      "\n",
      "Epoch 00065: loss improved from 0.00680 to 0.00670, saving model to Test3216-B10-LB10-D03.hdf5\n",
      "Epoch 66/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0068\n",
      "\n",
      "Epoch 00066: loss did not improve\n",
      "Epoch 67/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0067\n",
      "\n",
      "Epoch 00067: loss improved from 0.00670 to 0.00670, saving model to Test3216-B10-LB10-D03.hdf5\n",
      "Epoch 68/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 7ms/step - loss: 0.0066\n",
      "\n",
      "Epoch 00068: loss improved from 0.00670 to 0.00663, saving model to Test3216-B10-LB10-D03.hdf5\n",
      "Epoch 69/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0072\n",
      "\n",
      "Epoch 00069: loss did not improve\n",
      "Epoch 70/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0073\n",
      "\n",
      "Epoch 00070: loss did not improve\n",
      "Epoch 71/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0067\n",
      "\n",
      "Epoch 00071: loss did not improve\n",
      "Epoch 72/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0093\n",
      "\n",
      "Epoch 00072: loss did not improve\n",
      "Epoch 73/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0071\n",
      "\n",
      "Epoch 00073: loss did not improve\n",
      "Epoch 74/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0071\n",
      "\n",
      "Epoch 00074: loss did not improve\n",
      "Epoch 75/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0076\n",
      "\n",
      "Epoch 00075: loss did not improve\n",
      "Epoch 76/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0087\n",
      "\n",
      "Epoch 00076: loss did not improve\n",
      "Epoch 77/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0082\n",
      "\n",
      "Epoch 00077: loss did not improve\n",
      "Epoch 78/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0072\n",
      "\n",
      "Epoch 00078: loss did not improve\n",
      "Epoch 79/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0071\n",
      "\n",
      "Epoch 00079: loss did not improve\n",
      "Epoch 80/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0072\n",
      "\n",
      "Epoch 00080: loss did not improve\n",
      "Epoch 81/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0072\n",
      "\n",
      "Epoch 00081: loss did not improve\n",
      "Epoch 82/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0073\n",
      "\n",
      "Epoch 00082: loss did not improve\n",
      "Epoch 83/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0078\n",
      "\n",
      "Epoch 00083: loss did not improve\n",
      "Epoch 84/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0069\n",
      "\n",
      "Epoch 00084: loss did not improve\n",
      "Epoch 85/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0085\n",
      "\n",
      "Epoch 00085: loss did not improve\n",
      "Epoch 86/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0066\n",
      "\n",
      "Epoch 00086: loss improved from 0.00663 to 0.00657, saving model to Test3216-B10-LB10-D03.hdf5\n",
      "Epoch 87/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0072\n",
      "\n",
      "Epoch 00087: loss did not improve\n",
      "Epoch 88/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0067\n",
      "\n",
      "Epoch 00088: loss did not improve\n",
      "Epoch 89/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0071\n",
      "\n",
      "Epoch 00089: loss did not improve\n",
      "Epoch 90/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0073\n",
      "\n",
      "Epoch 00090: loss did not improve\n",
      "Epoch 91/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0069\n",
      "\n",
      "Epoch 00091: loss did not improve\n",
      "Epoch 92/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0073\n",
      "\n",
      "Epoch 00092: loss did not improve\n",
      "Epoch 93/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0084\n",
      "\n",
      "Epoch 00093: loss did not improve\n",
      "Epoch 94/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0083\n",
      "\n",
      "Epoch 00094: loss did not improve\n",
      "Epoch 95/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0068\n",
      "\n",
      "Epoch 00095: loss did not improve\n",
      "Epoch 96/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0070\n",
      "\n",
      "Epoch 00096: loss did not improve\n",
      "Epoch 97/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0067\n",
      "\n",
      "Epoch 00097: loss did not improve\n",
      "Epoch 98/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0063\n",
      "\n",
      "Epoch 00098: loss improved from 0.00657 to 0.00635, saving model to Test3216-B10-LB10-D03.hdf5\n",
      "Epoch 99/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0066\n",
      "\n",
      "Epoch 00099: loss did not improve\n",
      "Epoch 100/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0076\n",
      "\n",
      "Epoch 00100: loss did not improve\n",
      "Epoch 101/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0073\n",
      "\n",
      "Epoch 00101: loss did not improve\n",
      "Epoch 102/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0067\n",
      "\n",
      "Epoch 00102: loss did not improve\n",
      "Epoch 103/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0070\n",
      "\n",
      "Epoch 00103: loss did not improve\n",
      "Epoch 104/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0072\n",
      "\n",
      "Epoch 00104: loss did not improve\n",
      "Epoch 105/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0089\n",
      "\n",
      "Epoch 00105: loss did not improve\n",
      "Epoch 106/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0078\n",
      "\n",
      "Epoch 00106: loss did not improve\n",
      "Epoch 107/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0068\n",
      "\n",
      "Epoch 00107: loss did not improve\n",
      "Epoch 108/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0069\n",
      "\n",
      "Epoch 00108: loss did not improve\n",
      "Epoch 109/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0073\n",
      "\n",
      "Epoch 00109: loss did not improve\n",
      "Epoch 110/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0074\n",
      "\n",
      "Epoch 00110: loss did not improve\n",
      "Epoch 111/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0067\n",
      "\n",
      "Epoch 00111: loss did not improve\n",
      "Epoch 112/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0072\n",
      "\n",
      "Epoch 00112: loss did not improve\n",
      "Epoch 113/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0069\n",
      "\n",
      "Epoch 00113: loss did not improve\n",
      "Epoch 114/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0064\n",
      "\n",
      "Epoch 00114: loss did not improve\n",
      "Epoch 115/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0072\n",
      "\n",
      "Epoch 00115: loss did not improve\n",
      "Epoch 116/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0074\n",
      "\n",
      "Epoch 00116: loss did not improve\n",
      "Epoch 117/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0075\n",
      "\n",
      "Epoch 00117: loss did not improve\n",
      "Epoch 118/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0076\n",
      "\n",
      "Epoch 00118: loss did not improve\n",
      "Epoch 119/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0073\n",
      "\n",
      "Epoch 00119: loss did not improve\n",
      "Epoch 120/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0064A: 0s - loss: 0.00\n",
      "\n",
      "Epoch 00120: loss did not improve\n",
      "Epoch 121/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0063\n",
      "\n",
      "Epoch 00121: loss improved from 0.00635 to 0.00630, saving model to Test3216-B10-LB10-D03.hdf5\n",
      "Epoch 122/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0066\n",
      "\n",
      "Epoch 00122: loss did not improve\n",
      "Epoch 123/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0068\n",
      "\n",
      "Epoch 00123: loss did not improve\n",
      "Epoch 124/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0065\n",
      "\n",
      "Epoch 00124: loss did not improve\n",
      "Epoch 125/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0067\n",
      "\n",
      "Epoch 00125: loss did not improve\n",
      "Epoch 126/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0069\n",
      "\n",
      "Epoch 00126: loss did not improve\n",
      "Epoch 127/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0070\n",
      "\n",
      "Epoch 00127: loss did not improve\n",
      "Epoch 128/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0080\n",
      "\n",
      "Epoch 00128: loss did not improve\n",
      "Epoch 129/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0064\n",
      "\n",
      "Epoch 00129: loss did not improve\n",
      "Epoch 130/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0072\n",
      "\n",
      "Epoch 00130: loss did not improve\n",
      "Epoch 131/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0069\n",
      "\n",
      "Epoch 00131: loss did not improve\n",
      "Epoch 132/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0069\n",
      "\n",
      "Epoch 00132: loss did not improve\n",
      "Epoch 133/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0071\n",
      "\n",
      "Epoch 00133: loss did not improve\n",
      "Epoch 134/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0069\n",
      "\n",
      "Epoch 00134: loss did not improve\n",
      "Epoch 135/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0081\n",
      "\n",
      "Epoch 00135: loss did not improve\n",
      "Epoch 136/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0068\n",
      "\n",
      "Epoch 00136: loss did not improve\n",
      "Epoch 137/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0069\n",
      "\n",
      "Epoch 00137: loss did not improve\n",
      "Epoch 138/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0065\n",
      "\n",
      "Epoch 00138: loss did not improve\n",
      "Epoch 139/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0064\n",
      "\n",
      "Epoch 00139: loss did not improve\n",
      "Epoch 140/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0061\n",
      "\n",
      "Epoch 00140: loss improved from 0.00630 to 0.00613, saving model to Test3216-B10-LB10-D03.hdf5\n",
      "Epoch 141/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0061\n",
      "\n",
      "Epoch 00141: loss improved from 0.00613 to 0.00611, saving model to Test3216-B10-LB10-D03.hdf5\n",
      "Epoch 142/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0061\n",
      "\n",
      "Epoch 00142: loss improved from 0.00611 to 0.00609, saving model to Test3216-B10-LB10-D03.hdf5\n",
      "Epoch 143/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0061\n",
      "\n",
      "Epoch 00143: loss improved from 0.00609 to 0.00606, saving model to Test3216-B10-LB10-D03.hdf5\n",
      "Epoch 144/200\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.0061\n",
      "\n",
      "Epoch 00144: loss did not improve\n",
      "Epoch 145/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0059\n",
      "\n",
      "Epoch 00145: loss improved from 0.00606 to 0.00594, saving model to Test3216-B10-LB10-D03.hdf5\n",
      "Epoch 146/200\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.0060\n",
      "\n",
      "Epoch 00146: loss did not improve\n",
      "Epoch 147/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0060\n",
      "\n",
      "Epoch 00147: loss did not improve\n",
      "Epoch 148/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0061\n",
      "\n",
      "Epoch 00148: loss did not improve\n",
      "Epoch 149/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0067\n",
      "\n",
      "Epoch 00149: loss did not improve\n",
      "Epoch 150/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0073\n",
      "\n",
      "Epoch 00150: loss did not improve\n",
      "Epoch 151/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0093\n",
      "\n",
      "Epoch 00151: loss did not improve\n",
      "Epoch 152/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0068\n",
      "\n",
      "Epoch 00152: loss did not improve\n",
      "Epoch 153/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0067\n",
      "\n",
      "Epoch 00153: loss did not improve\n",
      "Epoch 154/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0063\n",
      "\n",
      "Epoch 00154: loss did not improve\n",
      "Epoch 155/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0060\n",
      "\n",
      "Epoch 00155: loss did not improve\n",
      "Epoch 156/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0061\n",
      "\n",
      "Epoch 00156: loss did not improve\n",
      "Epoch 157/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0079\n",
      "\n",
      "Epoch 00157: loss did not improve\n",
      "Epoch 158/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0064\n",
      "\n",
      "Epoch 00158: loss did not improve\n",
      "Epoch 159/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0070\n",
      "\n",
      "Epoch 00159: loss did not improve\n",
      "Epoch 160/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0067\n",
      "\n",
      "Epoch 00160: loss did not improve\n",
      "Epoch 161/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0074\n",
      "\n",
      "Epoch 00161: loss did not improve\n",
      "Epoch 162/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0061\n",
      "\n",
      "Epoch 00162: loss did not improve\n",
      "Epoch 163/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0058\n",
      "\n",
      "Epoch 00163: loss improved from 0.00594 to 0.00585, saving model to Test3216-B10-LB10-D03.hdf5\n",
      "Epoch 164/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0061\n",
      "\n",
      "Epoch 00164: loss did not improve\n",
      "Epoch 165/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0061\n",
      "\n",
      "Epoch 00165: loss did not improve\n",
      "Epoch 166/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0062\n",
      "\n",
      "Epoch 00166: loss did not improve\n",
      "Epoch 167/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0070\n",
      "\n",
      "Epoch 00167: loss did not improve\n",
      "Epoch 168/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0066\n",
      "\n",
      "Epoch 00168: loss did not improve\n",
      "Epoch 169/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0064\n",
      "\n",
      "Epoch 00169: loss did not improve\n",
      "Epoch 170/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0060\n",
      "\n",
      "Epoch 00170: loss did not improve\n",
      "Epoch 171/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0066\n",
      "\n",
      "Epoch 00171: loss did not improve\n",
      "Epoch 172/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0061\n",
      "\n",
      "Epoch 00172: loss did not improve\n",
      "Epoch 173/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0062\n",
      "\n",
      "Epoch 00173: loss did not improve\n",
      "Epoch 174/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0062\n",
      "\n",
      "Epoch 00174: loss did not improve\n",
      "Epoch 175/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0059\n",
      "\n",
      "Epoch 00175: loss did not improve\n",
      "Epoch 176/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0058\n",
      "\n",
      "Epoch 00176: loss improved from 0.00585 to 0.00577, saving model to Test3216-B10-LB10-D03.hdf5\n",
      "Epoch 177/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0057\n",
      "\n",
      "Epoch 00177: loss improved from 0.00577 to 0.00574, saving model to Test3216-B10-LB10-D03.hdf5\n",
      "Epoch 178/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0059\n",
      "\n",
      "Epoch 00178: loss did not improve\n",
      "Epoch 179/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0058\n",
      "\n",
      "Epoch 00179: loss did not improve\n",
      "Epoch 180/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0058\n",
      "\n",
      "Epoch 00180: loss did not improve\n",
      "Epoch 181/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0057\n",
      "\n",
      "Epoch 00181: loss improved from 0.00574 to 0.00572, saving model to Test3216-B10-LB10-D03.hdf5\n",
      "Epoch 182/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0056\n",
      "\n",
      "Epoch 00182: loss improved from 0.00572 to 0.00563, saving model to Test3216-B10-LB10-D03.hdf5\n",
      "Epoch 183/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0058\n",
      "\n",
      "Epoch 00183: loss did not improve\n",
      "Epoch 184/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0062\n",
      "\n",
      "Epoch 00184: loss did not improve\n",
      "Epoch 185/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0068\n",
      "\n",
      "Epoch 00185: loss did not improve\n",
      "Epoch 186/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0062\n",
      "\n",
      "Epoch 00186: loss did not improve\n",
      "Epoch 187/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0062\n",
      "\n",
      "Epoch 00187: loss did not improve\n",
      "Epoch 188/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0061\n",
      "\n",
      "Epoch 00188: loss did not improve\n",
      "Epoch 189/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0059\n",
      "\n",
      "Epoch 00189: loss did not improve\n",
      "Epoch 190/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0064\n",
      "\n",
      "Epoch 00190: loss did not improve\n",
      "Epoch 191/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0061\n",
      "\n",
      "Epoch 00191: loss did not improve\n",
      "Epoch 192/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0057\n",
      "\n",
      "Epoch 00192: loss did not improve\n",
      "Epoch 193/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0059\n",
      "\n",
      "Epoch 00193: loss did not improve\n",
      "Epoch 194/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0058\n",
      "\n",
      "Epoch 00194: loss did not improve\n",
      "Epoch 195/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0059\n",
      "\n",
      "Epoch 00195: loss did not improve\n",
      "Epoch 196/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0059\n",
      "\n",
      "Epoch 00196: loss did not improve\n",
      "Epoch 197/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0056\n",
      "\n",
      "Epoch 00197: loss improved from 0.00563 to 0.00558, saving model to Test3216-B10-LB10-D03.hdf5\n",
      "Epoch 198/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0056\n",
      "\n",
      "Epoch 00198: loss improved from 0.00558 to 0.00558, saving model to Test3216-B10-LB10-D03.hdf5\n",
      "Epoch 199/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0071\n",
      "\n",
      "Epoch 00199: loss did not improve\n",
      "Epoch 200/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0064\n",
      "\n",
      "Epoch 00200: loss did not improve\n"
     ]
    }
   ],
   "source": [
    "history4 = model4.fit(X_train4, y_train4, epochs=200, batch_size=10,verbose=1, callbacks=[checkpoint4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: 22.68 RMSE\n",
      "Test Error: 19.40 RMSE\n",
      "----------------------------------------\n",
      "Train Accuracy: 77.32 RMSE\n",
      "Test Accuracy: 80.60 RMSE\n"
     ]
    }
   ],
   "source": [
    "trainPredict4 = model4.predict(X_train4)\n",
    "testPredict4 = model4.predict(X_test4)\n",
    "\n",
    "trainPredict4 = sc.inverse_transform(trainPredict4)\n",
    "trainY4 = sc.inverse_transform([y_train4])\n",
    "testPredict4 = sc.inverse_transform(testPredict4)\n",
    "testY4 = sc.inverse_transform([y_test4])\n",
    "\n",
    "trainError4 = math.sqrt(mean_squared_error(trainY4[0], trainPredict4[:,0]))\n",
    "testError4 = math.sqrt(mean_squared_error(testY4[0], testPredict4[:,0]))\n",
    "\n",
    "print('Train Error: %.2f RMSE' % (trainError4))\n",
    "print('Test Error: %.2f RMSE' % (testError4))\n",
    "print(\"----------------------------------------\")\n",
    "print('Train Accuracy: %.2f RMSE' % (100-trainError4))\n",
    "print('Test Accuracy: %.2f RMSE' % (100-testError4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testY4 = np.array(testY4).reshape(-1, 1)\n",
    "\n",
    "plt.plot(testPredict4, 'b', label = 'Predicted Price')\n",
    "plt.plot(testY4, 'r', label = 'Actual Price')\n",
    "plt.xlabel('Time in Days')\n",
    "plt.ylabel('Value of Stocks')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2673.165]]\n",
      "[[2671.92]]\n"
     ]
    }
   ],
   "source": [
    "print(testPredict4[-1:,:])\n",
    "print(testY4[-1:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(testPredict2[-5:,:])\n",
    "print(testY2[-1:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = importData(\"data10.csv\")\n",
    "sequence = 7\n",
    "\n",
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "X_train3, y_train3, X_test3, y_test3 = preprocessData(sc, data3, sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "2014/2014 [==============================] - 3s 2ms/step - loss: 0.1054\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.10540, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 2/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 0.0705\n",
      "\n",
      "Epoch 00002: loss improved from 0.10540 to 0.07047, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 3/2000\n",
      "2014/2014 [==============================] - 0s 36us/step - loss: 0.0407\n",
      "\n",
      "Epoch 00003: loss improved from 0.07047 to 0.04070, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 4/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 0.0191\n",
      "\n",
      "Epoch 00004: loss improved from 0.04070 to 0.01911, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 5/2000\n",
      "2014/2014 [==============================] - 0s 40us/step - loss: 0.0069\n",
      "\n",
      "Epoch 00005: loss improved from 0.01911 to 0.00688, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 6/2000\n",
      "2014/2014 [==============================] - 0s 41us/step - loss: 0.0036\n",
      "\n",
      "Epoch 00006: loss improved from 0.00688 to 0.00356, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 7/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 0.0055\n",
      "\n",
      "Epoch 00007: loss did not improve\n",
      "Epoch 8/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 0.0067\n",
      "\n",
      "Epoch 00008: loss did not improve\n",
      "Epoch 9/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 0.0051\n",
      "\n",
      "Epoch 00009: loss did not improve\n",
      "Epoch 10/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 0.0032\n",
      "\n",
      "Epoch 00010: loss improved from 0.00356 to 0.00322, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 11/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 0.0024\n",
      "\n",
      "Epoch 00011: loss improved from 0.00322 to 0.00237, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 12/2000\n",
      "2014/2014 [==============================] - 0s 38us/step - loss: 0.0023\n",
      "\n",
      "Epoch 00012: loss improved from 0.00237 to 0.00235, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 13/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 0.0024\n",
      "\n",
      "Epoch 00013: loss did not improve\n",
      "Epoch 14/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 0.0021\n",
      "\n",
      "Epoch 00014: loss improved from 0.00235 to 0.00211, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 15/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 0.0017\n",
      "\n",
      "Epoch 00015: loss improved from 0.00211 to 0.00171, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 16/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 0.0014\n",
      "\n",
      "Epoch 00016: loss improved from 0.00171 to 0.00140, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 17/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 0.0013\n",
      "\n",
      "Epoch 00017: loss improved from 0.00140 to 0.00126, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 18/2000\n",
      "2014/2014 [==============================] - 0s 39us/step - loss: 0.0011\n",
      "\n",
      "Epoch 00018: loss improved from 0.00126 to 0.00114, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 19/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 9.7715e-04\n",
      "\n",
      "Epoch 00019: loss improved from 0.00114 to 0.00098, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 20/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 8.1242e-04\n",
      "\n",
      "Epoch 00020: loss improved from 0.00098 to 0.00081, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 21/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 6.9163e-04\n",
      "\n",
      "Epoch 00021: loss improved from 0.00081 to 0.00069, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 22/2000\n",
      "2014/2014 [==============================] - 0s 40us/step - loss: 5.9787e-04\n",
      "\n",
      "Epoch 00022: loss improved from 0.00069 to 0.00060, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 23/2000\n",
      "2014/2014 [==============================] - 0s 40us/step - loss: 5.1072e-04\n",
      "\n",
      "Epoch 00023: loss improved from 0.00060 to 0.00051, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 24/2000\n",
      "2014/2014 [==============================] - 0s 39us/step - loss: 4.2996e-04\n",
      "\n",
      "Epoch 00024: loss improved from 0.00051 to 0.00043, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 25/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 3.6660e-04\n",
      "\n",
      "Epoch 00025: loss improved from 0.00043 to 0.00037, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 26/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 3.1822e-04\n",
      "\n",
      "Epoch 00026: loss improved from 0.00037 to 0.00032, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 27/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 2.7754e-04\n",
      "\n",
      "Epoch 00027: loss improved from 0.00032 to 0.00028, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 28/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 2.4502e-04\n",
      "\n",
      "Epoch 00028: loss improved from 0.00028 to 0.00025, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 29/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 2.2027e-04\n",
      "\n",
      "Epoch 00029: loss improved from 0.00025 to 0.00022, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 30/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 2.0301e-04\n",
      "\n",
      "Epoch 00030: loss improved from 0.00022 to 0.00020, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 31/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.9029e-04\n",
      "\n",
      "Epoch 00031: loss improved from 0.00020 to 0.00019, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 32/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.8104e-04\n",
      "\n",
      "Epoch 00032: loss improved from 0.00019 to 0.00018, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 33/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.7506e-04\n",
      "\n",
      "Epoch 00033: loss improved from 0.00018 to 0.00018, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 34/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.7142e-04\n",
      "\n",
      "Epoch 00034: loss improved from 0.00018 to 0.00017, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 35/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.6860e-04\n",
      "\n",
      "Epoch 00035: loss improved from 0.00017 to 0.00017, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 36/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 1.6725e-04\n",
      "\n",
      "Epoch 00036: loss improved from 0.00017 to 0.00017, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 37/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.6642e-04\n",
      "\n",
      "Epoch 00037: loss improved from 0.00017 to 0.00017, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 38/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.6579e-04\n",
      "\n",
      "Epoch 00038: loss improved from 0.00017 to 0.00017, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 39/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.6537e-04\n",
      "\n",
      "Epoch 00039: loss improved from 0.00017 to 0.00017, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 40/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.6506e-04\n",
      "\n",
      "Epoch 00040: loss improved from 0.00017 to 0.00017, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 41/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.6488e-04\n",
      "\n",
      "Epoch 00041: loss improved from 0.00017 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 42/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.6467e-04\n",
      "\n",
      "Epoch 00042: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 43/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.6441e-04\n",
      "\n",
      "Epoch 00043: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 44/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.6414e-04\n",
      "\n",
      "Epoch 00044: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 45/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.6384e-04\n",
      "\n",
      "Epoch 00045: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 46/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.6360e-04\n",
      "\n",
      "Epoch 00046: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 47/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.6334e-04\n",
      "\n",
      "Epoch 00047: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 48/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.6317e-04\n",
      "\n",
      "Epoch 00048: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 49/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.6278e-04\n",
      "\n",
      "Epoch 00049: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 50/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.6250e-04\n",
      "\n",
      "Epoch 00050: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 51/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.6222e-04\n",
      "\n",
      "Epoch 00051: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 52/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.6208e-04\n",
      "\n",
      "Epoch 00052: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 53/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.6170e-04\n",
      "\n",
      "Epoch 00053: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 54/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.6137e-04\n",
      "\n",
      "Epoch 00054: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 55/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.6110e-04\n",
      "\n",
      "Epoch 00055: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 56/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.6082e-04\n",
      "\n",
      "Epoch 00056: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 57/2000\n",
      "2014/2014 [==============================] - 0s 44us/step - loss: 1.6056e-04\n",
      "\n",
      "Epoch 00057: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 58/2000\n",
      "2014/2014 [==============================] - 0s 46us/step - loss: 1.6036e-04\n",
      "\n",
      "Epoch 00058: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 59/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.6006e-04\n",
      "\n",
      "Epoch 00059: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 60/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.5967e-04\n",
      "\n",
      "Epoch 00060: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 61/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.5949e-04\n",
      "\n",
      "Epoch 00061: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 62/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.5922e-04\n",
      "\n",
      "Epoch 00062: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 63/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.5895e-04\n",
      "\n",
      "Epoch 00063: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 64/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.5864e-04\n",
      "\n",
      "Epoch 00064: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 65/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.5833e-04\n",
      "\n",
      "Epoch 00065: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 66/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.5803e-04\n",
      "\n",
      "Epoch 00066: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 67/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.5775e-04\n",
      "\n",
      "Epoch 00067: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 68/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.5747e-04\n",
      "\n",
      "Epoch 00068: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 69/2000\n",
      "2014/2014 [==============================] - ETA: 0s - loss: 1.7038e-0 - 0s 29us/step - loss: 1.5718e-04\n",
      "\n",
      "Epoch 00069: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 70/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.5690e-04\n",
      "\n",
      "Epoch 00070: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 71/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.5664e-04\n",
      "\n",
      "Epoch 00071: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 72/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.5637e-04\n",
      "\n",
      "Epoch 00072: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 73/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.5607e-04\n",
      "\n",
      "Epoch 00073: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 74/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.5583e-04\n",
      "\n",
      "Epoch 00074: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 75/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.5561e-04\n",
      "\n",
      "Epoch 00075: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 76/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.5533e-04\n",
      "\n",
      "Epoch 00076: loss improved from 0.00016 to 0.00016, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 77/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.5496e-04\n",
      "\n",
      "Epoch 00077: loss improved from 0.00016 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 78/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.5468e-04\n",
      "\n",
      "Epoch 00078: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 79/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.5439e-04\n",
      "\n",
      "Epoch 00079: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 80/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 1.5413e-04\n",
      "\n",
      "Epoch 00080: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 81/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.5384e-04\n",
      "\n",
      "Epoch 00081: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 82/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.5354e-04\n",
      "\n",
      "Epoch 00082: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 83/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.5329e-04\n",
      "\n",
      "Epoch 00083: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 84/2000\n",
      "2014/2014 [==============================] - 0s 25us/step - loss: 1.5306e-04\n",
      "\n",
      "Epoch 00084: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 85/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.5272e-04\n",
      "\n",
      "Epoch 00085: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 86/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.5245e-04\n",
      "\n",
      "Epoch 00086: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 87/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.5220e-04\n",
      "\n",
      "Epoch 00087: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 88/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.5192e-04\n",
      "\n",
      "Epoch 00088: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 89/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.5163e-04\n",
      "\n",
      "Epoch 00089: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 90/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.5137e-04\n",
      "\n",
      "Epoch 00090: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 91/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 34us/step - loss: 1.5110e-04\n",
      "\n",
      "Epoch 00091: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 92/2000\n",
      "2014/2014 [==============================] - 0s 40us/step - loss: 1.5080e-04\n",
      "\n",
      "Epoch 00092: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 93/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 1.5061e-04\n",
      "\n",
      "Epoch 00093: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 94/2000\n",
      "2014/2014 [==============================] - 0s 38us/step - loss: 1.5029e-04\n",
      "\n",
      "Epoch 00094: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 95/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.5006e-04\n",
      "\n",
      "Epoch 00095: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 96/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.4988e-04\n",
      "\n",
      "Epoch 00096: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 97/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.4949e-04\n",
      "\n",
      "Epoch 00097: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 98/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.4922e-04\n",
      "\n",
      "Epoch 00098: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 99/2000\n",
      "2014/2014 [==============================] - 0s 45us/step - loss: 1.4898e-04\n",
      "\n",
      "Epoch 00099: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 100/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.4876e-04\n",
      "\n",
      "Epoch 00100: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 101/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.4844e-04\n",
      "\n",
      "Epoch 00101: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 102/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.4819e-04\n",
      "\n",
      "Epoch 00102: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 103/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.4792e-04\n",
      "\n",
      "Epoch 00103: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 104/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.4765e-04\n",
      "\n",
      "Epoch 00104: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 105/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.4740e-04\n",
      "\n",
      "Epoch 00105: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 106/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.4716e-04\n",
      "\n",
      "Epoch 00106: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 107/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.4692e-04\n",
      "\n",
      "Epoch 00107: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 108/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.4667e-04\n",
      "\n",
      "Epoch 00108: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 109/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.4643e-04\n",
      "\n",
      "Epoch 00109: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 110/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.4616e-04\n",
      "\n",
      "Epoch 00110: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 111/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.4591e-04\n",
      "\n",
      "Epoch 00111: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 112/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.4566e-04\n",
      "\n",
      "Epoch 00112: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 113/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.4548e-04\n",
      "\n",
      "Epoch 00113: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 114/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.4520e-04\n",
      "\n",
      "Epoch 00114: loss improved from 0.00015 to 0.00015, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 115/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.4490e-04\n",
      "\n",
      "Epoch 00115: loss improved from 0.00015 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 116/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.4469e-04\n",
      "\n",
      "Epoch 00116: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 117/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.4443e-04\n",
      "\n",
      "Epoch 00117: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 118/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.4422e-04\n",
      "\n",
      "Epoch 00118: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 119/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.4400e-04\n",
      "\n",
      "Epoch 00119: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 120/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.4382e-04\n",
      "\n",
      "Epoch 00120: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 121/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.4360e-04\n",
      "\n",
      "Epoch 00121: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 122/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.4327e-04\n",
      "\n",
      "Epoch 00122: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 123/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.4307e-04\n",
      "\n",
      "Epoch 00123: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 124/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.4284e-04\n",
      "\n",
      "Epoch 00124: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 125/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 1.4260e-04\n",
      "\n",
      "Epoch 00125: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 126/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.4238e-04\n",
      "\n",
      "Epoch 00126: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 127/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.4222e-04\n",
      "\n",
      "Epoch 00127: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 128/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.4188e-04\n",
      "\n",
      "Epoch 00128: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 129/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.4171e-04\n",
      "\n",
      "Epoch 00129: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 130/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.4151e-04\n",
      "\n",
      "Epoch 00130: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 131/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.4129e-04\n",
      "\n",
      "Epoch 00131: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 132/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.4103e-04\n",
      "\n",
      "Epoch 00132: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 133/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.4091e-04\n",
      "\n",
      "Epoch 00133: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 134/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.4061e-04\n",
      "\n",
      "Epoch 00134: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 135/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.4040e-04\n",
      "\n",
      "Epoch 00135: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 136/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.4023e-04\n",
      "\n",
      "Epoch 00136: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 137/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.4001e-04\n",
      "\n",
      "Epoch 00137: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 138/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.3981e-04\n",
      "\n",
      "Epoch 00138: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 139/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.3963e-04\n",
      "\n",
      "Epoch 00139: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 140/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.3937e-04\n",
      "\n",
      "Epoch 00140: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 141/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.3926e-04\n",
      "\n",
      "Epoch 00141: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 142/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.3897e-04\n",
      "\n",
      "Epoch 00142: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 143/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.3876e-04\n",
      "\n",
      "Epoch 00143: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 144/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.3854e-04\n",
      "\n",
      "Epoch 00144: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 145/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.3838e-04\n",
      "\n",
      "Epoch 00145: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 146/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.3831e-04\n",
      "\n",
      "Epoch 00146: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 147/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.3799e-04\n",
      "\n",
      "Epoch 00147: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 148/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.3787e-04\n",
      "\n",
      "Epoch 00148: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 149/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.3762e-04\n",
      "\n",
      "Epoch 00149: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 150/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.3742e-04\n",
      "\n",
      "Epoch 00150: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 151/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.3727e-04\n",
      "\n",
      "Epoch 00151: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 152/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.3715e-04\n",
      "\n",
      "Epoch 00152: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 153/2000\n",
      "2014/2014 [==============================] - 0s 40us/step - loss: 1.3688e-04\n",
      "\n",
      "Epoch 00153: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 154/2000\n",
      "2014/2014 [==============================] - 0s 37us/step - loss: 1.3671e-04\n",
      "\n",
      "Epoch 00154: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 155/2000\n",
      "2014/2014 [==============================] - 0s 43us/step - loss: 1.3651e-04\n",
      "\n",
      "Epoch 00155: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 156/2000\n",
      "2014/2014 [==============================] - 0s 37us/step - loss: 1.3635e-04\n",
      "\n",
      "Epoch 00156: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 157/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.3616e-04\n",
      "\n",
      "Epoch 00157: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 158/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.3600e-04\n",
      "\n",
      "Epoch 00158: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 159/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.3584e-04\n",
      "\n",
      "Epoch 00159: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 160/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.3567e-04\n",
      "\n",
      "Epoch 00160: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 161/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.3552e-04\n",
      "\n",
      "Epoch 00161: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 162/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.3535e-04\n",
      "\n",
      "Epoch 00162: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 163/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.3517e-04\n",
      "\n",
      "Epoch 00163: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 164/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.3500e-04\n",
      "\n",
      "Epoch 00164: loss improved from 0.00014 to 0.00014, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 165/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.3484e-04\n",
      "\n",
      "Epoch 00165: loss improved from 0.00014 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 166/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.3473e-04\n",
      "\n",
      "Epoch 00166: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 167/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.3462e-04\n",
      "\n",
      "Epoch 00167: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 168/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.3436e-04\n",
      "\n",
      "Epoch 00168: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 169/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.3421e-04\n",
      "\n",
      "Epoch 00169: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 170/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.3408e-04\n",
      "\n",
      "Epoch 00170: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 171/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.3392e-04\n",
      "\n",
      "Epoch 00171: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 172/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.3380e-04\n",
      "\n",
      "Epoch 00172: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 173/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.3359e-04\n",
      "\n",
      "Epoch 00173: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 174/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.3347e-04\n",
      "\n",
      "Epoch 00174: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 175/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.3337e-04\n",
      "\n",
      "Epoch 00175: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 176/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 1.3318e-04\n",
      "\n",
      "Epoch 00176: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 177/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.3307e-04\n",
      "\n",
      "Epoch 00177: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 178/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.3298e-04\n",
      "\n",
      "Epoch 00178: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 179/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.3278e-04\n",
      "\n",
      "Epoch 00179: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 180/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.3276e-04\n",
      "\n",
      "Epoch 00180: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 181/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.3249e-04\n",
      "\n",
      "Epoch 00181: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 182/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.3237e-04\n",
      "\n",
      "Epoch 00182: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 183/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.3225e-04\n",
      "\n",
      "Epoch 00183: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 184/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.3230e-04\n",
      "\n",
      "Epoch 00184: loss did not improve\n",
      "Epoch 185/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.3204e-04\n",
      "\n",
      "Epoch 00185: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 186/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.3196e-04\n",
      "\n",
      "Epoch 00186: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 187/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.3184e-04\n",
      "\n",
      "Epoch 00187: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 188/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.3163e-04\n",
      "\n",
      "Epoch 00188: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 189/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.3148e-04\n",
      "\n",
      "Epoch 00189: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 190/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.3139e-04\n",
      "\n",
      "Epoch 00190: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 191/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.3127e-04\n",
      "\n",
      "Epoch 00191: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 192/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 1.3119e-04\n",
      "\n",
      "Epoch 00192: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 193/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.3103e-04\n",
      "\n",
      "Epoch 00193: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 194/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.3105e-04\n",
      "\n",
      "Epoch 00194: loss did not improve\n",
      "Epoch 195/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.3092e-04\n",
      "\n",
      "Epoch 00195: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 196/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.3080e-04\n",
      "\n",
      "Epoch 00196: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 197/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.3069e-04\n",
      "\n",
      "Epoch 00197: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 198/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.3045e-04\n",
      "\n",
      "Epoch 00198: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 199/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.3039e-04\n",
      "\n",
      "Epoch 00199: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 200/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.3024e-04\n",
      "\n",
      "Epoch 00200: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 201/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.3018e-04\n",
      "\n",
      "Epoch 00201: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 202/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.3008e-04\n",
      "\n",
      "Epoch 00202: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 203/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.3000e-04\n",
      "\n",
      "Epoch 00203: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 204/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2988e-04\n",
      "\n",
      "Epoch 00204: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 205/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.2984e-04\n",
      "\n",
      "Epoch 00205: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 206/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2965e-04\n",
      "\n",
      "Epoch 00206: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 207/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2963e-04\n",
      "\n",
      "Epoch 00207: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 208/2000\n",
      "2014/2014 [==============================] - 0s 38us/step - loss: 1.2954e-04\n",
      "\n",
      "Epoch 00208: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 209/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 1.2947e-04\n",
      "\n",
      "Epoch 00209: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 210/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 1.2933e-04\n",
      "\n",
      "Epoch 00210: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 211/2000\n",
      "2014/2014 [==============================] - 0s 41us/step - loss: 1.2937e-04\n",
      "\n",
      "Epoch 00211: loss did not improve\n",
      "Epoch 212/2000\n",
      "2014/2014 [==============================] - 0s 42us/step - loss: 1.2923e-04\n",
      "\n",
      "Epoch 00212: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 213/2000\n",
      "2014/2014 [==============================] - 0s 42us/step - loss: 1.2912e-04\n",
      "\n",
      "Epoch 00213: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 214/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.2899e-04\n",
      "\n",
      "Epoch 00214: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 215/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2896e-04\n",
      "\n",
      "Epoch 00215: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 216/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2879e-04\n",
      "\n",
      "Epoch 00216: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 217/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2885e-04\n",
      "\n",
      "Epoch 00217: loss did not improve\n",
      "Epoch 218/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.2866e-04\n",
      "\n",
      "Epoch 00218: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 219/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2861e-04\n",
      "\n",
      "Epoch 00219: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 220/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2849e-04\n",
      "\n",
      "Epoch 00220: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 221/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2843e-04\n",
      "\n",
      "Epoch 00221: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 222/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2828e-04\n",
      "\n",
      "Epoch 00222: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 223/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2827e-04\n",
      "\n",
      "Epoch 00223: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 224/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2818e-04\n",
      "\n",
      "Epoch 00224: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 225/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2804e-04\n",
      "\n",
      "Epoch 00225: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 226/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2803e-04\n",
      "\n",
      "Epoch 00226: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 227/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2793e-04\n",
      "\n",
      "Epoch 00227: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 228/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 1.2789e-04\n",
      "\n",
      "Epoch 00228: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 229/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2776e-04\n",
      "\n",
      "Epoch 00229: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 230/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2776e-04\n",
      "\n",
      "Epoch 00230: loss did not improve\n",
      "Epoch 231/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.2766e-04\n",
      "\n",
      "Epoch 00231: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 232/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2759e-04\n",
      "\n",
      "Epoch 00232: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 233/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2753e-04\n",
      "\n",
      "Epoch 00233: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 234/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2746e-04\n",
      "\n",
      "Epoch 00234: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 235/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2740e-04\n",
      "\n",
      "Epoch 00235: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 236/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2751e-04\n",
      "\n",
      "Epoch 00236: loss did not improve\n",
      "Epoch 237/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2731e-04\n",
      "\n",
      "Epoch 00237: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 238/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2723e-04\n",
      "\n",
      "Epoch 00238: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 239/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2712e-04\n",
      "\n",
      "Epoch 00239: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 240/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2709e-04\n",
      "\n",
      "Epoch 00240: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 241/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2712e-04\n",
      "\n",
      "Epoch 00241: loss did not improve\n",
      "Epoch 242/2000\n",
      "2014/2014 [==============================] - 0s 38us/step - loss: 1.2711e-04\n",
      "\n",
      "Epoch 00242: loss did not improve\n",
      "Epoch 243/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2702e-04\n",
      "\n",
      "Epoch 00243: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 244/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2687e-04\n",
      "\n",
      "Epoch 00244: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 245/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2684e-04\n",
      "\n",
      "Epoch 00245: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 246/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2671e-04\n",
      "\n",
      "Epoch 00246: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 247/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2667e-04\n",
      "\n",
      "Epoch 00247: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 248/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2664e-04\n",
      "\n",
      "Epoch 00248: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 249/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2672e-04\n",
      "\n",
      "Epoch 00249: loss did not improve\n",
      "Epoch 250/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2665e-04\n",
      "\n",
      "Epoch 00250: loss did not improve\n",
      "Epoch 251/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2647e-04\n",
      "\n",
      "Epoch 00251: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 252/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2647e-04\n",
      "\n",
      "Epoch 00252: loss did not improve\n",
      "Epoch 253/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2644e-04\n",
      "\n",
      "Epoch 00253: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 254/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.2639e-04\n",
      "\n",
      "Epoch 00254: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 255/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2640e-04\n",
      "\n",
      "Epoch 00255: loss did not improve\n",
      "Epoch 256/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 1.2633e-04\n",
      "\n",
      "Epoch 00256: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 257/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2619e-04\n",
      "\n",
      "Epoch 00257: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 258/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2623e-04\n",
      "\n",
      "Epoch 00258: loss did not improve\n",
      "Epoch 259/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.2629e-04\n",
      "\n",
      "Epoch 00259: loss did not improve\n",
      "Epoch 260/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.2602e-04\n",
      "\n",
      "Epoch 00260: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 261/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 1.2602e-04\n",
      "\n",
      "Epoch 00261: loss did not improve\n",
      "Epoch 262/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.2597e-04\n",
      "\n",
      "Epoch 00262: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 263/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.2588e-04\n",
      "\n",
      "Epoch 00263: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 264/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.2589e-04\n",
      "\n",
      "Epoch 00264: loss did not improve\n",
      "Epoch 265/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2591e-04\n",
      "\n",
      "Epoch 00265: loss did not improve\n",
      "Epoch 266/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.2603e-04\n",
      "\n",
      "Epoch 00266: loss did not improve\n",
      "Epoch 267/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 1.2572e-04\n",
      "\n",
      "Epoch 00267: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 268/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2578e-04\n",
      "\n",
      "Epoch 00268: loss did not improve\n",
      "Epoch 269/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.2565e-04\n",
      "\n",
      "Epoch 00269: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 270/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2563e-04\n",
      "\n",
      "Epoch 00270: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 271/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2562e-04\n",
      "\n",
      "Epoch 00271: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 272/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2546e-04\n",
      "\n",
      "Epoch 00272: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2567e-04\n",
      "\n",
      "Epoch 00273: loss did not improve\n",
      "Epoch 274/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.2539e-04\n",
      "\n",
      "Epoch 00274: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 275/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2541e-04\n",
      "\n",
      "Epoch 00275: loss did not improve\n",
      "Epoch 276/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2539e-04\n",
      "\n",
      "Epoch 00276: loss did not improve\n",
      "Epoch 277/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2530e-04\n",
      "\n",
      "Epoch 00277: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 278/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.2528e-04\n",
      "\n",
      "Epoch 00278: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 279/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2526e-04\n",
      "\n",
      "Epoch 00279: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 280/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2524e-04\n",
      "\n",
      "Epoch 00280: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 281/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2518e-04\n",
      "\n",
      "Epoch 00281: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 282/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2514e-04\n",
      "\n",
      "Epoch 00282: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 283/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2511e-04\n",
      "\n",
      "Epoch 00283: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 284/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2504e-04\n",
      "\n",
      "Epoch 00284: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 285/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2506e-04\n",
      "\n",
      "Epoch 00285: loss did not improve\n",
      "Epoch 286/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2503e-04\n",
      "\n",
      "Epoch 00286: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 287/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2500e-04\n",
      "\n",
      "Epoch 00287: loss improved from 0.00013 to 0.00013, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 288/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2489e-04\n",
      "\n",
      "Epoch 00288: loss improved from 0.00013 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 289/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2485e-04\n",
      "\n",
      "Epoch 00289: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 290/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2488e-04\n",
      "\n",
      "Epoch 00290: loss did not improve\n",
      "Epoch 291/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.2484e-04\n",
      "\n",
      "Epoch 00291: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 292/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2482e-04\n",
      "\n",
      "Epoch 00292: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 293/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2481e-04\n",
      "\n",
      "Epoch 00293: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 294/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2474e-04\n",
      "\n",
      "Epoch 00294: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 295/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2470e-04\n",
      "\n",
      "Epoch 00295: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 296/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.2470e-04\n",
      "\n",
      "Epoch 00296: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 297/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.2463e-04\n",
      "\n",
      "Epoch 00297: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 298/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 1.2458e-04\n",
      "\n",
      "Epoch 00298: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 299/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2456e-04\n",
      "\n",
      "Epoch 00299: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 300/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2448e-04\n",
      "\n",
      "Epoch 00300: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 301/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2461e-04\n",
      "\n",
      "Epoch 00301: loss did not improve\n",
      "Epoch 302/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2457e-04\n",
      "\n",
      "Epoch 00302: loss did not improve\n",
      "Epoch 303/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.2444e-04\n",
      "\n",
      "Epoch 00303: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 304/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2455e-04\n",
      "\n",
      "Epoch 00304: loss did not improve\n",
      "Epoch 305/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2435e-04\n",
      "\n",
      "Epoch 00305: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 306/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2441e-04\n",
      "\n",
      "Epoch 00306: loss did not improve\n",
      "Epoch 307/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2428e-04\n",
      "\n",
      "Epoch 00307: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 308/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2432e-04\n",
      "\n",
      "Epoch 00308: loss did not improve\n",
      "Epoch 309/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2424e-04\n",
      "\n",
      "Epoch 00309: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 310/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2421e-04\n",
      "\n",
      "Epoch 00310: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 311/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2420e-04\n",
      "\n",
      "Epoch 00311: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 312/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2414e-04\n",
      "\n",
      "Epoch 00312: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 313/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2437e-04\n",
      "\n",
      "Epoch 00313: loss did not improve\n",
      "Epoch 314/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2408e-04\n",
      "\n",
      "Epoch 00314: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 315/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2430e-04\n",
      "\n",
      "Epoch 00315: loss did not improve\n",
      "Epoch 316/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2403e-04\n",
      "\n",
      "Epoch 00316: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 317/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2415e-04\n",
      "\n",
      "Epoch 00317: loss did not improve\n",
      "Epoch 318/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.2413e-04\n",
      "\n",
      "Epoch 00318: loss did not improve\n",
      "Epoch 319/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2398e-04\n",
      "\n",
      "Epoch 00319: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 320/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.2397e-04\n",
      "\n",
      "Epoch 00320: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 321/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.2402e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00321: loss did not improve\n",
      "Epoch 322/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2390e-04\n",
      "\n",
      "Epoch 00322: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 323/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.2383e-04\n",
      "\n",
      "Epoch 00323: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 324/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 1.2384e-04\n",
      "\n",
      "Epoch 00324: loss did not improve\n",
      "Epoch 325/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2372e-04\n",
      "\n",
      "Epoch 00325: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 326/2000\n",
      "2014/2014 [==============================] - 0s 25us/step - loss: 1.2374e-04\n",
      "\n",
      "Epoch 00326: loss did not improve\n",
      "Epoch 327/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2366e-04\n",
      "\n",
      "Epoch 00327: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 328/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2367e-04\n",
      "\n",
      "Epoch 00328: loss did not improve\n",
      "Epoch 329/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2378e-04\n",
      "\n",
      "Epoch 00329: loss did not improve\n",
      "Epoch 330/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2364e-04\n",
      "\n",
      "Epoch 00330: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 331/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.2356e-04\n",
      "\n",
      "Epoch 00331: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 332/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2359e-04\n",
      "\n",
      "Epoch 00332: loss did not improve\n",
      "Epoch 333/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2343e-04\n",
      "\n",
      "Epoch 00333: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 334/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2350e-04\n",
      "\n",
      "Epoch 00334: loss did not improve\n",
      "Epoch 335/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2345e-04\n",
      "\n",
      "Epoch 00335: loss did not improve\n",
      "Epoch 336/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2365e-04\n",
      "\n",
      "Epoch 00336: loss did not improve\n",
      "Epoch 337/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2377e-04\n",
      "\n",
      "Epoch 00337: loss did not improve\n",
      "Epoch 338/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2339e-04\n",
      "\n",
      "Epoch 00338: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 339/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.2388e-04\n",
      "\n",
      "Epoch 00339: loss did not improve\n",
      "Epoch 340/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2305e-04\n",
      "\n",
      "Epoch 00340: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 341/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2360e-04\n",
      "\n",
      "Epoch 00341: loss did not improve\n",
      "Epoch 342/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2355e-04\n",
      "\n",
      "Epoch 00342: loss did not improve\n",
      "Epoch 343/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 1.2353e-04\n",
      "\n",
      "Epoch 00343: loss did not improve\n",
      "Epoch 344/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2317e-04\n",
      "\n",
      "Epoch 00344: loss did not improve\n",
      "Epoch 345/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2320e-04\n",
      "\n",
      "Epoch 00345: loss did not improve\n",
      "Epoch 346/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.2347e-04\n",
      "\n",
      "Epoch 00346: loss did not improve\n",
      "Epoch 347/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2306e-04\n",
      "\n",
      "Epoch 00347: loss did not improve\n",
      "Epoch 348/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2309e-04\n",
      "\n",
      "Epoch 00348: loss did not improve\n",
      "Epoch 349/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.2309e-04\n",
      "\n",
      "Epoch 00349: loss did not improve\n",
      "Epoch 350/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2294e-04\n",
      "\n",
      "Epoch 00350: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 351/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2298e-04\n",
      "\n",
      "Epoch 00351: loss did not improve\n",
      "Epoch 352/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2307e-04\n",
      "\n",
      "Epoch 00352: loss did not improve\n",
      "Epoch 353/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2297e-04\n",
      "\n",
      "Epoch 00353: loss did not improve\n",
      "Epoch 354/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2294e-04\n",
      "\n",
      "Epoch 00354: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 355/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2294e-04\n",
      "\n",
      "Epoch 00355: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 356/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2288e-04\n",
      "\n",
      "Epoch 00356: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 357/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2275e-04\n",
      "\n",
      "Epoch 00357: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 358/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2283e-04\n",
      "\n",
      "Epoch 00358: loss did not improve\n",
      "Epoch 359/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 1.2264e-04\n",
      "\n",
      "Epoch 00359: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 360/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2267e-04\n",
      "\n",
      "Epoch 00360: loss did not improve\n",
      "Epoch 361/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2262e-04\n",
      "\n",
      "Epoch 00361: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 362/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2279e-04\n",
      "\n",
      "Epoch 00362: loss did not improve\n",
      "Epoch 363/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2253e-04\n",
      "\n",
      "Epoch 00363: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 364/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2264e-04\n",
      "\n",
      "Epoch 00364: loss did not improve\n",
      "Epoch 365/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2250e-04\n",
      "\n",
      "Epoch 00365: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 366/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2255e-04\n",
      "\n",
      "Epoch 00366: loss did not improve\n",
      "Epoch 367/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.2245e-04\n",
      "\n",
      "Epoch 00367: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 368/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2252e-04\n",
      "\n",
      "Epoch 00368: loss did not improve\n",
      "Epoch 369/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2267e-04\n",
      "\n",
      "Epoch 00369: loss did not improve\n",
      "Epoch 370/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2240e-04\n",
      "\n",
      "Epoch 00370: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 371/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2240e-04\n",
      "\n",
      "Epoch 00371: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 372/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2230e-04\n",
      "\n",
      "Epoch 00372: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 373/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2226e-04\n",
      "\n",
      "Epoch 00373: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 374/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2221e-04\n",
      "\n",
      "Epoch 00374: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 375/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2224e-04\n",
      "\n",
      "Epoch 00375: loss did not improve\n",
      "Epoch 376/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2240e-04\n",
      "\n",
      "Epoch 00376: loss did not improve\n",
      "Epoch 377/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2223e-04\n",
      "\n",
      "Epoch 00377: loss did not improve\n",
      "Epoch 378/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2246e-04\n",
      "\n",
      "Epoch 00378: loss did not improve\n",
      "Epoch 379/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2201e-04\n",
      "\n",
      "Epoch 00379: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 380/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2214e-04\n",
      "\n",
      "Epoch 00380: loss did not improve\n",
      "Epoch 381/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.2219e-04\n",
      "\n",
      "Epoch 00381: loss did not improve\n",
      "Epoch 382/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2199e-04\n",
      "\n",
      "Epoch 00382: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 383/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 1.2242e-04\n",
      "\n",
      "Epoch 00383: loss did not improve\n",
      "Epoch 384/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2233e-04\n",
      "\n",
      "Epoch 00384: loss did not improve\n",
      "Epoch 385/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2190e-04\n",
      "\n",
      "Epoch 00385: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 386/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2231e-04\n",
      "\n",
      "Epoch 00386: loss did not improve\n",
      "Epoch 387/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2222e-04\n",
      "\n",
      "Epoch 00387: loss did not improve\n",
      "Epoch 388/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2259e-04\n",
      "\n",
      "Epoch 00388: loss did not improve\n",
      "Epoch 389/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2183e-04\n",
      "\n",
      "Epoch 00389: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 390/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2187e-04\n",
      "\n",
      "Epoch 00390: loss did not improve\n",
      "Epoch 391/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2169e-04\n",
      "\n",
      "Epoch 00391: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 392/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2176e-04\n",
      "\n",
      "Epoch 00392: loss did not improve\n",
      "Epoch 393/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2201e-04\n",
      "\n",
      "Epoch 00393: loss did not improve\n",
      "Epoch 394/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2155e-04\n",
      "\n",
      "Epoch 00394: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 395/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.2169e-04\n",
      "\n",
      "Epoch 00395: loss did not improve\n",
      "Epoch 396/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2170e-04\n",
      "\n",
      "Epoch 00396: loss did not improve\n",
      "Epoch 397/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2147e-04\n",
      "\n",
      "Epoch 00397: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 398/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 1.2144e-04\n",
      "\n",
      "Epoch 00398: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 399/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2140e-04\n",
      "\n",
      "Epoch 00399: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 400/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2150e-04\n",
      "\n",
      "Epoch 00400: loss did not improve\n",
      "Epoch 401/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2132e-04\n",
      "\n",
      "Epoch 00401: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 402/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2146e-04\n",
      "\n",
      "Epoch 00402: loss did not improve\n",
      "Epoch 403/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2129e-04\n",
      "\n",
      "Epoch 00403: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 404/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2129e-04\n",
      "\n",
      "Epoch 00404: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 405/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2128e-04\n",
      "\n",
      "Epoch 00405: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 406/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2122e-04\n",
      "\n",
      "Epoch 00406: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 407/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.2120e-04\n",
      "\n",
      "Epoch 00407: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 408/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2112e-04\n",
      "\n",
      "Epoch 00408: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 409/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2114e-04\n",
      "\n",
      "Epoch 00409: loss did not improve\n",
      "Epoch 410/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2146e-04\n",
      "\n",
      "Epoch 00410: loss did not improve\n",
      "Epoch 411/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.2100e-04\n",
      "\n",
      "Epoch 00411: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 412/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2121e-04\n",
      "\n",
      "Epoch 00412: loss did not improve\n",
      "Epoch 413/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2097e-04\n",
      "\n",
      "Epoch 00413: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 414/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2099e-04\n",
      "\n",
      "Epoch 00414: loss did not improve\n",
      "Epoch 415/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2110e-04\n",
      "\n",
      "Epoch 00415: loss did not improve\n",
      "Epoch 416/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2102e-04\n",
      "\n",
      "Epoch 00416: loss did not improve\n",
      "Epoch 417/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.2093e-04\n",
      "\n",
      "Epoch 00417: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 418/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2092e-04\n",
      "\n",
      "Epoch 00418: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 419/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 1.2081e-04\n",
      "\n",
      "Epoch 00419: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 420/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2081e-04\n",
      "\n",
      "Epoch 00420: loss did not improve\n",
      "Epoch 421/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 1.2073e-04\n",
      "\n",
      "Epoch 00421: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 422/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2064e-04\n",
      "\n",
      "Epoch 00422: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 423/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2060e-04\n",
      "\n",
      "Epoch 00423: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 424/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2055e-04\n",
      "\n",
      "Epoch 00424: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 425/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2066e-04\n",
      "\n",
      "Epoch 00425: loss did not improve\n",
      "Epoch 426/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.2080e-04\n",
      "\n",
      "Epoch 00426: loss did not improve\n",
      "Epoch 427/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2061e-04\n",
      "\n",
      "Epoch 00427: loss did not improve\n",
      "Epoch 428/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.2052e-04\n",
      "\n",
      "Epoch 00428: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 429/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2066e-04\n",
      "\n",
      "Epoch 00429: loss did not improve\n",
      "Epoch 430/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2080e-04\n",
      "\n",
      "Epoch 00430: loss did not improve\n",
      "Epoch 431/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.2048e-04\n",
      "\n",
      "Epoch 00431: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 432/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2038e-04\n",
      "\n",
      "Epoch 00432: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 433/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2050e-04\n",
      "\n",
      "Epoch 00433: loss did not improve\n",
      "Epoch 434/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 1.2026e-04\n",
      "\n",
      "Epoch 00434: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 435/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2027e-04\n",
      "\n",
      "Epoch 00435: loss did not improve\n",
      "Epoch 436/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2029e-04\n",
      "\n",
      "Epoch 00436: loss did not improve\n",
      "Epoch 437/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.2028e-04\n",
      "\n",
      "Epoch 00437: loss did not improve\n",
      "Epoch 438/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2012e-04\n",
      "\n",
      "Epoch 00438: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 439/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2018e-04\n",
      "\n",
      "Epoch 00439: loss did not improve\n",
      "Epoch 440/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2009e-04\n",
      "\n",
      "Epoch 00440: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 441/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.2003e-04\n",
      "\n",
      "Epoch 00441: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 442/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.1995e-04\n",
      "\n",
      "Epoch 00442: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 443/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.1991e-04\n",
      "\n",
      "Epoch 00443: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 444/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.1999e-04\n",
      "\n",
      "Epoch 00444: loss did not improve\n",
      "Epoch 445/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1996e-04\n",
      "\n",
      "Epoch 00445: loss did not improve\n",
      "Epoch 446/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.2045e-04\n",
      "\n",
      "Epoch 00446: loss did not improve\n",
      "Epoch 447/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.2057e-04\n",
      "\n",
      "Epoch 00447: loss did not improve\n",
      "Epoch 448/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.2032e-04\n",
      "\n",
      "Epoch 00448: loss did not improve\n",
      "Epoch 449/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1995e-04\n",
      "\n",
      "Epoch 00449: loss did not improve\n",
      "Epoch 450/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 1.1989e-04\n",
      "\n",
      "Epoch 00450: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 451/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.1980e-04\n",
      "\n",
      "Epoch 00451: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 452/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1958e-04\n",
      "\n",
      "Epoch 00452: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 453/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1966e-04\n",
      "\n",
      "Epoch 00453: loss did not improve\n",
      "Epoch 454/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1953e-04\n",
      "\n",
      "Epoch 00454: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 455/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.1960e-04\n",
      "\n",
      "Epoch 00455: loss did not improve\n",
      "Epoch 456/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1991e-04\n",
      "\n",
      "Epoch 00456: loss did not improve\n",
      "Epoch 457/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1932e-04\n",
      "\n",
      "Epoch 00457: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 458/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.1960e-04\n",
      "\n",
      "Epoch 00458: loss did not improve\n",
      "Epoch 459/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.1959e-04\n",
      "\n",
      "Epoch 00459: loss did not improve\n",
      "Epoch 460/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.1954e-04\n",
      "\n",
      "Epoch 00460: loss did not improve\n",
      "Epoch 461/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1940e-04\n",
      "\n",
      "Epoch 00461: loss did not improve\n",
      "Epoch 462/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1936e-04\n",
      "\n",
      "Epoch 00462: loss did not improve\n",
      "Epoch 463/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1917e-04\n",
      "\n",
      "Epoch 00463: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 464/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.1926e-04\n",
      "\n",
      "Epoch 00464: loss did not improve\n",
      "Epoch 465/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.1953e-04\n",
      "\n",
      "Epoch 00465: loss did not improve\n",
      "Epoch 466/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1936e-04\n",
      "\n",
      "Epoch 00466: loss did not improve\n",
      "Epoch 467/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1949e-04\n",
      "\n",
      "Epoch 00467: loss did not improve\n",
      "Epoch 468/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.1915e-04\n",
      "\n",
      "Epoch 00468: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 469/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1902e-04\n",
      "\n",
      "Epoch 00469: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 470/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1908e-04\n",
      "\n",
      "Epoch 00470: loss did not improve\n",
      "Epoch 471/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.1896e-04\n",
      "\n",
      "Epoch 00471: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 472/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1898e-04\n",
      "\n",
      "Epoch 00472: loss did not improve\n",
      "Epoch 473/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1906e-04\n",
      "\n",
      "Epoch 00473: loss did not improve\n",
      "Epoch 474/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1910e-04\n",
      "\n",
      "Epoch 00474: loss did not improve\n",
      "Epoch 475/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.1905e-04\n",
      "\n",
      "Epoch 00475: loss did not improve\n",
      "Epoch 476/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.1907e-04\n",
      "\n",
      "Epoch 00476: loss did not improve\n",
      "Epoch 477/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.1869e-04\n",
      "\n",
      "Epoch 00477: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 478/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1877e-04\n",
      "\n",
      "Epoch 00478: loss did not improve\n",
      "Epoch 479/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.1858e-04\n",
      "\n",
      "Epoch 00479: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 480/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1867e-04\n",
      "\n",
      "Epoch 00480: loss did not improve\n",
      "Epoch 481/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 1.1855e-04\n",
      "\n",
      "Epoch 00481: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 482/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1846e-04\n",
      "\n",
      "Epoch 00482: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 483/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.1852e-04\n",
      "\n",
      "Epoch 00483: loss did not improve\n",
      "Epoch 484/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1839e-04\n",
      "\n",
      "Epoch 00484: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 485/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 1.1835e-04\n",
      "\n",
      "Epoch 00485: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 486/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.1837e-04\n",
      "\n",
      "Epoch 00486: loss did not improve\n",
      "Epoch 487/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.1827e-04\n",
      "\n",
      "Epoch 00487: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 488/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1838e-04\n",
      "\n",
      "Epoch 00488: loss did not improve\n",
      "Epoch 489/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1873e-04\n",
      "\n",
      "Epoch 00489: loss did not improve\n",
      "Epoch 490/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1856e-04\n",
      "\n",
      "Epoch 00490: loss did not improve\n",
      "Epoch 491/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.1819e-04\n",
      "\n",
      "Epoch 00491: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 492/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1826e-04\n",
      "\n",
      "Epoch 00492: loss did not improve\n",
      "Epoch 493/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.1811e-04\n",
      "\n",
      "Epoch 00493: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 494/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1810e-04\n",
      "\n",
      "Epoch 00494: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 495/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.1806e-04\n",
      "\n",
      "Epoch 00495: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 496/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.1807e-04\n",
      "\n",
      "Epoch 00496: loss did not improve\n",
      "Epoch 497/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1824e-04\n",
      "\n",
      "Epoch 00497: loss did not improve\n",
      "Epoch 498/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1782e-04\n",
      "\n",
      "Epoch 00498: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 499/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1796e-04\n",
      "\n",
      "Epoch 00499: loss did not improve\n",
      "Epoch 500/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 1.1835e-04\n",
      "\n",
      "Epoch 00500: loss did not improve\n",
      "Epoch 501/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1771e-04\n",
      "\n",
      "Epoch 00501: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 502/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.1801e-04\n",
      "\n",
      "Epoch 00502: loss did not improve\n",
      "Epoch 503/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.1827e-04\n",
      "\n",
      "Epoch 00503: loss did not improve\n",
      "Epoch 504/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1774e-04\n",
      "\n",
      "Epoch 00504: loss did not improve\n",
      "Epoch 505/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.1773e-04\n",
      "\n",
      "Epoch 00505: loss did not improve\n",
      "Epoch 506/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.1792e-04\n",
      "\n",
      "Epoch 00506: loss did not improve\n",
      "Epoch 507/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.1769e-04\n",
      "\n",
      "Epoch 00507: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 508/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.1749e-04\n",
      "\n",
      "Epoch 00508: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 509/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1749e-04\n",
      "\n",
      "Epoch 00509: loss did not improve\n",
      "Epoch 510/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.1769e-04\n",
      "\n",
      "Epoch 00510: loss did not improve\n",
      "Epoch 511/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.1735e-04\n",
      "\n",
      "Epoch 00511: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 512/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1744e-04\n",
      "\n",
      "Epoch 00512: loss did not improve\n",
      "Epoch 513/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.1732e-04\n",
      "\n",
      "Epoch 00513: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 514/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.1729e-04\n",
      "\n",
      "Epoch 00514: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 515/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1709e-04\n",
      "\n",
      "Epoch 00515: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 516/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1712e-04\n",
      "\n",
      "Epoch 00516: loss did not improve\n",
      "Epoch 517/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1707e-04\n",
      "\n",
      "Epoch 00517: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 518/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.1699e-04\n",
      "\n",
      "Epoch 00518: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 519/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1700e-04\n",
      "\n",
      "Epoch 00519: loss did not improve\n",
      "Epoch 520/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1696e-04\n",
      "\n",
      "Epoch 00520: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 521/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.1691e-04\n",
      "\n",
      "Epoch 00521: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 522/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.1688e-04\n",
      "\n",
      "Epoch 00522: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 523/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1684e-04\n",
      "\n",
      "Epoch 00523: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 524/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1689e-04\n",
      "\n",
      "Epoch 00524: loss did not improve\n",
      "Epoch 525/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1668e-04\n",
      "\n",
      "Epoch 00525: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 526/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.1667e-04\n",
      "\n",
      "Epoch 00526: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 527/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1664e-04\n",
      "\n",
      "Epoch 00527: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 528/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 1.1663e-04\n",
      "\n",
      "Epoch 00528: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 529/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.1662e-04\n",
      "\n",
      "Epoch 00529: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 530/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.1656e-04\n",
      "\n",
      "Epoch 00530: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 531/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.1656e-04\n",
      "\n",
      "Epoch 00531: loss did not improve\n",
      "Epoch 532/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.1637e-04\n",
      "\n",
      "Epoch 00532: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 533/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1638e-04\n",
      "\n",
      "Epoch 00533: loss did not improve\n",
      "Epoch 534/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.1633e-04\n",
      "\n",
      "Epoch 00534: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 535/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1641e-04\n",
      "\n",
      "Epoch 00535: loss did not improve\n",
      "Epoch 536/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.1634e-04\n",
      "\n",
      "Epoch 00536: loss did not improve\n",
      "Epoch 537/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.1631e-04\n",
      "\n",
      "Epoch 00537: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 538/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1649e-04\n",
      "\n",
      "Epoch 00538: loss did not improve\n",
      "Epoch 539/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1655e-04\n",
      "\n",
      "Epoch 00539: loss did not improve\n",
      "Epoch 540/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.1662e-04\n",
      "\n",
      "Epoch 00540: loss did not improve\n",
      "Epoch 541/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1672e-04\n",
      "\n",
      "Epoch 00541: loss did not improve\n",
      "Epoch 542/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.1595e-04\n",
      "\n",
      "Epoch 00542: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 543/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.1611e-04\n",
      "\n",
      "Epoch 00543: loss did not improve\n",
      "Epoch 544/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1596e-04\n",
      "\n",
      "Epoch 00544: loss did not improve\n",
      "Epoch 545/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1582e-04\n",
      "\n",
      "Epoch 00545: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 546/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1592e-04\n",
      "\n",
      "Epoch 00546: loss did not improve\n",
      "Epoch 547/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1598e-04\n",
      "\n",
      "Epoch 00547: loss did not improve\n",
      "Epoch 548/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.1574e-04\n",
      "\n",
      "Epoch 00548: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 549/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.1600e-04\n",
      "\n",
      "Epoch 00549: loss did not improve\n",
      "Epoch 550/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1571e-04\n",
      "\n",
      "Epoch 00550: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 551/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1563e-04\n",
      "\n",
      "Epoch 00551: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 552/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1554e-04\n",
      "\n",
      "Epoch 00552: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 553/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1552e-04\n",
      "\n",
      "Epoch 00553: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 554/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.1555e-04\n",
      "\n",
      "Epoch 00554: loss did not improve\n",
      "Epoch 555/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.1597e-04\n",
      "\n",
      "Epoch 00555: loss did not improve\n",
      "Epoch 556/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.1570e-04\n",
      "\n",
      "Epoch 00556: loss did not improve\n",
      "Epoch 557/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.1545e-04\n",
      "\n",
      "Epoch 00557: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 558/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1551e-04\n",
      "\n",
      "Epoch 00558: loss did not improve\n",
      "Epoch 559/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1533e-04\n",
      "\n",
      "Epoch 00559: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 560/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.1527e-04\n",
      "\n",
      "Epoch 00560: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 561/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1527e-04\n",
      "\n",
      "Epoch 00561: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 562/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 1.1519e-04\n",
      "\n",
      "Epoch 00562: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 563/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1510e-04\n",
      "\n",
      "Epoch 00563: loss improved from 0.00012 to 0.00012, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 564/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1530e-04\n",
      "\n",
      "Epoch 00564: loss did not improve\n",
      "Epoch 565/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1497e-04\n",
      "\n",
      "Epoch 00565: loss improved from 0.00012 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 566/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.1488e-04\n",
      "\n",
      "Epoch 00566: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 567/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.1527e-04\n",
      "\n",
      "Epoch 00567: loss did not improve\n",
      "Epoch 568/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.1507e-04\n",
      "\n",
      "Epoch 00568: loss did not improve\n",
      "Epoch 569/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.1497e-04\n",
      "\n",
      "Epoch 00569: loss did not improve\n",
      "Epoch 570/2000\n",
      "2014/2014 [==============================] - 0s 38us/step - loss: 1.1473e-04\n",
      "\n",
      "Epoch 00570: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 571/2000\n",
      "2014/2014 [==============================] - 0s 39us/step - loss: 1.1514e-04\n",
      "\n",
      "Epoch 00571: loss did not improve\n",
      "Epoch 572/2000\n",
      "2014/2014 [==============================] - 0s 39us/step - loss: 1.1474e-04\n",
      "\n",
      "Epoch 00572: loss did not improve\n",
      "Epoch 573/2000\n",
      "2014/2014 [==============================] - 0s 36us/step - loss: 1.1460e-04\n",
      "\n",
      "Epoch 00573: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 574/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.1459e-04\n",
      "\n",
      "Epoch 00574: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 575/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.1467e-04\n",
      "\n",
      "Epoch 00575: loss did not improve\n",
      "Epoch 576/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1443e-04\n",
      "\n",
      "Epoch 00576: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 577/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1469e-04\n",
      "\n",
      "Epoch 00577: loss did not improve\n",
      "Epoch 578/2000\n",
      "2014/2014 [==============================] - 0s 39us/step - loss: 1.1444e-04\n",
      "\n",
      "Epoch 00578: loss did not improve\n",
      "Epoch 579/2000\n",
      "2014/2014 [==============================] - 0s 45us/step - loss: 1.1436e-04\n",
      "\n",
      "Epoch 00579: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 580/2000\n",
      "2014/2014 [==============================] - 0s 44us/step - loss: 1.1452e-04\n",
      "\n",
      "Epoch 00580: loss did not improve\n",
      "Epoch 581/2000\n",
      "2014/2014 [==============================] - 0s 39us/step - loss: 1.1459e-04\n",
      "\n",
      "Epoch 00581: loss did not improve\n",
      "Epoch 582/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.1409e-04\n",
      "\n",
      "Epoch 00582: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 583/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.1418e-04\n",
      "\n",
      "Epoch 00583: loss did not improve\n",
      "Epoch 584/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.1420e-04\n",
      "\n",
      "Epoch 00584: loss did not improve\n",
      "Epoch 585/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.1432e-04\n",
      "\n",
      "Epoch 00585: loss did not improve\n",
      "Epoch 586/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.1437e-04\n",
      "\n",
      "Epoch 00586: loss did not improve\n",
      "Epoch 587/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.1454e-04\n",
      "\n",
      "Epoch 00587: loss did not improve\n",
      "Epoch 588/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.1423e-04\n",
      "\n",
      "Epoch 00588: loss did not improve\n",
      "Epoch 589/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.1422e-04\n",
      "\n",
      "Epoch 00589: loss did not improve\n",
      "Epoch 590/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.1373e-04\n",
      "\n",
      "Epoch 00590: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 591/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1417e-04\n",
      "\n",
      "Epoch 00591: loss did not improve\n",
      "Epoch 592/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1418e-04\n",
      "\n",
      "Epoch 00592: loss did not improve\n",
      "Epoch 593/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1345e-04\n",
      "\n",
      "Epoch 00593: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 594/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.1379e-04\n",
      "\n",
      "Epoch 00594: loss did not improve\n",
      "Epoch 595/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1369e-04\n",
      "\n",
      "Epoch 00595: loss did not improve\n",
      "Epoch 596/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1367e-04\n",
      "\n",
      "Epoch 00596: loss did not improve\n",
      "Epoch 597/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1401e-04\n",
      "\n",
      "Epoch 00597: loss did not improve\n",
      "Epoch 598/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.1363e-04\n",
      "\n",
      "Epoch 00598: loss did not improve\n",
      "Epoch 599/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 1.1321e-04\n",
      "\n",
      "Epoch 00599: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 600/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1346e-04\n",
      "\n",
      "Epoch 00600: loss did not improve\n",
      "Epoch 601/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1340e-04\n",
      "\n",
      "Epoch 00601: loss did not improve\n",
      "Epoch 602/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 1.1322e-04\n",
      "\n",
      "Epoch 00602: loss did not improve\n",
      "Epoch 603/2000\n",
      "2014/2014 [==============================] - 0s 37us/step - loss: 1.1307e-04\n",
      "\n",
      "Epoch 00603: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 604/2000\n",
      "2014/2014 [==============================] - 0s 36us/step - loss: 1.1306e-04\n",
      "\n",
      "Epoch 00604: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 605/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 1.1308e-04\n",
      "\n",
      "Epoch 00605: loss did not improve\n",
      "Epoch 606/2000\n",
      "2014/2014 [==============================] - 0s 38us/step - loss: 1.1308e-04\n",
      "\n",
      "Epoch 00606: loss did not improve\n",
      "Epoch 607/2000\n",
      "2014/2014 [==============================] - 0s 36us/step - loss: 1.1300e-04\n",
      "\n",
      "Epoch 00607: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 608/2000\n",
      "2014/2014 [==============================] - 0s 37us/step - loss: 1.1278e-04\n",
      "\n",
      "Epoch 00608: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 609/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 1.1281e-04\n",
      "\n",
      "Epoch 00609: loss did not improve\n",
      "Epoch 610/2000\n",
      "2014/2014 [==============================] - 0s 37us/step - loss: 1.1277e-04\n",
      "\n",
      "Epoch 00610: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 611/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 1.1268e-04\n",
      "\n",
      "Epoch 00611: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 612/2000\n",
      "2014/2014 [==============================] - 0s 38us/step - loss: 1.1276e-04\n",
      "\n",
      "Epoch 00612: loss did not improve\n",
      "Epoch 613/2000\n",
      "2014/2014 [==============================] - 0s 37us/step - loss: 1.1257e-04\n",
      "\n",
      "Epoch 00613: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 614/2000\n",
      "2014/2014 [==============================] - 0s 37us/step - loss: 1.1270e-04\n",
      "\n",
      "Epoch 00614: loss did not improve\n",
      "Epoch 615/2000\n",
      "2014/2014 [==============================] - 0s 41us/step - loss: 1.1271e-04\n",
      "\n",
      "Epoch 00615: loss did not improve\n",
      "Epoch 616/2000\n",
      "2014/2014 [==============================] - 0s 39us/step - loss: 1.1284e-04\n",
      "\n",
      "Epoch 00616: loss did not improve\n",
      "Epoch 617/2000\n",
      "2014/2014 [==============================] - 0s 37us/step - loss: 1.1248e-04\n",
      "\n",
      "Epoch 00617: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 618/2000\n",
      "2014/2014 [==============================] - 0s 36us/step - loss: 1.1236e-04\n",
      "\n",
      "Epoch 00618: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 619/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 1.1248e-04\n",
      "\n",
      "Epoch 00619: loss did not improve\n",
      "Epoch 620/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.1225e-04\n",
      "\n",
      "Epoch 00620: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 621/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1232e-04\n",
      "\n",
      "Epoch 00621: loss did not improve\n",
      "Epoch 622/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 1.1210e-04\n",
      "\n",
      "Epoch 00622: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 623/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1206e-04\n",
      "\n",
      "Epoch 00623: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 624/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.1214e-04\n",
      "\n",
      "Epoch 00624: loss did not improve\n",
      "Epoch 625/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.1197e-04\n",
      "\n",
      "Epoch 00625: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 626/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.1199e-04\n",
      "\n",
      "Epoch 00626: loss did not improve\n",
      "Epoch 627/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 1.1191e-04\n",
      "\n",
      "Epoch 00627: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 628/2000\n",
      "2014/2014 [==============================] - 0s 41us/step - loss: 1.1229e-04\n",
      "\n",
      "Epoch 00628: loss did not improve\n",
      "Epoch 629/2000\n",
      "2014/2014 [==============================] - 0s 36us/step - loss: 1.1196e-04\n",
      "\n",
      "Epoch 00629: loss did not improve\n",
      "Epoch 630/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 1.1197e-04\n",
      "\n",
      "Epoch 00630: loss did not improve\n",
      "Epoch 631/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 1.1190e-04\n",
      "\n",
      "Epoch 00631: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 632/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.1150e-04\n",
      "\n",
      "Epoch 00632: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 633/2000\n",
      "2014/2014 [==============================] - 0s 42us/step - loss: 1.1181e-04\n",
      "\n",
      "Epoch 00633: loss did not improve\n",
      "Epoch 634/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 1.1185e-04\n",
      "\n",
      "Epoch 00634: loss did not improve\n",
      "Epoch 635/2000\n",
      "2014/2014 [==============================] - 0s 36us/step - loss: 1.1171e-04\n",
      "\n",
      "Epoch 00635: loss did not improve\n",
      "Epoch 636/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 1.1131e-04\n",
      "\n",
      "Epoch 00636: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 637/2000\n",
      "2014/2014 [==============================] - 0s 38us/step - loss: 1.1150e-04\n",
      "\n",
      "Epoch 00637: loss did not improve\n",
      "Epoch 638/2000\n",
      "2014/2014 [==============================] - 0s 43us/step - loss: 1.1131e-04\n",
      "\n",
      "Epoch 00638: loss did not improve\n",
      "Epoch 639/2000\n",
      "2014/2014 [==============================] - 0s 40us/step - loss: 1.1133e-04\n",
      "\n",
      "Epoch 00639: loss did not improve\n",
      "Epoch 640/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 1.1133e-04\n",
      "\n",
      "Epoch 00640: loss did not improve\n",
      "Epoch 641/2000\n",
      "2014/2014 [==============================] - 0s 36us/step - loss: 1.1120e-04\n",
      "\n",
      "Epoch 00641: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 642/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 1.1124e-04\n",
      "\n",
      "Epoch 00642: loss did not improve\n",
      "Epoch 643/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.1116e-04\n",
      "\n",
      "Epoch 00643: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 644/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.1094e-04\n",
      "\n",
      "Epoch 00644: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 645/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 1.1083e-04\n",
      "\n",
      "Epoch 00645: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 646/2000\n",
      "2014/2014 [==============================] - 0s 36us/step - loss: 1.1076e-04\n",
      "\n",
      "Epoch 00646: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 647/2000\n",
      "2014/2014 [==============================] - 0s 40us/step - loss: 1.1075e-04\n",
      "\n",
      "Epoch 00647: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 648/2000\n",
      "2014/2014 [==============================] - 0s 37us/step - loss: 1.1068e-04\n",
      "\n",
      "Epoch 00648: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 649/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.1090e-04\n",
      "\n",
      "Epoch 00649: loss did not improve\n",
      "Epoch 650/2000\n",
      "2014/2014 [==============================] - 0s 40us/step - loss: 1.1060e-04\n",
      "\n",
      "Epoch 00650: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 651/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 1.1097e-04\n",
      "\n",
      "Epoch 00651: loss did not improve\n",
      "Epoch 652/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1168e-04\n",
      "\n",
      "Epoch 00652: loss did not improve\n",
      "Epoch 653/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.1130e-04\n",
      "\n",
      "Epoch 00653: loss did not improve\n",
      "Epoch 654/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1044e-04\n",
      "\n",
      "Epoch 00654: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 655/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.1041e-04\n",
      "\n",
      "Epoch 00655: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 656/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1045e-04\n",
      "\n",
      "Epoch 00656: loss did not improve\n",
      "Epoch 657/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1049e-04\n",
      "\n",
      "Epoch 00657: loss did not improve\n",
      "Epoch 658/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.1028e-04\n",
      "\n",
      "Epoch 00658: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 659/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.1019e-04\n",
      "\n",
      "Epoch 00659: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 660/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.1010e-04\n",
      "\n",
      "Epoch 00660: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 661/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.0998e-04\n",
      "\n",
      "Epoch 00661: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 662/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1004e-04\n",
      "\n",
      "Epoch 00662: loss did not improve\n",
      "Epoch 663/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.1007e-04\n",
      "\n",
      "Epoch 00663: loss did not improve\n",
      "Epoch 664/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.0979e-04\n",
      "\n",
      "Epoch 00664: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 665/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.1009e-04\n",
      "\n",
      "Epoch 00665: loss did not improve\n",
      "Epoch 666/2000\n",
      "2014/2014 [==============================] - 0s 37us/step - loss: 1.0965e-04\n",
      "\n",
      "Epoch 00666: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 667/2000\n",
      "2014/2014 [==============================] - 0s 36us/step - loss: 1.0985e-04\n",
      "\n",
      "Epoch 00667: loss did not improve\n",
      "Epoch 668/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 1.0985e-04\n",
      "\n",
      "Epoch 00668: loss did not improve\n",
      "Epoch 669/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 1.1023e-04\n",
      "\n",
      "Epoch 00669: loss did not improve\n",
      "Epoch 670/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.1039e-04\n",
      "\n",
      "Epoch 00670: loss did not improve\n",
      "Epoch 671/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 1.1069e-04\n",
      "\n",
      "Epoch 00671: loss did not improve\n",
      "Epoch 672/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 1.1190e-04\n",
      "\n",
      "Epoch 00672: loss did not improve\n",
      "Epoch 673/2000\n",
      "2014/2014 [==============================] - 0s 39us/step - loss: 1.1028e-04\n",
      "\n",
      "Epoch 00673: loss did not improve\n",
      "Epoch 674/2000\n",
      "2014/2014 [==============================] - 0s 39us/step - loss: 1.0970e-04\n",
      "\n",
      "Epoch 00674: loss did not improve\n",
      "Epoch 675/2000\n",
      "2014/2014 [==============================] - 0s 36us/step - loss: 1.0946e-04\n",
      "\n",
      "Epoch 00675: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 676/2000\n",
      "2014/2014 [==============================] - 0s 37us/step - loss: 1.0991e-04\n",
      "\n",
      "Epoch 00676: loss did not improve\n",
      "Epoch 677/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 1.0947e-04\n",
      "\n",
      "Epoch 00677: loss did not improve\n",
      "Epoch 678/2000\n",
      "2014/2014 [==============================] - 0s 41us/step - loss: 1.0904e-04\n",
      "\n",
      "Epoch 00678: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 679/2000\n",
      "2014/2014 [==============================] - 0s 38us/step - loss: 1.0920e-04\n",
      "\n",
      "Epoch 00679: loss did not improve\n",
      "Epoch 680/2000\n",
      "2014/2014 [==============================] - 0s 36us/step - loss: 1.0887e-04\n",
      "\n",
      "Epoch 00680: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 681/2000\n",
      "2014/2014 [==============================] - 0s 39us/step - loss: 1.0886e-04\n",
      "\n",
      "Epoch 00681: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 682/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 1.0935e-04\n",
      "\n",
      "Epoch 00682: loss did not improve\n",
      "Epoch 683/2000\n",
      "2014/2014 [==============================] - 0s 37us/step - loss: 1.0907e-04\n",
      "\n",
      "Epoch 00683: loss did not improve\n",
      "Epoch 684/2000\n",
      "2014/2014 [==============================] - 0s 37us/step - loss: 1.0894e-04\n",
      "\n",
      "Epoch 00684: loss did not improve\n",
      "Epoch 685/2000\n",
      "2014/2014 [==============================] - 0s 37us/step - loss: 1.0905e-04\n",
      "\n",
      "Epoch 00685: loss did not improve\n",
      "Epoch 686/2000\n",
      "2014/2014 [==============================] - 0s 36us/step - loss: 1.0874e-04\n",
      "\n",
      "Epoch 00686: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 687/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.0889e-04\n",
      "\n",
      "Epoch 00687: loss did not improve\n",
      "Epoch 688/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.1018e-04\n",
      "\n",
      "Epoch 00688: loss did not improve\n",
      "Epoch 689/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 1.0987e-04\n",
      "\n",
      "Epoch 00689: loss did not improve\n",
      "Epoch 690/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.1009e-04\n",
      "\n",
      "Epoch 00690: loss did not improve\n",
      "Epoch 691/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 1.0908e-04\n",
      "\n",
      "Epoch 00691: loss did not improve\n",
      "Epoch 692/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.0951e-04\n",
      "\n",
      "Epoch 00692: loss did not improve\n",
      "Epoch 693/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.0959e-04\n",
      "\n",
      "Epoch 00693: loss did not improve\n",
      "Epoch 694/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.0853e-04\n",
      "\n",
      "Epoch 00694: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 695/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.0851e-04\n",
      "\n",
      "Epoch 00695: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 696/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0816e-04\n",
      "\n",
      "Epoch 00696: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 697/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.0775e-04\n",
      "\n",
      "Epoch 00697: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 698/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 1.0759e-04\n",
      "\n",
      "Epoch 00698: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 699/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.0793e-04\n",
      "\n",
      "Epoch 00699: loss did not improve\n",
      "Epoch 700/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.0783e-04\n",
      "\n",
      "Epoch 00700: loss did not improve\n",
      "Epoch 701/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0783e-04\n",
      "\n",
      "Epoch 00701: loss did not improve\n",
      "Epoch 702/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.0758e-04\n",
      "\n",
      "Epoch 00702: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 703/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.0738e-04\n",
      "\n",
      "Epoch 00703: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 704/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.0718e-04\n",
      "\n",
      "Epoch 00704: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 705/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.0719e-04\n",
      "\n",
      "Epoch 00705: loss did not improve\n",
      "Epoch 706/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 1.0720e-04\n",
      "\n",
      "Epoch 00706: loss did not improve\n",
      "Epoch 707/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.0719e-04\n",
      "\n",
      "Epoch 00707: loss did not improve\n",
      "Epoch 708/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.0713e-04\n",
      "\n",
      "Epoch 00708: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 709/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0696e-04\n",
      "\n",
      "Epoch 00709: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 710/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.0704e-04\n",
      "\n",
      "Epoch 00710: loss did not improve\n",
      "Epoch 711/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.0664e-04\n",
      "\n",
      "Epoch 00711: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 712/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.0714e-04\n",
      "\n",
      "Epoch 00712: loss did not improve\n",
      "Epoch 713/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.0715e-04\n",
      "\n",
      "Epoch 00713: loss did not improve\n",
      "Epoch 714/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.0688e-04\n",
      "\n",
      "Epoch 00714: loss did not improve\n",
      "Epoch 715/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 1.0683e-04\n",
      "\n",
      "Epoch 00715: loss did not improve\n",
      "Epoch 716/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.0649e-04\n",
      "\n",
      "Epoch 00716: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 717/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.0637e-04\n",
      "\n",
      "Epoch 00717: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 718/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.0620e-04\n",
      "\n",
      "Epoch 00718: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 719/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 1.0725e-04\n",
      "\n",
      "Epoch 00719: loss did not improve\n",
      "Epoch 720/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.0705e-04\n",
      "\n",
      "Epoch 00720: loss did not improve\n",
      "Epoch 721/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.0677e-04\n",
      "\n",
      "Epoch 00721: loss did not improve\n",
      "Epoch 722/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0615e-04\n",
      "\n",
      "Epoch 00722: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 723/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 1.0590e-04\n",
      "\n",
      "Epoch 00723: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 724/2000\n",
      "2014/2014 [==============================] - 0s 38us/step - loss: 1.0595e-04\n",
      "\n",
      "Epoch 00724: loss did not improve\n",
      "Epoch 725/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.0598e-04\n",
      "\n",
      "Epoch 00725: loss did not improve\n",
      "Epoch 726/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0582e-04\n",
      "\n",
      "Epoch 00726: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 727/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.0579e-04\n",
      "\n",
      "Epoch 00727: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 728/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.0575e-04\n",
      "\n",
      "Epoch 00728: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 729/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0566e-04\n",
      "\n",
      "Epoch 00729: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 730/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0543e-04\n",
      "\n",
      "Epoch 00730: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 731/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0555e-04\n",
      "\n",
      "Epoch 00731: loss did not improve\n",
      "Epoch 732/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0582e-04\n",
      "\n",
      "Epoch 00732: loss did not improve\n",
      "Epoch 733/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.0529e-04\n",
      "\n",
      "Epoch 00733: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 734/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.0506e-04\n",
      "\n",
      "Epoch 00734: loss improved from 0.00011 to 0.00011, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 735/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.0531e-04\n",
      "\n",
      "Epoch 00735: loss did not improve\n",
      "Epoch 736/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.0513e-04\n",
      "\n",
      "Epoch 00736: loss did not improve\n",
      "Epoch 737/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.0538e-04\n",
      "\n",
      "Epoch 00737: loss did not improve\n",
      "Epoch 738/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.0508e-04\n",
      "\n",
      "Epoch 00738: loss did not improve\n",
      "Epoch 739/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0546e-04\n",
      "\n",
      "Epoch 00739: loss did not improve\n",
      "Epoch 740/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.0535e-04\n",
      "\n",
      "Epoch 00740: loss did not improve\n",
      "Epoch 741/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.0471e-04\n",
      "\n",
      "Epoch 00741: loss improved from 0.00011 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 742/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0456e-04\n",
      "\n",
      "Epoch 00742: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 743/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.0452e-04\n",
      "\n",
      "Epoch 00743: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 744/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.0458e-04\n",
      "\n",
      "Epoch 00744: loss did not improve\n",
      "Epoch 745/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.0474e-04\n",
      "\n",
      "Epoch 00745: loss did not improve\n",
      "Epoch 746/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0486e-04\n",
      "\n",
      "Epoch 00746: loss did not improve\n",
      "Epoch 747/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.0545e-04\n",
      "\n",
      "Epoch 00747: loss did not improve\n",
      "Epoch 748/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.0538e-04\n",
      "\n",
      "Epoch 00748: loss did not improve\n",
      "Epoch 749/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 1.0520e-04\n",
      "\n",
      "Epoch 00749: loss did not improve\n",
      "Epoch 750/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.0559e-04\n",
      "\n",
      "Epoch 00750: loss did not improve\n",
      "Epoch 751/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.0525e-04\n",
      "\n",
      "Epoch 00751: loss did not improve\n",
      "Epoch 752/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0415e-04\n",
      "\n",
      "Epoch 00752: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 753/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.0391e-04\n",
      "\n",
      "Epoch 00753: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 754/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.0364e-04\n",
      "\n",
      "Epoch 00754: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 755/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.0371e-04\n",
      "\n",
      "Epoch 00755: loss did not improve\n",
      "Epoch 756/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.0411e-04\n",
      "\n",
      "Epoch 00756: loss did not improve\n",
      "Epoch 757/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.0338e-04\n",
      "\n",
      "Epoch 00757: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 758/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0321e-04\n",
      "\n",
      "Epoch 00758: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 759/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0332e-04\n",
      "\n",
      "Epoch 00759: loss did not improve\n",
      "Epoch 760/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.0322e-04\n",
      "\n",
      "Epoch 00760: loss did not improve\n",
      "Epoch 761/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.0314e-04\n",
      "\n",
      "Epoch 00761: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 762/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.0310e-04\n",
      "\n",
      "Epoch 00762: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 763/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.0284e-04\n",
      "\n",
      "Epoch 00763: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 764/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.0285e-04\n",
      "\n",
      "Epoch 00764: loss did not improve\n",
      "Epoch 765/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.0300e-04\n",
      "\n",
      "Epoch 00765: loss did not improve\n",
      "Epoch 766/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.0256e-04\n",
      "\n",
      "Epoch 00766: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 767/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.0266e-04\n",
      "\n",
      "Epoch 00767: loss did not improve\n",
      "Epoch 768/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0287e-04\n",
      "\n",
      "Epoch 00768: loss did not improve\n",
      "Epoch 769/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0312e-04\n",
      "\n",
      "Epoch 00769: loss did not improve\n",
      "Epoch 770/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 1.0311e-04\n",
      "\n",
      "Epoch 00770: loss did not improve\n",
      "Epoch 771/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.0291e-04\n",
      "\n",
      "Epoch 00771: loss did not improve\n",
      "Epoch 772/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0256e-04\n",
      "\n",
      "Epoch 00772: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 773/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0245e-04\n",
      "\n",
      "Epoch 00773: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 774/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.0194e-04\n",
      "\n",
      "Epoch 00774: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 775/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.0177e-04\n",
      "\n",
      "Epoch 00775: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 776/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.0178e-04\n",
      "\n",
      "Epoch 00776: loss did not improve\n",
      "Epoch 777/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.0173e-04\n",
      "\n",
      "Epoch 00777: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 778/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 1.0185e-04\n",
      "\n",
      "Epoch 00778: loss did not improve\n",
      "Epoch 779/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0182e-04\n",
      "\n",
      "Epoch 00779: loss did not improve\n",
      "Epoch 780/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 1.0151e-04\n",
      "\n",
      "Epoch 00780: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 781/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0133e-04\n",
      "\n",
      "Epoch 00781: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 782/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.0127e-04\n",
      "\n",
      "Epoch 00782: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 783/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 1.0118e-04\n",
      "\n",
      "Epoch 00783: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 784/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.0100e-04\n",
      "\n",
      "Epoch 00784: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 785/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 1.0115e-04\n",
      "\n",
      "Epoch 00785: loss did not improve\n",
      "Epoch 786/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 1.0085e-04\n",
      "\n",
      "Epoch 00786: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 787/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0079e-04\n",
      "\n",
      "Epoch 00787: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 788/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0065e-04\n",
      "\n",
      "Epoch 00788: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 789/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 1.0072e-04\n",
      "\n",
      "Epoch 00789: loss did not improve\n",
      "Epoch 790/2000\n",
      "2014/2014 [==============================] - 0s 41us/step - loss: 1.0060e-04\n",
      "\n",
      "Epoch 00790: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 791/2000\n",
      "2014/2014 [==============================] - 0s 40us/step - loss: 1.0106e-04\n",
      "\n",
      "Epoch 00791: loss did not improve\n",
      "Epoch 792/2000\n",
      "2014/2014 [==============================] - 0s 44us/step - loss: 1.0026e-04\n",
      "\n",
      "Epoch 00792: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 793/2000\n",
      "2014/2014 [==============================] - 0s 41us/step - loss: 1.0060e-04\n",
      "\n",
      "Epoch 00793: loss did not improve\n",
      "Epoch 794/2000\n",
      "2014/2014 [==============================] - 0s 38us/step - loss: 1.0011e-04\n",
      "\n",
      "Epoch 00794: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 795/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 9.9983e-05\n",
      "\n",
      "Epoch 00795: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 796/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 1.0041e-04\n",
      "\n",
      "Epoch 00796: loss did not improve\n",
      "Epoch 797/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 1.0193e-04\n",
      "\n",
      "Epoch 00797: loss did not improve\n",
      "Epoch 798/2000\n",
      "2014/2014 [==============================] - 0s 41us/step - loss: 1.0109e-04\n",
      "\n",
      "Epoch 00798: loss did not improve\n",
      "Epoch 799/2000\n",
      "2014/2014 [==============================] - 0s 44us/step - loss: 1.0134e-04\n",
      "\n",
      "Epoch 00799: loss did not improve\n",
      "Epoch 800/2000\n",
      "2014/2014 [==============================] - 0s 39us/step - loss: 1.0197e-04\n",
      "\n",
      "Epoch 00800: loss did not improve\n",
      "Epoch 801/2000\n",
      "2014/2014 [==============================] - 0s 42us/step - loss: 1.0015e-04\n",
      "\n",
      "Epoch 00801: loss did not improve\n",
      "Epoch 802/2000\n",
      "2014/2014 [==============================] - 0s 39us/step - loss: 9.9526e-05\n",
      "\n",
      "Epoch 00802: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 803/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 1.0024e-04\n",
      "\n",
      "Epoch 00803: loss did not improve\n",
      "Epoch 804/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 9.9034e-05\n",
      "\n",
      "Epoch 00804: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 805/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 9.9067e-05\n",
      "\n",
      "Epoch 00805: loss did not improve\n",
      "Epoch 806/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 9.9890e-05\n",
      "\n",
      "Epoch 00806: loss did not improve\n",
      "Epoch 807/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 9.9192e-05\n",
      "\n",
      "Epoch 00807: loss did not improve\n",
      "Epoch 808/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 9.8902e-05\n",
      "\n",
      "Epoch 00808: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 809/2000\n",
      "2014/2014 [==============================] - 0s 44us/step - loss: 9.8983e-05\n",
      "\n",
      "Epoch 00809: loss did not improve\n",
      "Epoch 810/2000\n",
      "2014/2014 [==============================] - 0s 47us/step - loss: 9.8681e-05\n",
      "\n",
      "Epoch 00810: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 811/2000\n",
      "2014/2014 [==============================] - 0s 43us/step - loss: 9.8601e-05\n",
      "\n",
      "Epoch 00811: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 812/2000\n",
      "2014/2014 [==============================] - 0s 41us/step - loss: 9.9223e-05\n",
      "\n",
      "Epoch 00812: loss did not improve\n",
      "Epoch 813/2000\n",
      "2014/2014 [==============================] - 0s 54us/step - loss: 9.9148e-05\n",
      "\n",
      "Epoch 00813: loss did not improve\n",
      "Epoch 814/2000\n",
      "2014/2014 [==============================] - 0s 42us/step - loss: 9.8374e-05\n",
      "\n",
      "Epoch 00814: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 815/2000\n",
      "2014/2014 [==============================] - 0s 48us/step - loss: 9.8136e-05\n",
      "\n",
      "Epoch 00815: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 816/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 9.8143e-05\n",
      "\n",
      "Epoch 00816: loss did not improve\n",
      "Epoch 817/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 9.8101e-05\n",
      "\n",
      "Epoch 00817: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 818/2000\n",
      "2014/2014 [==============================] - 0s 25us/step - loss: 9.7733e-05\n",
      "\n",
      "Epoch 00818: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 819/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 9.7737e-05\n",
      "\n",
      "Epoch 00819: loss did not improve\n",
      "Epoch 820/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 9.8375e-05\n",
      "\n",
      "Epoch 00820: loss did not improve\n",
      "Epoch 821/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 9.7839e-05\n",
      "\n",
      "Epoch 00821: loss did not improve\n",
      "Epoch 822/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 9.8987e-05\n",
      "\n",
      "Epoch 00822: loss did not improve\n",
      "Epoch 823/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 9.7648e-05\n",
      "\n",
      "Epoch 00823: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 824/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 9.7574e-05\n",
      "\n",
      "Epoch 00824: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 825/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 9.7517e-05\n",
      "\n",
      "Epoch 00825: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 826/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 9.8520e-05\n",
      "\n",
      "Epoch 00826: loss did not improve\n",
      "Epoch 827/2000\n",
      "2014/2014 [==============================] - 0s 41us/step - loss: 9.8368e-05\n",
      "\n",
      "Epoch 00827: loss did not improve\n",
      "Epoch 828/2000\n",
      "2014/2014 [==============================] - 0s 46us/step - loss: 9.7616e-05\n",
      "\n",
      "Epoch 00828: loss did not improve\n",
      "Epoch 829/2000\n",
      "2014/2014 [==============================] - 0s 44us/step - loss: 9.7077e-05\n",
      "\n",
      "Epoch 00829: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 830/2000\n",
      "2014/2014 [==============================] - 0s 39us/step - loss: 9.6893e-05\n",
      "\n",
      "Epoch 00830: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 831/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 9.6358e-05\n",
      "\n",
      "Epoch 00831: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 832/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 9.6156e-05\n",
      "\n",
      "Epoch 00832: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 833/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 9.6163e-05\n",
      "\n",
      "Epoch 00833: loss did not improve\n",
      "Epoch 834/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 9.6110e-05\n",
      "\n",
      "Epoch 00834: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 835/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 9.7228e-05\n",
      "\n",
      "Epoch 00835: loss did not improve\n",
      "Epoch 836/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 9.5662e-05\n",
      "\n",
      "Epoch 00836: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 837/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 9.5952e-05\n",
      "\n",
      "Epoch 00837: loss did not improve\n",
      "Epoch 838/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 9.5624e-05\n",
      "\n",
      "Epoch 00838: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 839/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 9.6000e-05\n",
      "\n",
      "Epoch 00839: loss did not improve\n",
      "Epoch 840/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 9.6832e-05\n",
      "\n",
      "Epoch 00840: loss did not improve\n",
      "Epoch 841/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 9.5620e-05\n",
      "\n",
      "Epoch 00841: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 842/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 9.5637e-05\n",
      "\n",
      "Epoch 00842: loss did not improve\n",
      "Epoch 843/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 9.5836e-05\n",
      "\n",
      "Epoch 00843: loss did not improve\n",
      "Epoch 844/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 9.5040e-05\n",
      "\n",
      "Epoch 00844: loss improved from 0.00010 to 0.00010, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 845/2000\n",
      "2014/2014 [==============================] - 0s 41us/step - loss: 9.4606e-05\n",
      "\n",
      "Epoch 00845: loss improved from 0.00010 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 846/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 9.4503e-05\n",
      "\n",
      "Epoch 00846: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 847/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 9.4357e-05\n",
      "\n",
      "Epoch 00847: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 848/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 9.5716e-05\n",
      "\n",
      "Epoch 00848: loss did not improve\n",
      "Epoch 849/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 9.5392e-05\n",
      "\n",
      "Epoch 00849: loss did not improve\n",
      "Epoch 850/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 9.5060e-05\n",
      "\n",
      "Epoch 00850: loss did not improve\n",
      "Epoch 851/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 9.4075e-05\n",
      "\n",
      "Epoch 00851: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 852/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 9.3738e-05\n",
      "\n",
      "Epoch 00852: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 853/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 9.3862e-05\n",
      "\n",
      "Epoch 00853: loss did not improve\n",
      "Epoch 854/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 9.3711e-05\n",
      "\n",
      "Epoch 00854: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 855/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 29us/step - loss: 9.3499e-05\n",
      "\n",
      "Epoch 00855: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 856/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 9.3906e-05\n",
      "\n",
      "Epoch 00856: loss did not improve\n",
      "Epoch 857/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 9.3973e-05\n",
      "\n",
      "Epoch 00857: loss did not improve\n",
      "Epoch 858/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 9.4694e-05\n",
      "\n",
      "Epoch 00858: loss did not improve\n",
      "Epoch 859/2000\n",
      "2014/2014 [==============================] - 0s 36us/step - loss: 9.4999e-05\n",
      "\n",
      "Epoch 00859: loss did not improve\n",
      "Epoch 860/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 9.3088e-05\n",
      "\n",
      "Epoch 00860: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 861/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 9.4083e-05\n",
      "\n",
      "Epoch 00861: loss did not improve\n",
      "Epoch 862/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 9.3078e-05\n",
      "\n",
      "Epoch 00862: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 863/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 9.2687e-05\n",
      "\n",
      "Epoch 00863: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 864/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 9.2508e-05\n",
      "\n",
      "Epoch 00864: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 865/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 9.2212e-05\n",
      "\n",
      "Epoch 00865: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 866/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 9.2139e-05\n",
      "\n",
      "Epoch 00866: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 867/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 9.1855e-05\n",
      "\n",
      "Epoch 00867: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 868/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 9.1793e-05\n",
      "\n",
      "Epoch 00868: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 869/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 9.2077e-05\n",
      "\n",
      "Epoch 00869: loss did not improve\n",
      "Epoch 870/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 9.3091e-05\n",
      "\n",
      "Epoch 00870: loss did not improve\n",
      "Epoch 871/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 9.2764e-05\n",
      "\n",
      "Epoch 00871: loss did not improve\n",
      "Epoch 872/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 9.2459e-05\n",
      "\n",
      "Epoch 00872: loss did not improve\n",
      "Epoch 873/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 9.2063e-05\n",
      "\n",
      "Epoch 00873: loss did not improve\n",
      "Epoch 874/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 9.1538e-05\n",
      "\n",
      "Epoch 00874: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 875/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 9.2714e-05\n",
      "\n",
      "Epoch 00875: loss did not improve\n",
      "Epoch 876/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 9.1528e-05\n",
      "\n",
      "Epoch 00876: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 877/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 9.1355e-05\n",
      "\n",
      "Epoch 00877: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 878/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 9.2520e-05\n",
      "\n",
      "Epoch 00878: loss did not improve\n",
      "Epoch 879/2000\n",
      "2014/2014 [==============================] - 0s 37us/step - loss: 9.0345e-05\n",
      "\n",
      "Epoch 00879: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 880/2000\n",
      "2014/2014 [==============================] - 0s 36us/step - loss: 9.0287e-05\n",
      "\n",
      "Epoch 00880: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 881/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 9.0550e-05\n",
      "\n",
      "Epoch 00881: loss did not improve\n",
      "Epoch 882/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 9.0687e-05\n",
      "\n",
      "Epoch 00882: loss did not improve\n",
      "Epoch 883/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 9.0044e-05\n",
      "\n",
      "Epoch 00883: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 884/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 8.9847e-05\n",
      "\n",
      "Epoch 00884: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 885/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 9.0229e-05\n",
      "\n",
      "Epoch 00885: loss did not improve\n",
      "Epoch 886/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 9.1153e-05\n",
      "\n",
      "Epoch 00886: loss did not improve\n",
      "Epoch 887/2000\n",
      "2014/2014 [==============================] - 0s 37us/step - loss: 9.2855e-05\n",
      "\n",
      "Epoch 00887: loss did not improve\n",
      "Epoch 888/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 9.3083e-05\n",
      "\n",
      "Epoch 00888: loss did not improve\n",
      "Epoch 889/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 9.2118e-05\n",
      "\n",
      "Epoch 00889: loss did not improve\n",
      "Epoch 890/2000\n",
      "2014/2014 [==============================] - 0s 42us/step - loss: 9.0969e-05\n",
      "\n",
      "Epoch 00890: loss did not improve\n",
      "Epoch 891/2000\n",
      "2014/2014 [==============================] - 0s 36us/step - loss: 8.9733e-05\n",
      "\n",
      "Epoch 00891: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 892/2000\n",
      "2014/2014 [==============================] - 0s 43us/step - loss: 8.8513e-05\n",
      "\n",
      "Epoch 00892: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 893/2000\n",
      "2014/2014 [==============================] - 0s 42us/step - loss: 8.8536e-05\n",
      "\n",
      "Epoch 00893: loss did not improve\n",
      "Epoch 894/2000\n",
      "2014/2014 [==============================] - 0s 40us/step - loss: 8.8511e-05\n",
      "\n",
      "Epoch 00894: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 895/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 8.8941e-05\n",
      "\n",
      "Epoch 00895: loss did not improve\n",
      "Epoch 896/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 8.8999e-05\n",
      "\n",
      "Epoch 00896: loss did not improve\n",
      "Epoch 897/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 8.8410e-05\n",
      "\n",
      "Epoch 00897: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 898/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.7819e-05\n",
      "\n",
      "Epoch 00898: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 899/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.7977e-05\n",
      "\n",
      "Epoch 00899: loss did not improve\n",
      "Epoch 900/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 8.7552e-05\n",
      "\n",
      "Epoch 00900: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 901/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.7800e-05\n",
      "\n",
      "Epoch 00901: loss did not improve\n",
      "Epoch 902/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.8362e-05\n",
      "\n",
      "Epoch 00902: loss did not improve\n",
      "Epoch 903/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 8.7624e-05\n",
      "\n",
      "Epoch 00903: loss did not improve\n",
      "Epoch 904/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 8.9641e-05\n",
      "\n",
      "Epoch 00904: loss did not improve\n",
      "Epoch 905/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.7429e-05\n",
      "\n",
      "Epoch 00905: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 906/2000\n",
      "2014/2014 [==============================] - 0s 41us/step - loss: 8.7863e-05\n",
      "\n",
      "Epoch 00906: loss did not improve\n",
      "Epoch 907/2000\n",
      "2014/2014 [==============================] - 0s 41us/step - loss: 8.7015e-05\n",
      "\n",
      "Epoch 00907: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 908/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 34us/step - loss: 8.6419e-05\n",
      "\n",
      "Epoch 00908: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 909/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.6793e-05\n",
      "\n",
      "Epoch 00909: loss did not improve\n",
      "Epoch 910/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 8.6562e-05\n",
      "\n",
      "Epoch 00910: loss did not improve\n",
      "Epoch 911/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.6126e-05\n",
      "\n",
      "Epoch 00911: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 912/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.6676e-05\n",
      "\n",
      "Epoch 00912: loss did not improve\n",
      "Epoch 913/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 8.6167e-05\n",
      "\n",
      "Epoch 00913: loss did not improve\n",
      "Epoch 914/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 8.5972e-05\n",
      "\n",
      "Epoch 00914: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 915/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 8.5604e-05\n",
      "\n",
      "Epoch 00915: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 916/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.5575e-05\n",
      "\n",
      "Epoch 00916: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 917/2000\n",
      "2014/2014 [==============================] - 0s 41us/step - loss: 8.9800e-05\n",
      "\n",
      "Epoch 00917: loss did not improve\n",
      "Epoch 918/2000\n",
      "2014/2014 [==============================] - 0s 81us/step - loss: 8.7571e-05\n",
      "\n",
      "Epoch 00918: loss did not improve\n",
      "Epoch 919/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 9.0040e-05\n",
      "\n",
      "Epoch 00919: loss did not improve\n",
      "Epoch 920/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 8.9217e-05\n",
      "\n",
      "Epoch 00920: loss did not improve\n",
      "Epoch 921/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 8.9010e-05\n",
      "\n",
      "Epoch 00921: loss did not improve\n",
      "Epoch 922/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.6750e-05\n",
      "\n",
      "Epoch 00922: loss did not improve\n",
      "Epoch 923/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 8.8148e-05\n",
      "\n",
      "Epoch 00923: loss did not improve\n",
      "Epoch 924/2000\n",
      "2014/2014 [==============================] - 0s 36us/step - loss: 8.5901e-05\n",
      "\n",
      "Epoch 00924: loss did not improve\n",
      "Epoch 925/2000\n",
      "2014/2014 [==============================] - 0s 38us/step - loss: 8.5703e-05\n",
      "\n",
      "Epoch 00925: loss did not improve\n",
      "Epoch 926/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 8.5483e-05\n",
      "\n",
      "Epoch 00926: loss improved from 0.00009 to 0.00009, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 927/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.4233e-05\n",
      "\n",
      "Epoch 00927: loss improved from 0.00009 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 928/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 8.4669e-05\n",
      "\n",
      "Epoch 00928: loss did not improve\n",
      "Epoch 929/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 8.4526e-05\n",
      "\n",
      "Epoch 00929: loss did not improve\n",
      "Epoch 930/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 8.4340e-05\n",
      "\n",
      "Epoch 00930: loss did not improve\n",
      "Epoch 931/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 9.1499e-05\n",
      "\n",
      "Epoch 00931: loss did not improve\n",
      "Epoch 932/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 8.6729e-05\n",
      "\n",
      "Epoch 00932: loss did not improve\n",
      "Epoch 933/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 8.4243e-05\n",
      "\n",
      "Epoch 00933: loss did not improve\n",
      "Epoch 934/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 8.3175e-05\n",
      "\n",
      "Epoch 00934: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 935/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.3857e-05\n",
      "\n",
      "Epoch 00935: loss did not improve\n",
      "Epoch 936/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.4219e-05\n",
      "\n",
      "Epoch 00936: loss did not improve\n",
      "Epoch 937/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.3084e-05\n",
      "\n",
      "Epoch 00937: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 938/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 8.6368e-05\n",
      "\n",
      "Epoch 00938: loss did not improve\n",
      "Epoch 939/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.5555e-05\n",
      "\n",
      "Epoch 00939: loss did not improve\n",
      "Epoch 940/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.6184e-05\n",
      "\n",
      "Epoch 00940: loss did not improve\n",
      "Epoch 941/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.4150e-05\n",
      "\n",
      "Epoch 00941: loss did not improve\n",
      "Epoch 942/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 8.2972e-05\n",
      "\n",
      "Epoch 00942: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 943/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 8.2443e-05\n",
      "\n",
      "Epoch 00943: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 944/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 8.2189e-05\n",
      "\n",
      "Epoch 00944: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 945/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.2869e-05\n",
      "\n",
      "Epoch 00945: loss did not improve\n",
      "Epoch 946/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 8.3156e-05\n",
      "\n",
      "Epoch 00946: loss did not improve\n",
      "Epoch 947/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.1939e-05\n",
      "\n",
      "Epoch 00947: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 948/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 8.2011e-05\n",
      "\n",
      "Epoch 00948: loss did not improve\n",
      "Epoch 949/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 8.2065e-05\n",
      "\n",
      "Epoch 00949: loss did not improve\n",
      "Epoch 950/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 8.1493e-05\n",
      "\n",
      "Epoch 00950: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 951/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 8.1517e-05\n",
      "\n",
      "Epoch 00951: loss did not improve\n",
      "Epoch 952/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 8.1229e-05\n",
      "\n",
      "Epoch 00952: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 953/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 8.1098e-05\n",
      "\n",
      "Epoch 00953: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 954/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 8.2426e-05\n",
      "\n",
      "Epoch 00954: loss did not improve\n",
      "Epoch 955/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 8.1566e-05\n",
      "\n",
      "Epoch 00955: loss did not improve\n",
      "Epoch 956/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 8.1969e-05\n",
      "\n",
      "Epoch 00956: loss did not improve\n",
      "Epoch 957/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 8.0713e-05\n",
      "\n",
      "Epoch 00957: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 958/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 8.1099e-05\n",
      "\n",
      "Epoch 00958: loss did not improve\n",
      "Epoch 959/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 8.1369e-05\n",
      "\n",
      "Epoch 00959: loss did not improve\n",
      "Epoch 960/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 8.0505e-05\n",
      "\n",
      "Epoch 00960: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 961/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 8.0260e-05\n",
      "\n",
      "Epoch 00961: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 962/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 8.1073e-05\n",
      "\n",
      "Epoch 00962: loss did not improve\n",
      "Epoch 963/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 8.1114e-05\n",
      "\n",
      "Epoch 00963: loss did not improve\n",
      "Epoch 964/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.2153e-05\n",
      "\n",
      "Epoch 00964: loss did not improve\n",
      "Epoch 965/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 8.1659e-05\n",
      "\n",
      "Epoch 00965: loss did not improve\n",
      "Epoch 966/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 8.1814e-05\n",
      "\n",
      "Epoch 00966: loss did not improve\n",
      "Epoch 967/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 8.2799e-05\n",
      "\n",
      "Epoch 00967: loss did not improve\n",
      "Epoch 968/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 8.1688e-05\n",
      "\n",
      "Epoch 00968: loss did not improve\n",
      "Epoch 969/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 7.9326e-05\n",
      "\n",
      "Epoch 00969: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 970/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.9537e-05\n",
      "\n",
      "Epoch 00970: loss did not improve\n",
      "Epoch 971/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 8.1333e-05\n",
      "\n",
      "Epoch 00971: loss did not improve\n",
      "Epoch 972/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 8.0406e-05\n",
      "\n",
      "Epoch 00972: loss did not improve\n",
      "Epoch 973/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.0347e-05\n",
      "\n",
      "Epoch 00973: loss did not improve\n",
      "Epoch 974/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 7.9774e-05\n",
      "\n",
      "Epoch 00974: loss did not improve\n",
      "Epoch 975/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.9299e-05\n",
      "\n",
      "Epoch 00975: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 976/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 8.1430e-05\n",
      "\n",
      "Epoch 00976: loss did not improve\n",
      "Epoch 977/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.9348e-05\n",
      "\n",
      "Epoch 00977: loss did not improve\n",
      "Epoch 978/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.9385e-05\n",
      "\n",
      "Epoch 00978: loss did not improve\n",
      "Epoch 979/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.0025e-05\n",
      "\n",
      "Epoch 00979: loss did not improve\n",
      "Epoch 980/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.9204e-05\n",
      "\n",
      "Epoch 00980: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 981/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.9225e-05\n",
      "\n",
      "Epoch 00981: loss did not improve\n",
      "Epoch 982/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.8813e-05\n",
      "\n",
      "Epoch 00982: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 983/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.9422e-05\n",
      "\n",
      "Epoch 00983: loss did not improve\n",
      "Epoch 984/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 8.1924e-05\n",
      "\n",
      "Epoch 00984: loss did not improve\n",
      "Epoch 985/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.0878e-05\n",
      "\n",
      "Epoch 00985: loss did not improve\n",
      "Epoch 986/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.0951e-05\n",
      "\n",
      "Epoch 00986: loss did not improve\n",
      "Epoch 987/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.9406e-05\n",
      "\n",
      "Epoch 00987: loss did not improve\n",
      "Epoch 988/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 7.9001e-05\n",
      "\n",
      "Epoch 00988: loss did not improve\n",
      "Epoch 989/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.0106e-05\n",
      "\n",
      "Epoch 00989: loss did not improve\n",
      "Epoch 990/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.8570e-05\n",
      "\n",
      "Epoch 00990: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 991/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 7.9010e-05\n",
      "\n",
      "Epoch 00991: loss did not improve\n",
      "Epoch 992/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.8470e-05\n",
      "\n",
      "Epoch 00992: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 993/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.8105e-05\n",
      "\n",
      "Epoch 00993: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 994/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 7.7414e-05\n",
      "\n",
      "Epoch 00994: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 995/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 7.7621e-05\n",
      "\n",
      "Epoch 00995: loss did not improve\n",
      "Epoch 996/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.7507e-05\n",
      "\n",
      "Epoch 00996: loss did not improve\n",
      "Epoch 997/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.7289e-05\n",
      "\n",
      "Epoch 00997: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 998/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 7.7453e-05\n",
      "\n",
      "Epoch 00998: loss did not improve\n",
      "Epoch 999/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.8964e-05\n",
      "\n",
      "Epoch 00999: loss did not improve\n",
      "Epoch 1000/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.0813e-05\n",
      "\n",
      "Epoch 01000: loss did not improve\n",
      "Epoch 1001/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 8.3030e-05\n",
      "\n",
      "Epoch 01001: loss did not improve\n",
      "Epoch 1002/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.9155e-05\n",
      "\n",
      "Epoch 01002: loss did not improve\n",
      "Epoch 1003/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.7745e-05\n",
      "\n",
      "Epoch 01003: loss did not improve\n",
      "Epoch 1004/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 7.7480e-05\n",
      "\n",
      "Epoch 01004: loss did not improve\n",
      "Epoch 1005/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.7750e-05\n",
      "\n",
      "Epoch 01005: loss did not improve\n",
      "Epoch 1006/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.7298e-05\n",
      "\n",
      "Epoch 01006: loss did not improve\n",
      "Epoch 1007/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.7921e-05\n",
      "\n",
      "Epoch 01007: loss did not improve\n",
      "Epoch 1008/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.7463e-05\n",
      "\n",
      "Epoch 01008: loss did not improve\n",
      "Epoch 1009/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.7266e-05\n",
      "\n",
      "Epoch 01009: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1010/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.7515e-05\n",
      "\n",
      "Epoch 01010: loss did not improve\n",
      "Epoch 1011/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.6575e-05\n",
      "\n",
      "Epoch 01011: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1012/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.8191e-05\n",
      "\n",
      "Epoch 01012: loss did not improve\n",
      "Epoch 1013/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 8.2063e-05\n",
      "\n",
      "Epoch 01013: loss did not improve\n",
      "Epoch 1014/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.9253e-05\n",
      "\n",
      "Epoch 01014: loss did not improve\n",
      "Epoch 1015/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 8.2894e-05\n",
      "\n",
      "Epoch 01015: loss did not improve\n",
      "Epoch 1016/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 8.2936e-05\n",
      "\n",
      "Epoch 01016: loss did not improve\n",
      "Epoch 1017/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 7.8417e-05\n",
      "\n",
      "Epoch 01017: loss did not improve\n",
      "Epoch 1018/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 8.2085e-05\n",
      "\n",
      "Epoch 01018: loss did not improve\n",
      "Epoch 1019/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 8.1296e-05\n",
      "\n",
      "Epoch 01019: loss did not improve\n",
      "Epoch 1020/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 8.1901e-05\n",
      "\n",
      "Epoch 01020: loss did not improve\n",
      "Epoch 1021/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.8661e-05\n",
      "\n",
      "Epoch 01021: loss did not improve\n",
      "Epoch 1022/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.8831e-05\n",
      "\n",
      "Epoch 01022: loss did not improve\n",
      "Epoch 1023/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 27us/step - loss: 8.0738e-05\n",
      "\n",
      "Epoch 01023: loss did not improve\n",
      "Epoch 1024/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.8640e-05\n",
      "\n",
      "Epoch 01024: loss did not improve\n",
      "Epoch 1025/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 7.9663e-05\n",
      "\n",
      "Epoch 01025: loss did not improve\n",
      "Epoch 1026/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.7475e-05\n",
      "\n",
      "Epoch 01026: loss did not improve\n",
      "Epoch 1027/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 7.5707e-05\n",
      "\n",
      "Epoch 01027: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1028/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.5481e-05\n",
      "\n",
      "Epoch 01028: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1029/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.7699e-05\n",
      "\n",
      "Epoch 01029: loss did not improve\n",
      "Epoch 1030/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.9429e-05\n",
      "\n",
      "Epoch 01030: loss did not improve\n",
      "Epoch 1031/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.8410e-05\n",
      "\n",
      "Epoch 01031: loss did not improve\n",
      "Epoch 1032/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 7.6939e-05\n",
      "\n",
      "Epoch 01032: loss did not improve\n",
      "Epoch 1033/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.5472e-05\n",
      "\n",
      "Epoch 01033: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1034/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 7.6474e-05\n",
      "\n",
      "Epoch 01034: loss did not improve\n",
      "Epoch 1035/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 7.5566e-05\n",
      "\n",
      "Epoch 01035: loss did not improve\n",
      "Epoch 1036/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.5383e-05\n",
      "\n",
      "Epoch 01036: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1037/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.5122e-05\n",
      "\n",
      "Epoch 01037: loss improved from 0.00008 to 0.00008, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1038/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.5157e-05\n",
      "\n",
      "Epoch 01038: loss did not improve\n",
      "Epoch 1039/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 7.4857e-05\n",
      "\n",
      "Epoch 01039: loss improved from 0.00008 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1040/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.4763e-05\n",
      "\n",
      "Epoch 01040: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1041/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.5247e-05\n",
      "\n",
      "Epoch 01041: loss did not improve\n",
      "Epoch 1042/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.5073e-05\n",
      "\n",
      "Epoch 01042: loss did not improve\n",
      "Epoch 1043/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.4882e-05\n",
      "\n",
      "Epoch 01043: loss did not improve\n",
      "Epoch 1044/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.4974e-05\n",
      "\n",
      "Epoch 01044: loss did not improve\n",
      "Epoch 1045/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.6063e-05\n",
      "\n",
      "Epoch 01045: loss did not improve\n",
      "Epoch 1046/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.4346e-05\n",
      "\n",
      "Epoch 01046: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1047/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.5010e-05\n",
      "\n",
      "Epoch 01047: loss did not improve\n",
      "Epoch 1048/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 7.5658e-05\n",
      "\n",
      "Epoch 01048: loss did not improve\n",
      "Epoch 1049/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.4764e-05\n",
      "\n",
      "Epoch 01049: loss did not improve\n",
      "Epoch 1050/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 7.5011e-05\n",
      "\n",
      "Epoch 01050: loss did not improve\n",
      "Epoch 1051/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 7.5800e-05\n",
      "\n",
      "Epoch 01051: loss did not improve\n",
      "Epoch 1052/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.6093e-05\n",
      "\n",
      "Epoch 01052: loss did not improve\n",
      "Epoch 1053/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 8.0513e-05\n",
      "\n",
      "Epoch 01053: loss did not improve\n",
      "Epoch 1054/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.9840e-05\n",
      "\n",
      "Epoch 01054: loss did not improve\n",
      "Epoch 1055/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.6904e-05\n",
      "\n",
      "Epoch 01055: loss did not improve\n",
      "Epoch 1056/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 7.6940e-05\n",
      "\n",
      "Epoch 01056: loss did not improve\n",
      "Epoch 1057/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.8896e-05\n",
      "\n",
      "Epoch 01057: loss did not improve\n",
      "Epoch 1058/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.5913e-05\n",
      "\n",
      "Epoch 01058: loss did not improve\n",
      "Epoch 1059/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.7783e-05\n",
      "\n",
      "Epoch 01059: loss did not improve\n",
      "Epoch 1060/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 7.6041e-05\n",
      "\n",
      "Epoch 01060: loss did not improve\n",
      "Epoch 1061/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.5633e-05\n",
      "\n",
      "Epoch 01061: loss did not improve\n",
      "Epoch 1062/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 7.4614e-05\n",
      "\n",
      "Epoch 01062: loss did not improve\n",
      "Epoch 1063/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.4512e-05\n",
      "\n",
      "Epoch 01063: loss did not improve\n",
      "Epoch 1064/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 7.5766e-05\n",
      "\n",
      "Epoch 01064: loss did not improve\n",
      "Epoch 1065/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 7.6966e-05\n",
      "\n",
      "Epoch 01065: loss did not improve\n",
      "Epoch 1066/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.4652e-05\n",
      "\n",
      "Epoch 01066: loss did not improve\n",
      "Epoch 1067/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.6122e-05\n",
      "\n",
      "Epoch 01067: loss did not improve\n",
      "Epoch 1068/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.3971e-05\n",
      "\n",
      "Epoch 01068: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1069/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.4122e-05\n",
      "\n",
      "Epoch 01069: loss did not improve\n",
      "Epoch 1070/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 7.3919e-05\n",
      "\n",
      "Epoch 01070: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1071/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.3443e-05\n",
      "\n",
      "Epoch 01071: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1072/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 7.3463e-05\n",
      "\n",
      "Epoch 01072: loss did not improve\n",
      "Epoch 1073/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.3208e-05\n",
      "\n",
      "Epoch 01073: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1074/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.5016e-05\n",
      "\n",
      "Epoch 01074: loss did not improve\n",
      "Epoch 1075/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.5022e-05\n",
      "\n",
      "Epoch 01075: loss did not improve\n",
      "Epoch 1076/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.3600e-05\n",
      "\n",
      "Epoch 01076: loss did not improve\n",
      "Epoch 1077/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.3200e-05\n",
      "\n",
      "Epoch 01077: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1078/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.3678e-05\n",
      "\n",
      "Epoch 01078: loss did not improve\n",
      "Epoch 1079/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.2960e-05\n",
      "\n",
      "Epoch 01079: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1080/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.3960e-05\n",
      "\n",
      "Epoch 01080: loss did not improve\n",
      "Epoch 1081/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 7.5243e-05\n",
      "\n",
      "Epoch 01081: loss did not improve\n",
      "Epoch 1082/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.3483e-05\n",
      "\n",
      "Epoch 01082: loss did not improve\n",
      "Epoch 1083/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 7.6580e-05\n",
      "\n",
      "Epoch 01083: loss did not improve\n",
      "Epoch 1084/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.5463e-05\n",
      "\n",
      "Epoch 01084: loss did not improve\n",
      "Epoch 1085/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.2874e-05\n",
      "\n",
      "Epoch 01085: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1086/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.3708e-05\n",
      "\n",
      "Epoch 01086: loss did not improve\n",
      "Epoch 1087/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.3770e-05\n",
      "\n",
      "Epoch 01087: loss did not improve\n",
      "Epoch 1088/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.3118e-05\n",
      "\n",
      "Epoch 01088: loss did not improve\n",
      "Epoch 1089/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.2403e-05\n",
      "\n",
      "Epoch 01089: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1090/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.3074e-05\n",
      "\n",
      "Epoch 01090: loss did not improve\n",
      "Epoch 1091/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 7.3008e-05\n",
      "\n",
      "Epoch 01091: loss did not improve\n",
      "Epoch 1092/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.3485e-05\n",
      "\n",
      "Epoch 01092: loss did not improve\n",
      "Epoch 1093/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.3116e-05\n",
      "\n",
      "Epoch 01093: loss did not improve\n",
      "Epoch 1094/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.2282e-05\n",
      "\n",
      "Epoch 01094: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1095/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 7.2508e-05\n",
      "\n",
      "Epoch 01095: loss did not improve\n",
      "Epoch 1096/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 7.2889e-05\n",
      "\n",
      "Epoch 01096: loss did not improve\n",
      "Epoch 1097/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 7.2978e-05\n",
      "\n",
      "Epoch 01097: loss did not improve\n",
      "Epoch 1098/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 7.2800e-05\n",
      "\n",
      "Epoch 01098: loss did not improve\n",
      "Epoch 1099/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 7.2879e-05\n",
      "\n",
      "Epoch 01099: loss did not improve\n",
      "Epoch 1100/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 7.2021e-05\n",
      "\n",
      "Epoch 01100: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1101/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.1827e-05\n",
      "\n",
      "Epoch 01101: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1102/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.2235e-05\n",
      "\n",
      "Epoch 01102: loss did not improve\n",
      "Epoch 1103/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 7.1968e-05\n",
      "\n",
      "Epoch 01103: loss did not improve\n",
      "Epoch 1104/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.1817e-05\n",
      "\n",
      "Epoch 01104: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1105/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.3567e-05\n",
      "\n",
      "Epoch 01105: loss did not improve\n",
      "Epoch 1106/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.2020e-05\n",
      "\n",
      "Epoch 01106: loss did not improve\n",
      "Epoch 1107/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.4020e-05\n",
      "\n",
      "Epoch 01107: loss did not improve\n",
      "Epoch 1108/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.3882e-05\n",
      "\n",
      "Epoch 01108: loss did not improve\n",
      "Epoch 1109/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.2539e-05\n",
      "\n",
      "Epoch 01109: loss did not improve\n",
      "Epoch 1110/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 7.1701e-05\n",
      "\n",
      "Epoch 01110: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1111/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.2191e-05\n",
      "\n",
      "Epoch 01111: loss did not improve\n",
      "Epoch 1112/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.1695e-05\n",
      "\n",
      "Epoch 01112: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1113/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 7.1403e-05\n",
      "\n",
      "Epoch 01113: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1114/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.1328e-05\n",
      "\n",
      "Epoch 01114: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1115/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.1878e-05\n",
      "\n",
      "Epoch 01115: loss did not improve\n",
      "Epoch 1116/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.1433e-05\n",
      "\n",
      "Epoch 01116: loss did not improve\n",
      "Epoch 1117/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.1487e-05\n",
      "\n",
      "Epoch 01117: loss did not improve\n",
      "Epoch 1118/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.1402e-05\n",
      "\n",
      "Epoch 01118: loss did not improve\n",
      "Epoch 1119/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.1479e-05\n",
      "\n",
      "Epoch 01119: loss did not improve\n",
      "Epoch 1120/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.1387e-05\n",
      "\n",
      "Epoch 01120: loss did not improve\n",
      "Epoch 1121/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.1644e-05\n",
      "\n",
      "Epoch 01121: loss did not improve\n",
      "Epoch 1122/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.2251e-05\n",
      "\n",
      "Epoch 01122: loss did not improve\n",
      "Epoch 1123/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.2265e-05\n",
      "\n",
      "Epoch 01123: loss did not improve\n",
      "Epoch 1124/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.3648e-05\n",
      "\n",
      "Epoch 01124: loss did not improve\n",
      "Epoch 1125/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.2256e-05\n",
      "\n",
      "Epoch 01125: loss did not improve\n",
      "Epoch 1126/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.3070e-05\n",
      "\n",
      "Epoch 01126: loss did not improve\n",
      "Epoch 1127/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.2252e-05\n",
      "\n",
      "Epoch 01127: loss did not improve\n",
      "Epoch 1128/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.2961e-05\n",
      "\n",
      "Epoch 01128: loss did not improve\n",
      "Epoch 1129/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.2743e-05\n",
      "\n",
      "Epoch 01129: loss did not improve\n",
      "Epoch 1130/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 7.2196e-05\n",
      "\n",
      "Epoch 01130: loss did not improve\n",
      "Epoch 1131/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.0741e-05\n",
      "\n",
      "Epoch 01131: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1132/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.0692e-05\n",
      "\n",
      "Epoch 01132: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1133/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 7.0641e-05\n",
      "\n",
      "Epoch 01133: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1134/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.0639e-05\n",
      "\n",
      "Epoch 01134: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1135/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.1154e-05\n",
      "\n",
      "Epoch 01135: loss did not improve\n",
      "Epoch 1136/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.1516e-05\n",
      "\n",
      "Epoch 01136: loss did not improve\n",
      "Epoch 1137/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.1124e-05\n",
      "\n",
      "Epoch 01137: loss did not improve\n",
      "Epoch 1138/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 7.0837e-05\n",
      "\n",
      "Epoch 01138: loss did not improve\n",
      "Epoch 1139/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.0728e-05\n",
      "\n",
      "Epoch 01139: loss did not improve\n",
      "Epoch 1140/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.0506e-05\n",
      "\n",
      "Epoch 01140: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1141/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.0465e-05\n",
      "\n",
      "Epoch 01141: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1142/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 7.1102e-05\n",
      "\n",
      "Epoch 01142: loss did not improve\n",
      "Epoch 1143/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.1151e-05\n",
      "\n",
      "Epoch 01143: loss did not improve\n",
      "Epoch 1144/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.0817e-05\n",
      "\n",
      "Epoch 01144: loss did not improve\n",
      "Epoch 1145/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.1120e-05\n",
      "\n",
      "Epoch 01145: loss did not improve\n",
      "Epoch 1146/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.0492e-05\n",
      "\n",
      "Epoch 01146: loss did not improve\n",
      "Epoch 1147/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.0817e-05\n",
      "\n",
      "Epoch 01147: loss did not improve\n",
      "Epoch 1148/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 7.0479e-05\n",
      "\n",
      "Epoch 01148: loss did not improve\n",
      "Epoch 1149/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.0491e-05\n",
      "\n",
      "Epoch 01149: loss did not improve\n",
      "Epoch 1150/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.0426e-05\n",
      "\n",
      "Epoch 01150: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1151/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.4917e-05\n",
      "\n",
      "Epoch 01151: loss did not improve\n",
      "Epoch 1152/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.1376e-05\n",
      "\n",
      "Epoch 01152: loss did not improve\n",
      "Epoch 1153/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.1212e-05\n",
      "\n",
      "Epoch 01153: loss did not improve\n",
      "Epoch 1154/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.3353e-05\n",
      "\n",
      "Epoch 01154: loss did not improve\n",
      "Epoch 1155/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.2014e-05\n",
      "\n",
      "Epoch 01155: loss did not improve\n",
      "Epoch 1156/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.1590e-05\n",
      "\n",
      "Epoch 01156: loss did not improve\n",
      "Epoch 1157/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.1261e-05\n",
      "\n",
      "Epoch 01157: loss did not improve\n",
      "Epoch 1158/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.1861e-05\n",
      "\n",
      "Epoch 01158: loss did not improve\n",
      "Epoch 1159/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 7.0082e-05\n",
      "\n",
      "Epoch 01159: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1160/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.0216e-05\n",
      "\n",
      "Epoch 01160: loss did not improve\n",
      "Epoch 1161/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.0654e-05\n",
      "\n",
      "Epoch 01161: loss did not improve\n",
      "Epoch 1162/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 7.1334e-05\n",
      "\n",
      "Epoch 01162: loss did not improve\n",
      "Epoch 1163/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 7.1720e-05\n",
      "\n",
      "Epoch 01163: loss did not improve\n",
      "Epoch 1164/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.2247e-05\n",
      "\n",
      "Epoch 01164: loss did not improve\n",
      "Epoch 1165/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.2632e-05\n",
      "\n",
      "Epoch 01165: loss did not improve\n",
      "Epoch 1166/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 7.4299e-05\n",
      "\n",
      "Epoch 01166: loss did not improve\n",
      "Epoch 1167/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.6964e-05\n",
      "\n",
      "Epoch 01167: loss did not improve\n",
      "Epoch 1168/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 7.4053e-05\n",
      "\n",
      "Epoch 01168: loss did not improve\n",
      "Epoch 1169/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.0412e-05\n",
      "\n",
      "Epoch 01169: loss did not improve\n",
      "Epoch 1170/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.9857e-05\n",
      "\n",
      "Epoch 01170: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1171/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.9515e-05\n",
      "\n",
      "Epoch 01171: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1172/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.9543e-05\n",
      "\n",
      "Epoch 01172: loss did not improve\n",
      "Epoch 1173/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.9984e-05\n",
      "\n",
      "Epoch 01173: loss did not improve\n",
      "Epoch 1174/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.9466e-05\n",
      "\n",
      "Epoch 01174: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1175/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.9738e-05\n",
      "\n",
      "Epoch 01175: loss did not improve\n",
      "Epoch 1176/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.0010e-05\n",
      "\n",
      "Epoch 01176: loss did not improve\n",
      "Epoch 1177/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.9445e-05\n",
      "\n",
      "Epoch 01177: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1178/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.9195e-05\n",
      "\n",
      "Epoch 01178: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1179/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.9456e-05\n",
      "\n",
      "Epoch 01179: loss did not improve\n",
      "Epoch 1180/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.9513e-05\n",
      "\n",
      "Epoch 01180: loss did not improve\n",
      "Epoch 1181/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.9431e-05\n",
      "\n",
      "Epoch 01181: loss did not improve\n",
      "Epoch 1182/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.9822e-05\n",
      "\n",
      "Epoch 01182: loss did not improve\n",
      "Epoch 1183/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.9141e-05\n",
      "\n",
      "Epoch 01183: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1184/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.9228e-05\n",
      "\n",
      "Epoch 01184: loss did not improve\n",
      "Epoch 1185/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.9940e-05\n",
      "\n",
      "Epoch 01185: loss did not improve\n",
      "Epoch 1186/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.9589e-05\n",
      "\n",
      "Epoch 01186: loss did not improve\n",
      "Epoch 1187/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.9321e-05\n",
      "\n",
      "Epoch 01187: loss did not improve\n",
      "Epoch 1188/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.9130e-05\n",
      "\n",
      "Epoch 01188: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1189/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.9027e-05\n",
      "\n",
      "Epoch 01189: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1190/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.9119e-05\n",
      "\n",
      "Epoch 01190: loss did not improve\n",
      "Epoch 1191/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.8836e-05\n",
      "\n",
      "Epoch 01191: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1192/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.9596e-05\n",
      "\n",
      "Epoch 01192: loss did not improve\n",
      "Epoch 1193/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.1077e-05\n",
      "\n",
      "Epoch 01193: loss did not improve\n",
      "Epoch 1194/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.9261e-05\n",
      "\n",
      "Epoch 01194: loss did not improve\n",
      "Epoch 1195/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.9219e-05\n",
      "\n",
      "Epoch 01195: loss did not improve\n",
      "Epoch 1196/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.9992e-05\n",
      "\n",
      "Epoch 01196: loss did not improve\n",
      "Epoch 1197/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.8902e-05\n",
      "\n",
      "Epoch 01197: loss did not improve\n",
      "Epoch 1198/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.8851e-05\n",
      "\n",
      "Epoch 01198: loss did not improve\n",
      "Epoch 1199/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.9661e-05\n",
      "\n",
      "Epoch 01199: loss did not improve\n",
      "Epoch 1200/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 6.9667e-05\n",
      "\n",
      "Epoch 01200: loss did not improve\n",
      "Epoch 1201/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.0440e-05\n",
      "\n",
      "Epoch 01201: loss did not improve\n",
      "Epoch 1202/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.1274e-05\n",
      "\n",
      "Epoch 01202: loss did not improve\n",
      "Epoch 1203/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.0343e-05\n",
      "\n",
      "Epoch 01203: loss did not improve\n",
      "Epoch 1204/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.9128e-05\n",
      "\n",
      "Epoch 01204: loss did not improve\n",
      "Epoch 1205/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.8876e-05\n",
      "\n",
      "Epoch 01205: loss did not improve\n",
      "Epoch 1206/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.9561e-05\n",
      "\n",
      "Epoch 01206: loss did not improve\n",
      "Epoch 1207/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.8766e-05\n",
      "\n",
      "Epoch 01207: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1208/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.0108e-05\n",
      "\n",
      "Epoch 01208: loss did not improve\n",
      "Epoch 1209/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.9711e-05\n",
      "\n",
      "Epoch 01209: loss did not improve\n",
      "Epoch 1210/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.0462e-05\n",
      "\n",
      "Epoch 01210: loss did not improve\n",
      "Epoch 1211/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 6.8870e-05\n",
      "\n",
      "Epoch 01211: loss did not improve\n",
      "Epoch 1212/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.8228e-05\n",
      "\n",
      "Epoch 01212: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1213/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.8395e-05\n",
      "\n",
      "Epoch 01213: loss did not improve\n",
      "Epoch 1214/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.8559e-05\n",
      "\n",
      "Epoch 01214: loss did not improve\n",
      "Epoch 1215/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.2281e-05\n",
      "\n",
      "Epoch 01215: loss did not improve\n",
      "Epoch 1216/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 7.0770e-05\n",
      "\n",
      "Epoch 01216: loss did not improve\n",
      "Epoch 1217/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.9759e-05\n",
      "\n",
      "Epoch 01217: loss did not improve\n",
      "Epoch 1218/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 7.2398e-05\n",
      "\n",
      "Epoch 01218: loss did not improve\n",
      "Epoch 1219/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.9519e-05\n",
      "\n",
      "Epoch 01219: loss did not improve\n",
      "Epoch 1220/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.9975e-05\n",
      "\n",
      "Epoch 01220: loss did not improve\n",
      "Epoch 1221/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 7.2081e-05\n",
      "\n",
      "Epoch 01221: loss did not improve\n",
      "Epoch 1222/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 7.0946e-05\n",
      "\n",
      "Epoch 01222: loss did not improve\n",
      "Epoch 1223/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.9994e-05\n",
      "\n",
      "Epoch 01223: loss did not improve\n",
      "Epoch 1224/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.9198e-05\n",
      "\n",
      "Epoch 01224: loss did not improve\n",
      "Epoch 1225/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.8904e-05\n",
      "\n",
      "Epoch 01225: loss did not improve\n",
      "Epoch 1226/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.8169e-05\n",
      "\n",
      "Epoch 01226: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1227/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.7917e-05\n",
      "\n",
      "Epoch 01227: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1228/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.9082e-05\n",
      "\n",
      "Epoch 01228: loss did not improve\n",
      "Epoch 1229/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.8312e-05\n",
      "\n",
      "Epoch 01229: loss did not improve\n",
      "Epoch 1230/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.8769e-05\n",
      "\n",
      "Epoch 01230: loss did not improve\n",
      "Epoch 1231/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.8198e-05\n",
      "\n",
      "Epoch 01231: loss did not improve\n",
      "Epoch 1232/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.9590e-05\n",
      "\n",
      "Epoch 01232: loss did not improve\n",
      "Epoch 1233/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 7.1153e-05\n",
      "\n",
      "Epoch 01233: loss did not improve\n",
      "Epoch 1234/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.9391e-05\n",
      "\n",
      "Epoch 01234: loss did not improve\n",
      "Epoch 1235/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.8926e-05\n",
      "\n",
      "Epoch 01235: loss did not improve\n",
      "Epoch 1236/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.8530e-05\n",
      "\n",
      "Epoch 01236: loss did not improve\n",
      "Epoch 1237/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.8355e-05\n",
      "\n",
      "Epoch 01237: loss did not improve\n",
      "Epoch 1238/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.9226e-05\n",
      "\n",
      "Epoch 01238: loss did not improve\n",
      "Epoch 1239/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 7.0357e-05\n",
      "\n",
      "Epoch 01239: loss did not improve\n",
      "Epoch 1240/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.8382e-05\n",
      "\n",
      "Epoch 01240: loss did not improve\n",
      "Epoch 1241/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.8750e-05\n",
      "\n",
      "Epoch 01241: loss did not improve\n",
      "Epoch 1242/2000\n",
      "2014/2014 [==============================] - ETA: 0s - loss: 5.8786e-0 - 0s 34us/step - loss: 6.7711e-05\n",
      "\n",
      "Epoch 01242: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1243/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.7488e-05\n",
      "\n",
      "Epoch 01243: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1244/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 6.7640e-05\n",
      "\n",
      "Epoch 01244: loss did not improve\n",
      "Epoch 1245/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.8166e-05\n",
      "\n",
      "Epoch 01245: loss did not improve\n",
      "Epoch 1246/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.7637e-05\n",
      "\n",
      "Epoch 01246: loss did not improve\n",
      "Epoch 1247/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.7412e-05\n",
      "\n",
      "Epoch 01247: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1248/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.7607e-05\n",
      "\n",
      "Epoch 01248: loss did not improve\n",
      "Epoch 1249/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.7630e-05\n",
      "\n",
      "Epoch 01249: loss did not improve\n",
      "Epoch 1250/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.8495e-05\n",
      "\n",
      "Epoch 01250: loss did not improve\n",
      "Epoch 1251/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.9054e-05\n",
      "\n",
      "Epoch 01251: loss did not improve\n",
      "Epoch 1252/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.9194e-05\n",
      "\n",
      "Epoch 01252: loss did not improve\n",
      "Epoch 1253/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.8648e-05\n",
      "\n",
      "Epoch 01253: loss did not improve\n",
      "Epoch 1254/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.7436e-05\n",
      "\n",
      "Epoch 01254: loss did not improve\n",
      "Epoch 1255/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.7959e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01255: loss did not improve\n",
      "Epoch 1256/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.8481e-05\n",
      "\n",
      "Epoch 01256: loss did not improve\n",
      "Epoch 1257/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.7912e-05\n",
      "\n",
      "Epoch 01257: loss did not improve\n",
      "Epoch 1258/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.7192e-05\n",
      "\n",
      "Epoch 01258: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1259/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.7613e-05\n",
      "\n",
      "Epoch 01259: loss did not improve\n",
      "Epoch 1260/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 6.8839e-05\n",
      "\n",
      "Epoch 01260: loss did not improve\n",
      "Epoch 1261/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.9133e-05\n",
      "\n",
      "Epoch 01261: loss did not improve\n",
      "Epoch 1262/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.8350e-05\n",
      "\n",
      "Epoch 01262: loss did not improve\n",
      "Epoch 1263/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.7741e-05\n",
      "\n",
      "Epoch 01263: loss did not improve\n",
      "Epoch 1264/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.8273e-05\n",
      "\n",
      "Epoch 01264: loss did not improve\n",
      "Epoch 1265/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.7347e-05\n",
      "\n",
      "Epoch 01265: loss did not improve\n",
      "Epoch 1266/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.7759e-05\n",
      "\n",
      "Epoch 01266: loss did not improve\n",
      "Epoch 1267/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.7112e-05\n",
      "\n",
      "Epoch 01267: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1268/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.8643e-05\n",
      "\n",
      "Epoch 01268: loss did not improve\n",
      "Epoch 1269/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.7688e-05\n",
      "\n",
      "Epoch 01269: loss did not improve\n",
      "Epoch 1270/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.6610e-05\n",
      "\n",
      "Epoch 01270: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1271/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.7039e-05\n",
      "\n",
      "Epoch 01271: loss did not improve\n",
      "Epoch 1272/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.7138e-05\n",
      "\n",
      "Epoch 01272: loss did not improve\n",
      "Epoch 1273/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.7090e-05\n",
      "\n",
      "Epoch 01273: loss did not improve\n",
      "Epoch 1274/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.7638e-05\n",
      "\n",
      "Epoch 01274: loss did not improve\n",
      "Epoch 1275/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.6578e-05\n",
      "\n",
      "Epoch 01275: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1276/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.6791e-05\n",
      "\n",
      "Epoch 01276: loss did not improve\n",
      "Epoch 1277/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.6431e-05\n",
      "\n",
      "Epoch 01277: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1278/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.6571e-05\n",
      "\n",
      "Epoch 01278: loss did not improve\n",
      "Epoch 1279/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.6737e-05\n",
      "\n",
      "Epoch 01279: loss did not improve\n",
      "Epoch 1280/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.6647e-05\n",
      "\n",
      "Epoch 01280: loss did not improve\n",
      "Epoch 1281/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.6896e-05\n",
      "\n",
      "Epoch 01281: loss did not improve\n",
      "Epoch 1282/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.6421e-05\n",
      "\n",
      "Epoch 01282: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1283/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.6515e-05\n",
      "\n",
      "Epoch 01283: loss did not improve\n",
      "Epoch 1284/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.6150e-05\n",
      "\n",
      "Epoch 01284: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1285/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 6.7088e-05\n",
      "\n",
      "Epoch 01285: loss did not improve\n",
      "Epoch 1286/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.7446e-05\n",
      "\n",
      "Epoch 01286: loss did not improve\n",
      "Epoch 1287/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.7550e-05\n",
      "\n",
      "Epoch 01287: loss did not improve\n",
      "Epoch 1288/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.7529e-05\n",
      "\n",
      "Epoch 01288: loss did not improve\n",
      "Epoch 1289/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.7139e-05\n",
      "\n",
      "Epoch 01289: loss did not improve\n",
      "Epoch 1290/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.6314e-05\n",
      "\n",
      "Epoch 01290: loss did not improve\n",
      "Epoch 1291/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.7269e-05\n",
      "\n",
      "Epoch 01291: loss did not improve\n",
      "Epoch 1292/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.6619e-05\n",
      "\n",
      "Epoch 01292: loss did not improve\n",
      "Epoch 1293/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 6.8295e-05\n",
      "\n",
      "Epoch 01293: loss did not improve\n",
      "Epoch 1294/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.9067e-05\n",
      "\n",
      "Epoch 01294: loss did not improve\n",
      "Epoch 1295/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.7107e-05\n",
      "\n",
      "Epoch 01295: loss did not improve\n",
      "Epoch 1296/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.8141e-05\n",
      "\n",
      "Epoch 01296: loss did not improve\n",
      "Epoch 1297/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 7.1981e-05\n",
      "\n",
      "Epoch 01297: loss did not improve\n",
      "Epoch 1298/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.9864e-05\n",
      "\n",
      "Epoch 01298: loss did not improve\n",
      "Epoch 1299/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.9523e-05\n",
      "\n",
      "Epoch 01299: loss did not improve\n",
      "Epoch 1300/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.7011e-05\n",
      "\n",
      "Epoch 01300: loss did not improve\n",
      "Epoch 1301/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.6715e-05\n",
      "\n",
      "Epoch 01301: loss did not improve\n",
      "Epoch 1302/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.7113e-05\n",
      "\n",
      "Epoch 01302: loss did not improve\n",
      "Epoch 1303/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.6284e-05\n",
      "\n",
      "Epoch 01303: loss did not improve\n",
      "Epoch 1304/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.5707e-05\n",
      "\n",
      "Epoch 01304: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1305/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.5722e-05\n",
      "\n",
      "Epoch 01305: loss did not improve\n",
      "Epoch 1306/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.5917e-05\n",
      "\n",
      "Epoch 01306: loss did not improve\n",
      "Epoch 1307/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.5763e-05\n",
      "\n",
      "Epoch 01307: loss did not improve\n",
      "Epoch 1308/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.7198e-05\n",
      "\n",
      "Epoch 01308: loss did not improve\n",
      "Epoch 1309/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.5831e-05\n",
      "\n",
      "Epoch 01309: loss did not improve\n",
      "Epoch 1310/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.6064e-05\n",
      "\n",
      "Epoch 01310: loss did not improve\n",
      "Epoch 1311/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.5492e-05\n",
      "\n",
      "Epoch 01311: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1312/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 6.6207e-05\n",
      "\n",
      "Epoch 01312: loss did not improve\n",
      "Epoch 1313/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.6399e-05\n",
      "\n",
      "Epoch 01313: loss did not improve\n",
      "Epoch 1314/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.5520e-05\n",
      "\n",
      "Epoch 01314: loss did not improve\n",
      "Epoch 1315/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.6340e-05\n",
      "\n",
      "Epoch 01315: loss did not improve\n",
      "Epoch 1316/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.6234e-05\n",
      "\n",
      "Epoch 01316: loss did not improve\n",
      "Epoch 1317/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.5629e-05\n",
      "\n",
      "Epoch 01317: loss did not improve\n",
      "Epoch 1318/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.6140e-05\n",
      "\n",
      "Epoch 01318: loss did not improve\n",
      "Epoch 1319/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.6114e-05\n",
      "\n",
      "Epoch 01319: loss did not improve\n",
      "Epoch 1320/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.5552e-05\n",
      "\n",
      "Epoch 01320: loss did not improve\n",
      "Epoch 1321/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.6350e-05\n",
      "\n",
      "Epoch 01321: loss did not improve\n",
      "Epoch 1322/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.8430e-05\n",
      "\n",
      "Epoch 01322: loss did not improve\n",
      "Epoch 1323/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.7422e-05\n",
      "\n",
      "Epoch 01323: loss did not improve\n",
      "Epoch 1324/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 6.6768e-05\n",
      "\n",
      "Epoch 01324: loss did not improve\n",
      "Epoch 1325/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.5342e-05\n",
      "\n",
      "Epoch 01325: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1326/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.5310e-05\n",
      "\n",
      "Epoch 01326: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1327/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 6.5303e-05\n",
      "\n",
      "Epoch 01327: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1328/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.5550e-05\n",
      "\n",
      "Epoch 01328: loss did not improve\n",
      "Epoch 1329/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.5111e-05\n",
      "\n",
      "Epoch 01329: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1330/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.5444e-05\n",
      "\n",
      "Epoch 01330: loss did not improve\n",
      "Epoch 1331/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.5036e-05\n",
      "\n",
      "Epoch 01331: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1332/2000\n",
      "2014/2014 [==============================] - 0s 25us/step - loss: 6.5186e-05\n",
      "\n",
      "Epoch 01332: loss did not improve\n",
      "Epoch 1333/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.5057e-05\n",
      "\n",
      "Epoch 01333: loss did not improve\n",
      "Epoch 1334/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.5027e-05\n",
      "\n",
      "Epoch 01334: loss improved from 0.00007 to 0.00007, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1335/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.8230e-05\n",
      "\n",
      "Epoch 01335: loss did not improve\n",
      "Epoch 1336/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.8181e-05\n",
      "\n",
      "Epoch 01336: loss did not improve\n",
      "Epoch 1337/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.6477e-05\n",
      "\n",
      "Epoch 01337: loss did not improve\n",
      "Epoch 1338/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.6001e-05\n",
      "\n",
      "Epoch 01338: loss did not improve\n",
      "Epoch 1339/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.5271e-05\n",
      "\n",
      "Epoch 01339: loss did not improve\n",
      "Epoch 1340/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.6363e-05\n",
      "\n",
      "Epoch 01340: loss did not improve\n",
      "Epoch 1341/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 6.8549e-05\n",
      "\n",
      "Epoch 01341: loss did not improve\n",
      "Epoch 1342/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.9256e-05\n",
      "\n",
      "Epoch 01342: loss did not improve\n",
      "Epoch 1343/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.7991e-05\n",
      "\n",
      "Epoch 01343: loss did not improve\n",
      "Epoch 1344/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 6.8372e-05\n",
      "\n",
      "Epoch 01344: loss did not improve\n",
      "Epoch 1345/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.7461e-05\n",
      "\n",
      "Epoch 01345: loss did not improve\n",
      "Epoch 1346/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 6.5762e-05\n",
      "\n",
      "Epoch 01346: loss did not improve\n",
      "Epoch 1347/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.6195e-05\n",
      "\n",
      "Epoch 01347: loss did not improve\n",
      "Epoch 1348/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.7241e-05\n",
      "\n",
      "Epoch 01348: loss did not improve\n",
      "Epoch 1349/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.6416e-05\n",
      "\n",
      "Epoch 01349: loss did not improve\n",
      "Epoch 1350/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.6067e-05\n",
      "\n",
      "Epoch 01350: loss did not improve\n",
      "Epoch 1351/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.5606e-05\n",
      "\n",
      "Epoch 01351: loss did not improve\n",
      "Epoch 1352/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.6001e-05\n",
      "\n",
      "Epoch 01352: loss did not improve\n",
      "Epoch 1353/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.6383e-05\n",
      "\n",
      "Epoch 01353: loss did not improve\n",
      "Epoch 1354/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.7392e-05\n",
      "\n",
      "Epoch 01354: loss did not improve\n",
      "Epoch 1355/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.6731e-05\n",
      "\n",
      "Epoch 01355: loss did not improve\n",
      "Epoch 1356/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.4784e-05\n",
      "\n",
      "Epoch 01356: loss improved from 0.00007 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1357/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.4983e-05\n",
      "\n",
      "Epoch 01357: loss did not improve\n",
      "Epoch 1358/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.4328e-05\n",
      "\n",
      "Epoch 01358: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1359/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.4815e-05\n",
      "\n",
      "Epoch 01359: loss did not improve\n",
      "Epoch 1360/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.4578e-05\n",
      "\n",
      "Epoch 01360: loss did not improve\n",
      "Epoch 1361/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 6.5758e-05\n",
      "\n",
      "Epoch 01361: loss did not improve\n",
      "Epoch 1362/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.5166e-05\n",
      "\n",
      "Epoch 01362: loss did not improve\n",
      "Epoch 1363/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.4415e-05\n",
      "\n",
      "Epoch 01363: loss did not improve\n",
      "Epoch 1364/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.4491e-05\n",
      "\n",
      "Epoch 01364: loss did not improve\n",
      "Epoch 1365/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.4225e-05\n",
      "\n",
      "Epoch 01365: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1366/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.4537e-05\n",
      "\n",
      "Epoch 01366: loss did not improve\n",
      "Epoch 1367/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.4894e-05\n",
      "\n",
      "Epoch 01367: loss did not improve\n",
      "Epoch 1368/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.4619e-05\n",
      "\n",
      "Epoch 01368: loss did not improve\n",
      "Epoch 1369/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.5174e-05\n",
      "\n",
      "Epoch 01369: loss did not improve\n",
      "Epoch 1370/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.4810e-05\n",
      "\n",
      "Epoch 01370: loss did not improve\n",
      "Epoch 1371/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.4844e-05\n",
      "\n",
      "Epoch 01371: loss did not improve\n",
      "Epoch 1372/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.4028e-05\n",
      "\n",
      "Epoch 01372: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1373/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.4159e-05\n",
      "\n",
      "Epoch 01373: loss did not improve\n",
      "Epoch 1374/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.4134e-05\n",
      "\n",
      "Epoch 01374: loss did not improve\n",
      "Epoch 1375/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.4039e-05\n",
      "\n",
      "Epoch 01375: loss did not improve\n",
      "Epoch 1376/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.4271e-05\n",
      "\n",
      "Epoch 01376: loss did not improve\n",
      "Epoch 1377/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.4637e-05\n",
      "\n",
      "Epoch 01377: loss did not improve\n",
      "Epoch 1378/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 6.7110e-05\n",
      "\n",
      "Epoch 01378: loss did not improve\n",
      "Epoch 1379/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.4934e-05\n",
      "\n",
      "Epoch 01379: loss did not improve\n",
      "Epoch 1380/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.4270e-05\n",
      "\n",
      "Epoch 01380: loss did not improve\n",
      "Epoch 1381/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.5429e-05\n",
      "\n",
      "Epoch 01381: loss did not improve\n",
      "Epoch 1382/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.5046e-05\n",
      "\n",
      "Epoch 01382: loss did not improve\n",
      "Epoch 1383/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.5328e-05\n",
      "\n",
      "Epoch 01383: loss did not improve\n",
      "Epoch 1384/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.4863e-05\n",
      "\n",
      "Epoch 01384: loss did not improve\n",
      "Epoch 1385/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.6372e-05\n",
      "\n",
      "Epoch 01385: loss did not improve\n",
      "Epoch 1386/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.5760e-05\n",
      "\n",
      "Epoch 01386: loss did not improve\n",
      "Epoch 1387/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.8364e-05\n",
      "\n",
      "Epoch 01387: loss did not improve\n",
      "Epoch 1388/2000\n",
      "2014/2014 [==============================] - 0s 37us/step - loss: 6.7451e-05\n",
      "\n",
      "Epoch 01388: loss did not improve\n",
      "Epoch 1389/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.4936e-05\n",
      "\n",
      "Epoch 01389: loss did not improve\n",
      "Epoch 1390/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.9565e-05\n",
      "\n",
      "Epoch 01390: loss did not improve\n",
      "Epoch 1391/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.4758e-05\n",
      "\n",
      "Epoch 01391: loss did not improve\n",
      "Epoch 1392/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.4388e-05\n",
      "\n",
      "Epoch 01392: loss did not improve\n",
      "Epoch 1393/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.4555e-05\n",
      "\n",
      "Epoch 01393: loss did not improve\n",
      "Epoch 1394/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.4574e-05\n",
      "\n",
      "Epoch 01394: loss did not improve\n",
      "Epoch 1395/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.4084e-05\n",
      "\n",
      "Epoch 01395: loss did not improve\n",
      "Epoch 1396/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.4297e-05\n",
      "\n",
      "Epoch 01396: loss did not improve\n",
      "Epoch 1397/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.5223e-05\n",
      "\n",
      "Epoch 01397: loss did not improve\n",
      "Epoch 1398/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.5292e-05\n",
      "\n",
      "Epoch 01398: loss did not improve\n",
      "Epoch 1399/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.7959e-05\n",
      "\n",
      "Epoch 01399: loss did not improve\n",
      "Epoch 1400/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.5638e-05\n",
      "\n",
      "Epoch 01400: loss did not improve\n",
      "Epoch 1401/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.6526e-05\n",
      "\n",
      "Epoch 01401: loss did not improve\n",
      "Epoch 1402/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.5837e-05\n",
      "\n",
      "Epoch 01402: loss did not improve\n",
      "Epoch 1403/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.5530e-05\n",
      "\n",
      "Epoch 01403: loss did not improve\n",
      "Epoch 1404/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.3672e-05\n",
      "\n",
      "Epoch 01404: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1405/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.3578e-05\n",
      "\n",
      "Epoch 01405: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1406/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.3872e-05\n",
      "\n",
      "Epoch 01406: loss did not improve\n",
      "Epoch 1407/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.3999e-05\n",
      "\n",
      "Epoch 01407: loss did not improve\n",
      "Epoch 1408/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.3615e-05\n",
      "\n",
      "Epoch 01408: loss did not improve\n",
      "Epoch 1409/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.3347e-05\n",
      "\n",
      "Epoch 01409: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1410/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.4080e-05\n",
      "\n",
      "Epoch 01410: loss did not improve\n",
      "Epoch 1411/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.7131e-05\n",
      "\n",
      "Epoch 01411: loss did not improve\n",
      "Epoch 1412/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.6134e-05\n",
      "\n",
      "Epoch 01412: loss did not improve\n",
      "Epoch 1413/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.5132e-05\n",
      "\n",
      "Epoch 01413: loss did not improve\n",
      "Epoch 1414/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.5655e-05\n",
      "\n",
      "Epoch 01414: loss did not improve\n",
      "Epoch 1415/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.3699e-05\n",
      "\n",
      "Epoch 01415: loss did not improve\n",
      "Epoch 1416/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.3692e-05\n",
      "\n",
      "Epoch 01416: loss did not improve\n",
      "Epoch 1417/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.3439e-05\n",
      "\n",
      "Epoch 01417: loss did not improve\n",
      "Epoch 1418/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.3492e-05\n",
      "\n",
      "Epoch 01418: loss did not improve\n",
      "Epoch 1419/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.3469e-05\n",
      "\n",
      "Epoch 01419: loss did not improve\n",
      "Epoch 1420/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.3116e-05\n",
      "\n",
      "Epoch 01420: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1421/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.3410e-05\n",
      "\n",
      "Epoch 01421: loss did not improve\n",
      "Epoch 1422/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.3545e-05\n",
      "\n",
      "Epoch 01422: loss did not improve\n",
      "Epoch 1423/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.3495e-05\n",
      "\n",
      "Epoch 01423: loss did not improve\n",
      "Epoch 1424/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.3400e-05\n",
      "\n",
      "Epoch 01424: loss did not improve\n",
      "Epoch 1425/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.3966e-05\n",
      "\n",
      "Epoch 01425: loss did not improve\n",
      "Epoch 1426/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.3332e-05\n",
      "\n",
      "Epoch 01426: loss did not improve\n",
      "Epoch 1427/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.3222e-05\n",
      "\n",
      "Epoch 01427: loss did not improve\n",
      "Epoch 1428/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.2883e-05\n",
      "\n",
      "Epoch 01428: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1429/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.3932e-05\n",
      "\n",
      "Epoch 01429: loss did not improve\n",
      "Epoch 1430/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.3620e-05\n",
      "\n",
      "Epoch 01430: loss did not improve\n",
      "Epoch 1431/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.4029e-05\n",
      "\n",
      "Epoch 01431: loss did not improve\n",
      "Epoch 1432/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.2866e-05\n",
      "\n",
      "Epoch 01432: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1433/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 6.2998e-05\n",
      "\n",
      "Epoch 01433: loss did not improve\n",
      "Epoch 1434/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.4116e-05\n",
      "\n",
      "Epoch 01434: loss did not improve\n",
      "Epoch 1435/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.4161e-05\n",
      "\n",
      "Epoch 01435: loss did not improve\n",
      "Epoch 1436/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.4473e-05\n",
      "\n",
      "Epoch 01436: loss did not improve\n",
      "Epoch 1437/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.5210e-05\n",
      "\n",
      "Epoch 01437: loss did not improve\n",
      "Epoch 1438/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.3440e-05\n",
      "\n",
      "Epoch 01438: loss did not improve\n",
      "Epoch 1439/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.3974e-05\n",
      "\n",
      "Epoch 01439: loss did not improve\n",
      "Epoch 1440/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.2663e-05\n",
      "\n",
      "Epoch 01440: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1441/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.3154e-05\n",
      "\n",
      "Epoch 01441: loss did not improve\n",
      "Epoch 1442/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.3238e-05\n",
      "\n",
      "Epoch 01442: loss did not improve\n",
      "Epoch 1443/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.3037e-05\n",
      "\n",
      "Epoch 01443: loss did not improve\n",
      "Epoch 1444/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.3385e-05\n",
      "\n",
      "Epoch 01444: loss did not improve\n",
      "Epoch 1445/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.2601e-05\n",
      "\n",
      "Epoch 01445: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1446/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.3300e-05\n",
      "\n",
      "Epoch 01446: loss did not improve\n",
      "Epoch 1447/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.3778e-05\n",
      "\n",
      "Epoch 01447: loss did not improve\n",
      "Epoch 1448/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.3451e-05\n",
      "\n",
      "Epoch 01448: loss did not improve\n",
      "Epoch 1449/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.3090e-05\n",
      "\n",
      "Epoch 01449: loss did not improve\n",
      "Epoch 1450/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.3331e-05\n",
      "\n",
      "Epoch 01450: loss did not improve\n",
      "Epoch 1451/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.4915e-05\n",
      "\n",
      "Epoch 01451: loss did not improve\n",
      "Epoch 1452/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.4356e-05\n",
      "\n",
      "Epoch 01452: loss did not improve\n",
      "Epoch 1453/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.5478e-05\n",
      "\n",
      "Epoch 01453: loss did not improve\n",
      "Epoch 1454/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.6462e-05\n",
      "\n",
      "Epoch 01454: loss did not improve\n",
      "Epoch 1455/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.5551e-05\n",
      "\n",
      "Epoch 01455: loss did not improve\n",
      "Epoch 1456/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.5381e-05\n",
      "\n",
      "Epoch 01456: loss did not improve\n",
      "Epoch 1457/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.6197e-05\n",
      "\n",
      "Epoch 01457: loss did not improve\n",
      "Epoch 1458/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.7113e-05\n",
      "\n",
      "Epoch 01458: loss did not improve\n",
      "Epoch 1459/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.6358e-05\n",
      "\n",
      "Epoch 01459: loss did not improve\n",
      "Epoch 1460/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.5748e-05\n",
      "\n",
      "Epoch 01460: loss did not improve\n",
      "Epoch 1461/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.3306e-05\n",
      "\n",
      "Epoch 01461: loss did not improve\n",
      "Epoch 1462/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.3130e-05\n",
      "\n",
      "Epoch 01462: loss did not improve\n",
      "Epoch 1463/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.3974e-05\n",
      "\n",
      "Epoch 01463: loss did not improve\n",
      "Epoch 1464/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.2513e-05\n",
      "\n",
      "Epoch 01464: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1465/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.3192e-05\n",
      "\n",
      "Epoch 01465: loss did not improve\n",
      "Epoch 1466/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.5749e-05\n",
      "\n",
      "Epoch 01466: loss did not improve\n",
      "Epoch 1467/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.4886e-05\n",
      "\n",
      "Epoch 01467: loss did not improve\n",
      "Epoch 1468/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.4994e-05\n",
      "\n",
      "Epoch 01468: loss did not improve\n",
      "Epoch 1469/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.3966e-05\n",
      "\n",
      "Epoch 01469: loss did not improve\n",
      "Epoch 1470/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.5490e-05\n",
      "\n",
      "Epoch 01470: loss did not improve\n",
      "Epoch 1471/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.3211e-05\n",
      "\n",
      "Epoch 01471: loss did not improve\n",
      "Epoch 1472/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.2508e-05\n",
      "\n",
      "Epoch 01472: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1473/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.4292e-05\n",
      "\n",
      "Epoch 01473: loss did not improve\n",
      "Epoch 1474/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.2136e-05\n",
      "\n",
      "Epoch 01474: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1475/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.2055e-05\n",
      "\n",
      "Epoch 01475: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1476/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.2177e-05\n",
      "\n",
      "Epoch 01476: loss did not improve\n",
      "Epoch 1477/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1990e-05\n",
      "\n",
      "Epoch 01477: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1478/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 6.2166e-05\n",
      "\n",
      "Epoch 01478: loss did not improve\n",
      "Epoch 1479/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.2487e-05\n",
      "\n",
      "Epoch 01479: loss did not improve\n",
      "Epoch 1480/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.6150e-05\n",
      "\n",
      "Epoch 01480: loss did not improve\n",
      "Epoch 1481/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.4868e-05\n",
      "\n",
      "Epoch 01481: loss did not improve\n",
      "Epoch 1482/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.3029e-05\n",
      "\n",
      "Epoch 01482: loss did not improve\n",
      "Epoch 1483/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.2457e-05\n",
      "\n",
      "Epoch 01483: loss did not improve\n",
      "Epoch 1484/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.2447e-05\n",
      "\n",
      "Epoch 01484: loss did not improve\n",
      "Epoch 1485/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.3732e-05\n",
      "\n",
      "Epoch 01485: loss did not improve\n",
      "Epoch 1486/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 6.4061e-05\n",
      "\n",
      "Epoch 01486: loss did not improve\n",
      "Epoch 1487/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.5359e-05\n",
      "\n",
      "Epoch 01487: loss did not improve\n",
      "Epoch 1488/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.7382e-05\n",
      "\n",
      "Epoch 01488: loss did not improve\n",
      "Epoch 1489/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.2225e-05\n",
      "\n",
      "Epoch 01489: loss did not improve\n",
      "Epoch 1490/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.2871e-05\n",
      "\n",
      "Epoch 01490: loss did not improve\n",
      "Epoch 1491/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.2855e-05\n",
      "\n",
      "Epoch 01491: loss did not improve\n",
      "Epoch 1492/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.2542e-05\n",
      "\n",
      "Epoch 01492: loss did not improve\n",
      "Epoch 1493/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.2201e-05\n",
      "\n",
      "Epoch 01493: loss did not improve\n",
      "Epoch 1494/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.2056e-05\n",
      "\n",
      "Epoch 01494: loss did not improve\n",
      "Epoch 1495/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.2683e-05\n",
      "\n",
      "Epoch 01495: loss did not improve\n",
      "Epoch 1496/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1708e-05\n",
      "\n",
      "Epoch 01496: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1497/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.1754e-05\n",
      "\n",
      "Epoch 01497: loss did not improve\n",
      "Epoch 1498/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.1538e-05\n",
      "\n",
      "Epoch 01498: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1499/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.1571e-05\n",
      "\n",
      "Epoch 01499: loss did not improve\n",
      "Epoch 1500/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.1690e-05\n",
      "\n",
      "Epoch 01500: loss did not improve\n",
      "Epoch 1501/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.2025e-05\n",
      "\n",
      "Epoch 01501: loss did not improve\n",
      "Epoch 1502/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.2862e-05\n",
      "\n",
      "Epoch 01502: loss did not improve\n",
      "Epoch 1503/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1966e-05\n",
      "\n",
      "Epoch 01503: loss did not improve\n",
      "Epoch 1504/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1745e-05\n",
      "\n",
      "Epoch 01504: loss did not improve\n",
      "Epoch 1505/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.2424e-05\n",
      "\n",
      "Epoch 01505: loss did not improve\n",
      "Epoch 1506/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.2713e-05\n",
      "\n",
      "Epoch 01506: loss did not improve\n",
      "Epoch 1507/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.3382e-05\n",
      "\n",
      "Epoch 01507: loss did not improve\n",
      "Epoch 1508/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.4744e-05\n",
      "\n",
      "Epoch 01508: loss did not improve\n",
      "Epoch 1509/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.4371e-05\n",
      "\n",
      "Epoch 01509: loss did not improve\n",
      "Epoch 1510/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.4779e-05\n",
      "\n",
      "Epoch 01510: loss did not improve\n",
      "Epoch 1511/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.3521e-05\n",
      "\n",
      "Epoch 01511: loss did not improve\n",
      "Epoch 1512/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.2958e-05\n",
      "\n",
      "Epoch 01512: loss did not improve\n",
      "Epoch 1513/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.1988e-05\n",
      "\n",
      "Epoch 01513: loss did not improve\n",
      "Epoch 1514/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.3124e-05\n",
      "\n",
      "Epoch 01514: loss did not improve\n",
      "Epoch 1515/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.2070e-05\n",
      "\n",
      "Epoch 01515: loss did not improve\n",
      "Epoch 1516/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.1609e-05\n",
      "\n",
      "Epoch 01516: loss did not improve\n",
      "Epoch 1517/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1684e-05\n",
      "\n",
      "Epoch 01517: loss did not improve\n",
      "Epoch 1518/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.1570e-05\n",
      "\n",
      "Epoch 01518: loss did not improve\n",
      "Epoch 1519/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.1397e-05\n",
      "\n",
      "Epoch 01519: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1520/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1622e-05\n",
      "\n",
      "Epoch 01520: loss did not improve\n",
      "Epoch 1521/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.2847e-05\n",
      "\n",
      "Epoch 01521: loss did not improve\n",
      "Epoch 1522/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.1443e-05\n",
      "\n",
      "Epoch 01522: loss did not improve\n",
      "Epoch 1523/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.3156e-05\n",
      "\n",
      "Epoch 01523: loss did not improve\n",
      "Epoch 1524/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.7022e-05\n",
      "\n",
      "Epoch 01524: loss did not improve\n",
      "Epoch 1525/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.5312e-05\n",
      "\n",
      "Epoch 01525: loss did not improve\n",
      "Epoch 1526/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.3648e-05\n",
      "\n",
      "Epoch 01526: loss did not improve\n",
      "Epoch 1527/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.3610e-05\n",
      "\n",
      "Epoch 01527: loss did not improve\n",
      "Epoch 1528/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.2143e-05\n",
      "\n",
      "Epoch 01528: loss did not improve\n",
      "Epoch 1529/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.2877e-05\n",
      "\n",
      "Epoch 01529: loss did not improve\n",
      "Epoch 1530/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.2693e-05\n",
      "\n",
      "Epoch 01530: loss did not improve\n",
      "Epoch 1531/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 6.1357e-05\n",
      "\n",
      "Epoch 01531: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1532/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1209e-05\n",
      "\n",
      "Epoch 01532: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1533/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1069e-05\n",
      "\n",
      "Epoch 01533: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1534/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.1626e-05\n",
      "\n",
      "Epoch 01534: loss did not improve\n",
      "Epoch 1535/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.1568e-05\n",
      "\n",
      "Epoch 01535: loss did not improve\n",
      "Epoch 1536/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 6.1705e-05\n",
      "\n",
      "Epoch 01536: loss did not improve\n",
      "Epoch 1537/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.2228e-05\n",
      "\n",
      "Epoch 01537: loss did not improve\n",
      "Epoch 1538/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.1438e-05\n",
      "\n",
      "Epoch 01538: loss did not improve\n",
      "Epoch 1539/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.1819e-05\n",
      "\n",
      "Epoch 01539: loss did not improve\n",
      "Epoch 1540/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.1188e-05\n",
      "\n",
      "Epoch 01540: loss did not improve\n",
      "Epoch 1541/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.1328e-05\n",
      "\n",
      "Epoch 01541: loss did not improve\n",
      "Epoch 1542/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.1475e-05\n",
      "\n",
      "Epoch 01542: loss did not improve\n",
      "Epoch 1543/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.1268e-05\n",
      "\n",
      "Epoch 01543: loss did not improve\n",
      "Epoch 1544/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.1134e-05\n",
      "\n",
      "Epoch 01544: loss did not improve\n",
      "Epoch 1545/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.1327e-05\n",
      "\n",
      "Epoch 01545: loss did not improve\n",
      "Epoch 1546/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1478e-05\n",
      "\n",
      "Epoch 01546: loss did not improve\n",
      "Epoch 1547/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 6.1412e-05\n",
      "\n",
      "Epoch 01547: loss did not improve\n",
      "Epoch 1548/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.0987e-05\n",
      "\n",
      "Epoch 01548: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1549/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0875e-05\n",
      "\n",
      "Epoch 01549: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1550/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1159e-05\n",
      "\n",
      "Epoch 01550: loss did not improve\n",
      "Epoch 1551/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.0870e-05\n",
      "\n",
      "Epoch 01551: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1552/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1032e-05\n",
      "\n",
      "Epoch 01552: loss did not improve\n",
      "Epoch 1553/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.0727e-05\n",
      "\n",
      "Epoch 01553: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1554/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.1189e-05\n",
      "\n",
      "Epoch 01554: loss did not improve\n",
      "Epoch 1555/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.1242e-05\n",
      "\n",
      "Epoch 01555: loss did not improve\n",
      "Epoch 1556/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0665e-05\n",
      "\n",
      "Epoch 01556: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1557/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0939e-05\n",
      "\n",
      "Epoch 01557: loss did not improve\n",
      "Epoch 1558/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.0768e-05\n",
      "\n",
      "Epoch 01558: loss did not improve\n",
      "Epoch 1559/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1343e-05\n",
      "\n",
      "Epoch 01559: loss did not improve\n",
      "Epoch 1560/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.0762e-05\n",
      "\n",
      "Epoch 01560: loss did not improve\n",
      "Epoch 1561/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1155e-05\n",
      "\n",
      "Epoch 01561: loss did not improve\n",
      "Epoch 1562/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.1720e-05\n",
      "\n",
      "Epoch 01562: loss did not improve\n",
      "Epoch 1563/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 6.1315e-05\n",
      "\n",
      "Epoch 01563: loss did not improve\n",
      "Epoch 1564/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.2080e-05\n",
      "\n",
      "Epoch 01564: loss did not improve\n",
      "Epoch 1565/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0994e-05\n",
      "\n",
      "Epoch 01565: loss did not improve\n",
      "Epoch 1566/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0839e-05\n",
      "\n",
      "Epoch 01566: loss did not improve\n",
      "Epoch 1567/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.1768e-05\n",
      "\n",
      "Epoch 01567: loss did not improve\n",
      "Epoch 1568/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.1231e-05\n",
      "\n",
      "Epoch 01568: loss did not improve\n",
      "Epoch 1569/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.2257e-05\n",
      "\n",
      "Epoch 01569: loss did not improve\n",
      "Epoch 1570/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.5141e-05\n",
      "\n",
      "Epoch 01570: loss did not improve\n",
      "Epoch 1571/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.3510e-05\n",
      "\n",
      "Epoch 01571: loss did not improve\n",
      "Epoch 1572/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.2498e-05\n",
      "\n",
      "Epoch 01572: loss did not improve\n",
      "Epoch 1573/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1473e-05\n",
      "\n",
      "Epoch 01573: loss did not improve\n",
      "Epoch 1574/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0759e-05\n",
      "\n",
      "Epoch 01574: loss did not improve\n",
      "Epoch 1575/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0589e-05\n",
      "\n",
      "Epoch 01575: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1576/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.0431e-05\n",
      "\n",
      "Epoch 01576: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1577/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 6.1448e-05\n",
      "\n",
      "Epoch 01577: loss did not improve\n",
      "Epoch 1578/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.3235e-05\n",
      "\n",
      "Epoch 01578: loss did not improve\n",
      "Epoch 1579/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.2941e-05\n",
      "\n",
      "Epoch 01579: loss did not improve\n",
      "Epoch 1580/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.2792e-05\n",
      "\n",
      "Epoch 01580: loss did not improve\n",
      "Epoch 1581/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.2689e-05\n",
      "\n",
      "Epoch 01581: loss did not improve\n",
      "Epoch 1582/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.4755e-05\n",
      "\n",
      "Epoch 01582: loss did not improve\n",
      "Epoch 1583/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.4088e-05\n",
      "\n",
      "Epoch 01583: loss did not improve\n",
      "Epoch 1584/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.4272e-05\n",
      "\n",
      "Epoch 01584: loss did not improve\n",
      "Epoch 1585/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.4564e-05\n",
      "\n",
      "Epoch 01585: loss did not improve\n",
      "Epoch 1586/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.3718e-05\n",
      "\n",
      "Epoch 01586: loss did not improve\n",
      "Epoch 1587/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.1086e-05\n",
      "\n",
      "Epoch 01587: loss did not improve\n",
      "Epoch 1588/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.0498e-05\n",
      "\n",
      "Epoch 01588: loss did not improve\n",
      "Epoch 1589/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0431e-05\n",
      "\n",
      "Epoch 01589: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1590/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.0770e-05\n",
      "\n",
      "Epoch 01590: loss did not improve\n",
      "Epoch 1591/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.0549e-05\n",
      "\n",
      "Epoch 01591: loss did not improve\n",
      "Epoch 1592/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1884e-05\n",
      "\n",
      "Epoch 01592: loss did not improve\n",
      "Epoch 1593/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.1150e-05\n",
      "\n",
      "Epoch 01593: loss did not improve\n",
      "Epoch 1594/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.4044e-05\n",
      "\n",
      "Epoch 01594: loss did not improve\n",
      "Epoch 1595/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.1657e-05\n",
      "\n",
      "Epoch 01595: loss did not improve\n",
      "Epoch 1596/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.1319e-05\n",
      "\n",
      "Epoch 01596: loss did not improve\n",
      "Epoch 1597/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.2155e-05\n",
      "\n",
      "Epoch 01597: loss did not improve\n",
      "Epoch 1598/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.3447e-05\n",
      "\n",
      "Epoch 01598: loss did not improve\n",
      "Epoch 1599/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.5135e-05\n",
      "\n",
      "Epoch 01599: loss did not improve\n",
      "Epoch 1600/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.1286e-05\n",
      "\n",
      "Epoch 01600: loss did not improve\n",
      "Epoch 1601/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.2519e-05\n",
      "\n",
      "Epoch 01601: loss did not improve\n",
      "Epoch 1602/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1639e-05\n",
      "\n",
      "Epoch 01602: loss did not improve\n",
      "Epoch 1603/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.3318e-05\n",
      "\n",
      "Epoch 01603: loss did not improve\n",
      "Epoch 1604/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.4028e-05\n",
      "\n",
      "Epoch 01604: loss did not improve\n",
      "Epoch 1605/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.5471e-05\n",
      "\n",
      "Epoch 01605: loss did not improve\n",
      "Epoch 1606/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.2919e-05\n",
      "\n",
      "Epoch 01606: loss did not improve\n",
      "Epoch 1607/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.3097e-05\n",
      "\n",
      "Epoch 01607: loss did not improve\n",
      "Epoch 1608/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.2543e-05\n",
      "\n",
      "Epoch 01608: loss did not improve\n",
      "Epoch 1609/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.0116e-05\n",
      "\n",
      "Epoch 01609: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1610/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.0377e-05\n",
      "\n",
      "Epoch 01610: loss did not improve\n",
      "Epoch 1611/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.0551e-05\n",
      "\n",
      "Epoch 01611: loss did not improve\n",
      "Epoch 1612/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0014e-05\n",
      "\n",
      "Epoch 01612: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1613/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0909e-05\n",
      "\n",
      "Epoch 01613: loss did not improve\n",
      "Epoch 1614/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.1265e-05\n",
      "\n",
      "Epoch 01614: loss did not improve\n",
      "Epoch 1615/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.0808e-05\n",
      "\n",
      "Epoch 01615: loss did not improve\n",
      "Epoch 1616/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0238e-05\n",
      "\n",
      "Epoch 01616: loss did not improve\n",
      "Epoch 1617/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.0933e-05\n",
      "\n",
      "Epoch 01617: loss did not improve\n",
      "Epoch 1618/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.3887e-05\n",
      "\n",
      "Epoch 01618: loss did not improve\n",
      "Epoch 1619/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.4391e-05\n",
      "\n",
      "Epoch 01619: loss did not improve\n",
      "Epoch 1620/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.2176e-05\n",
      "\n",
      "Epoch 01620: loss did not improve\n",
      "Epoch 1621/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.2338e-05\n",
      "\n",
      "Epoch 01621: loss did not improve\n",
      "Epoch 1622/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1708e-05\n",
      "\n",
      "Epoch 01622: loss did not improve\n",
      "Epoch 1623/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.0327e-05\n",
      "\n",
      "Epoch 01623: loss did not improve\n",
      "Epoch 1624/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0059e-05\n",
      "\n",
      "Epoch 01624: loss did not improve\n",
      "Epoch 1625/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0320e-05\n",
      "\n",
      "Epoch 01625: loss did not improve\n",
      "Epoch 1626/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1726e-05\n",
      "\n",
      "Epoch 01626: loss did not improve\n",
      "Epoch 1627/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.1300e-05\n",
      "\n",
      "Epoch 01627: loss did not improve\n",
      "Epoch 1628/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.1985e-05\n",
      "\n",
      "Epoch 01628: loss did not improve\n",
      "Epoch 1629/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.1686e-05\n",
      "\n",
      "Epoch 01629: loss did not improve\n",
      "Epoch 1630/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.0022e-05\n",
      "\n",
      "Epoch 01630: loss did not improve\n",
      "Epoch 1631/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 6.1437e-05\n",
      "\n",
      "Epoch 01631: loss did not improve\n",
      "Epoch 1632/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.0501e-05\n",
      "\n",
      "Epoch 01632: loss did not improve\n",
      "Epoch 1633/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.9789e-05\n",
      "\n",
      "Epoch 01633: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1634/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.0401e-05\n",
      "\n",
      "Epoch 01634: loss did not improve\n",
      "Epoch 1635/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9783e-05\n",
      "\n",
      "Epoch 01635: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1636/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.9977e-05\n",
      "\n",
      "Epoch 01636: loss did not improve\n",
      "Epoch 1637/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9907e-05\n",
      "\n",
      "Epoch 01637: loss did not improve\n",
      "Epoch 1638/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.9512e-05\n",
      "\n",
      "Epoch 01638: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1639/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.1131e-05\n",
      "\n",
      "Epoch 01639: loss did not improve\n",
      "Epoch 1640/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.1381e-05\n",
      "\n",
      "Epoch 01640: loss did not improve\n",
      "Epoch 1641/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0486e-05\n",
      "\n",
      "Epoch 01641: loss did not improve\n",
      "Epoch 1642/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 5.9500e-05\n",
      "\n",
      "Epoch 01642: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1643/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.9864e-05\n",
      "\n",
      "Epoch 01643: loss did not improve\n",
      "Epoch 1644/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.9704e-05\n",
      "\n",
      "Epoch 01644: loss did not improve\n",
      "Epoch 1645/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1288e-05\n",
      "\n",
      "Epoch 01645: loss did not improve\n",
      "Epoch 1646/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.1045e-05\n",
      "\n",
      "Epoch 01646: loss did not improve\n",
      "Epoch 1647/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 6.0910e-05\n",
      "\n",
      "Epoch 01647: loss did not improve\n",
      "Epoch 1648/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.0477e-05\n",
      "\n",
      "Epoch 01648: loss did not improve\n",
      "Epoch 1649/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.0986e-05\n",
      "\n",
      "Epoch 01649: loss did not improve\n",
      "Epoch 1650/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.0667e-05\n",
      "\n",
      "Epoch 01650: loss did not improve\n",
      "Epoch 1651/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.1387e-05\n",
      "\n",
      "Epoch 01651: loss did not improve\n",
      "Epoch 1652/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.0647e-05\n",
      "\n",
      "Epoch 01652: loss did not improve\n",
      "Epoch 1653/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.0693e-05\n",
      "\n",
      "Epoch 01653: loss did not improve\n",
      "Epoch 1654/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0080e-05\n",
      "\n",
      "Epoch 01654: loss did not improve\n",
      "Epoch 1655/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.0385e-05\n",
      "\n",
      "Epoch 01655: loss did not improve\n",
      "Epoch 1656/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0384e-05\n",
      "\n",
      "Epoch 01656: loss did not improve\n",
      "Epoch 1657/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.3470e-05\n",
      "\n",
      "Epoch 01657: loss did not improve\n",
      "Epoch 1658/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.3297e-05\n",
      "\n",
      "Epoch 01658: loss did not improve\n",
      "Epoch 1659/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.5447e-05\n",
      "\n",
      "Epoch 01659: loss did not improve\n",
      "Epoch 1660/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.2707e-05\n",
      "\n",
      "Epoch 01660: loss did not improve\n",
      "Epoch 1661/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.1661e-05\n",
      "\n",
      "Epoch 01661: loss did not improve\n",
      "Epoch 1662/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0102e-05\n",
      "\n",
      "Epoch 01662: loss did not improve\n",
      "Epoch 1663/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9631e-05\n",
      "\n",
      "Epoch 01663: loss did not improve\n",
      "Epoch 1664/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 5.9887e-05\n",
      "\n",
      "Epoch 01664: loss did not improve\n",
      "Epoch 1665/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.9757e-05\n",
      "\n",
      "Epoch 01665: loss did not improve\n",
      "Epoch 1666/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.9394e-05\n",
      "\n",
      "Epoch 01666: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1667/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9361e-05\n",
      "\n",
      "Epoch 01667: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1668/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9822e-05\n",
      "\n",
      "Epoch 01668: loss did not improve\n",
      "Epoch 1669/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.0602e-05\n",
      "\n",
      "Epoch 01669: loss did not improve\n",
      "Epoch 1670/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9709e-05\n",
      "\n",
      "Epoch 01670: loss did not improve\n",
      "Epoch 1671/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.9669e-05\n",
      "\n",
      "Epoch 01671: loss did not improve\n",
      "Epoch 1672/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9815e-05\n",
      "\n",
      "Epoch 01672: loss did not improve\n",
      "Epoch 1673/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9994e-05\n",
      "\n",
      "Epoch 01673: loss did not improve\n",
      "Epoch 1674/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0164e-05\n",
      "\n",
      "Epoch 01674: loss did not improve\n",
      "Epoch 1675/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.0322e-05\n",
      "\n",
      "Epoch 01675: loss did not improve\n",
      "Epoch 1676/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.9981e-05\n",
      "\n",
      "Epoch 01676: loss did not improve\n",
      "Epoch 1677/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0077e-05\n",
      "\n",
      "Epoch 01677: loss did not improve\n",
      "Epoch 1678/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9427e-05\n",
      "\n",
      "Epoch 01678: loss did not improve\n",
      "Epoch 1679/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.9319e-05\n",
      "\n",
      "Epoch 01679: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1680/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9267e-05\n",
      "\n",
      "Epoch 01680: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1681/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9481e-05\n",
      "\n",
      "Epoch 01681: loss did not improve\n",
      "Epoch 1682/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0621e-05\n",
      "\n",
      "Epoch 01682: loss did not improve\n",
      "Epoch 1683/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.1960e-05\n",
      "\n",
      "Epoch 01683: loss did not improve\n",
      "Epoch 1684/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.3001e-05\n",
      "\n",
      "Epoch 01684: loss did not improve\n",
      "Epoch 1685/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.2317e-05\n",
      "\n",
      "Epoch 01685: loss did not improve\n",
      "Epoch 1686/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.1073e-05\n",
      "\n",
      "Epoch 01686: loss did not improve\n",
      "Epoch 1687/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0731e-05\n",
      "\n",
      "Epoch 01687: loss did not improve\n",
      "Epoch 1688/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.1575e-05\n",
      "\n",
      "Epoch 01688: loss did not improve\n",
      "Epoch 1689/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.1880e-05\n",
      "\n",
      "Epoch 01689: loss did not improve\n",
      "Epoch 1690/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.9873e-05\n",
      "\n",
      "Epoch 01690: loss did not improve\n",
      "Epoch 1691/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.9327e-05\n",
      "\n",
      "Epoch 01691: loss did not improve\n",
      "Epoch 1692/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.9413e-05\n",
      "\n",
      "Epoch 01692: loss did not improve\n",
      "Epoch 1693/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.0373e-05\n",
      "\n",
      "Epoch 01693: loss did not improve\n",
      "Epoch 1694/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.1603e-05\n",
      "\n",
      "Epoch 01694: loss did not improve\n",
      "Epoch 1695/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.1004e-05\n",
      "\n",
      "Epoch 01695: loss did not improve\n",
      "Epoch 1696/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.0019e-05\n",
      "\n",
      "Epoch 01696: loss did not improve\n",
      "Epoch 1697/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9822e-05\n",
      "\n",
      "Epoch 01697: loss did not improve\n",
      "Epoch 1698/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 5.9278e-05\n",
      "\n",
      "Epoch 01698: loss did not improve\n",
      "Epoch 1699/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9130e-05\n",
      "\n",
      "Epoch 01699: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1700/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.9550e-05\n",
      "\n",
      "Epoch 01700: loss did not improve\n",
      "Epoch 1701/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.0128e-05\n",
      "\n",
      "Epoch 01701: loss did not improve\n",
      "Epoch 1702/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1908e-05\n",
      "\n",
      "Epoch 01702: loss did not improve\n",
      "Epoch 1703/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9953e-05\n",
      "\n",
      "Epoch 01703: loss did not improve\n",
      "Epoch 1704/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0363e-05\n",
      "\n",
      "Epoch 01704: loss did not improve\n",
      "Epoch 1705/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0982e-05\n",
      "\n",
      "Epoch 01705: loss did not improve\n",
      "Epoch 1706/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.0195e-05\n",
      "\n",
      "Epoch 01706: loss did not improve\n",
      "Epoch 1707/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9386e-05\n",
      "\n",
      "Epoch 01707: loss did not improve\n",
      "Epoch 1708/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.9056e-05\n",
      "\n",
      "Epoch 01708: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1709/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.9276e-05\n",
      "\n",
      "Epoch 01709: loss did not improve\n",
      "Epoch 1710/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.9427e-05\n",
      "\n",
      "Epoch 01710: loss did not improve\n",
      "Epoch 1711/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9760e-05\n",
      "\n",
      "Epoch 01711: loss did not improve\n",
      "Epoch 1712/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.9826e-05\n",
      "\n",
      "Epoch 01712: loss did not improve\n",
      "Epoch 1713/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.9858e-05\n",
      "\n",
      "Epoch 01713: loss did not improve\n",
      "Epoch 1714/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 5.9943e-05\n",
      "\n",
      "Epoch 01714: loss did not improve\n",
      "Epoch 1715/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.0520e-05\n",
      "\n",
      "Epoch 01715: loss did not improve\n",
      "Epoch 1716/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.2026e-05\n",
      "\n",
      "Epoch 01716: loss did not improve\n",
      "Epoch 1717/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.2654e-05\n",
      "\n",
      "Epoch 01717: loss did not improve\n",
      "Epoch 1718/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.0745e-05\n",
      "\n",
      "Epoch 01718: loss did not improve\n",
      "Epoch 1719/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 5.9006e-05\n",
      "\n",
      "Epoch 01719: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1720/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1502e-05\n",
      "\n",
      "Epoch 01720: loss did not improve\n",
      "Epoch 1721/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.6494e-05\n",
      "\n",
      "Epoch 01721: loss did not improve\n",
      "Epoch 1722/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.3191e-05\n",
      "\n",
      "Epoch 01722: loss did not improve\n",
      "Epoch 1723/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.2179e-05\n",
      "\n",
      "Epoch 01723: loss did not improve\n",
      "Epoch 1724/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.5412e-05\n",
      "\n",
      "Epoch 01724: loss did not improve\n",
      "Epoch 1725/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.3282e-05\n",
      "\n",
      "Epoch 01725: loss did not improve\n",
      "Epoch 1726/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.0965e-05\n",
      "\n",
      "Epoch 01726: loss did not improve\n",
      "Epoch 1727/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.0064e-05\n",
      "\n",
      "Epoch 01727: loss did not improve\n",
      "Epoch 1728/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.0104e-05\n",
      "\n",
      "Epoch 01728: loss did not improve\n",
      "Epoch 1729/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.9756e-05\n",
      "\n",
      "Epoch 01729: loss did not improve\n",
      "Epoch 1730/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9318e-05\n",
      "\n",
      "Epoch 01730: loss did not improve\n",
      "Epoch 1731/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.0822e-05\n",
      "\n",
      "Epoch 01731: loss did not improve\n",
      "Epoch 1732/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.4283e-05\n",
      "\n",
      "Epoch 01732: loss did not improve\n",
      "Epoch 1733/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.3389e-05\n",
      "\n",
      "Epoch 01733: loss did not improve\n",
      "Epoch 1734/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.4233e-05\n",
      "\n",
      "Epoch 01734: loss did not improve\n",
      "Epoch 1735/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.2076e-05\n",
      "\n",
      "Epoch 01735: loss did not improve\n",
      "Epoch 1736/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.0237e-05\n",
      "\n",
      "Epoch 01736: loss did not improve\n",
      "Epoch 1737/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.0716e-05\n",
      "\n",
      "Epoch 01737: loss did not improve\n",
      "Epoch 1738/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.0252e-05\n",
      "\n",
      "Epoch 01738: loss did not improve\n",
      "Epoch 1739/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.9404e-05\n",
      "\n",
      "Epoch 01739: loss did not improve\n",
      "Epoch 1740/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.8925e-05\n",
      "\n",
      "Epoch 01740: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1741/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9321e-05\n",
      "\n",
      "Epoch 01741: loss did not improve\n",
      "Epoch 1742/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.8746e-05\n",
      "\n",
      "Epoch 01742: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1743/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0990e-05\n",
      "\n",
      "Epoch 01743: loss did not improve\n",
      "Epoch 1744/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.9566e-05\n",
      "\n",
      "Epoch 01744: loss did not improve\n",
      "Epoch 1745/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.0624e-05\n",
      "\n",
      "Epoch 01745: loss did not improve\n",
      "Epoch 1746/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.2689e-05\n",
      "\n",
      "Epoch 01746: loss did not improve\n",
      "Epoch 1747/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.2112e-05\n",
      "\n",
      "Epoch 01747: loss did not improve\n",
      "Epoch 1748/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1823e-05\n",
      "\n",
      "Epoch 01748: loss did not improve\n",
      "Epoch 1749/2000\n",
      "2014/2014 [==============================] - 0s 25us/step - loss: 6.2164e-05\n",
      "\n",
      "Epoch 01749: loss did not improve\n",
      "Epoch 1750/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.2860e-05\n",
      "\n",
      "Epoch 01750: loss did not improve\n",
      "Epoch 1751/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.3478e-05\n",
      "\n",
      "Epoch 01751: loss did not improve\n",
      "Epoch 1752/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0672e-05\n",
      "\n",
      "Epoch 01752: loss did not improve\n",
      "Epoch 1753/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.9109e-05\n",
      "\n",
      "Epoch 01753: loss did not improve\n",
      "Epoch 1754/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.8717e-05\n",
      "\n",
      "Epoch 01754: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1755/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.9347e-05\n",
      "\n",
      "Epoch 01755: loss did not improve\n",
      "Epoch 1756/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9243e-05\n",
      "\n",
      "Epoch 01756: loss did not improve\n",
      "Epoch 1757/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.8926e-05\n",
      "\n",
      "Epoch 01757: loss did not improve\n",
      "Epoch 1758/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9908e-05\n",
      "\n",
      "Epoch 01758: loss did not improve\n",
      "Epoch 1759/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9465e-05\n",
      "\n",
      "Epoch 01759: loss did not improve\n",
      "Epoch 1760/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8950e-05\n",
      "\n",
      "Epoch 01760: loss did not improve\n",
      "Epoch 1761/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 5.9973e-05\n",
      "\n",
      "Epoch 01761: loss did not improve\n",
      "Epoch 1762/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9413e-05\n",
      "\n",
      "Epoch 01762: loss did not improve\n",
      "Epoch 1763/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.8861e-05\n",
      "\n",
      "Epoch 01763: loss did not improve\n",
      "Epoch 1764/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.9146e-05\n",
      "\n",
      "Epoch 01764: loss did not improve\n",
      "Epoch 1765/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 5.8649e-05\n",
      "\n",
      "Epoch 01765: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1766/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.9668e-05\n",
      "\n",
      "Epoch 01766: loss did not improve\n",
      "Epoch 1767/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8709e-05\n",
      "\n",
      "Epoch 01767: loss did not improve\n",
      "Epoch 1768/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.8855e-05\n",
      "\n",
      "Epoch 01768: loss did not improve\n",
      "Epoch 1769/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.8663e-05\n",
      "\n",
      "Epoch 01769: loss did not improve\n",
      "Epoch 1770/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.8652e-05\n",
      "\n",
      "Epoch 01770: loss did not improve\n",
      "Epoch 1771/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.9650e-05\n",
      "\n",
      "Epoch 01771: loss did not improve\n",
      "Epoch 1772/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 5.9038e-05\n",
      "\n",
      "Epoch 01772: loss did not improve\n",
      "Epoch 1773/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.8861e-05\n",
      "\n",
      "Epoch 01773: loss did not improve\n",
      "Epoch 1774/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9300e-05\n",
      "\n",
      "Epoch 01774: loss did not improve\n",
      "Epoch 1775/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9552e-05\n",
      "\n",
      "Epoch 01775: loss did not improve\n",
      "Epoch 1776/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9341e-05\n",
      "\n",
      "Epoch 01776: loss did not improve\n",
      "Epoch 1777/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9733e-05\n",
      "\n",
      "Epoch 01777: loss did not improve\n",
      "Epoch 1778/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.8771e-05\n",
      "\n",
      "Epoch 01778: loss did not improve\n",
      "Epoch 1779/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.8918e-05\n",
      "\n",
      "Epoch 01779: loss did not improve\n",
      "Epoch 1780/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9405e-05\n",
      "\n",
      "Epoch 01780: loss did not improve\n",
      "Epoch 1781/2000\n",
      "2014/2014 [==============================] - ETA: 0s - loss: 5.4652e-0 - 0s 31us/step - loss: 6.0513e-05\n",
      "\n",
      "Epoch 01781: loss did not improve\n",
      "Epoch 1782/2000\n",
      "2014/2014 [==============================] - 0s 35us/step - loss: 6.0143e-05\n",
      "\n",
      "Epoch 01782: loss did not improve\n",
      "Epoch 1783/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.9558e-05\n",
      "\n",
      "Epoch 01783: loss did not improve\n",
      "Epoch 1784/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.9276e-05\n",
      "\n",
      "Epoch 01784: loss did not improve\n",
      "Epoch 1785/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9638e-05\n",
      "\n",
      "Epoch 01785: loss did not improve\n",
      "Epoch 1786/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 5.8516e-05\n",
      "\n",
      "Epoch 01786: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1787/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.8930e-05\n",
      "\n",
      "Epoch 01787: loss did not improve\n",
      "Epoch 1788/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.8927e-05\n",
      "\n",
      "Epoch 01788: loss did not improve\n",
      "Epoch 1789/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9310e-05\n",
      "\n",
      "Epoch 01789: loss did not improve\n",
      "Epoch 1790/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 5.9564e-05\n",
      "\n",
      "Epoch 01790: loss did not improve\n",
      "Epoch 1791/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0206e-05\n",
      "\n",
      "Epoch 01791: loss did not improve\n",
      "Epoch 1792/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.0983e-05\n",
      "\n",
      "Epoch 01792: loss did not improve\n",
      "Epoch 1793/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9769e-05\n",
      "\n",
      "Epoch 01793: loss did not improve\n",
      "Epoch 1794/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9016e-05\n",
      "\n",
      "Epoch 01794: loss did not improve\n",
      "Epoch 1795/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9095e-05\n",
      "\n",
      "Epoch 01795: loss did not improve\n",
      "Epoch 1796/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.8671e-05\n",
      "\n",
      "Epoch 01796: loss did not improve\n",
      "Epoch 1797/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.8853e-05\n",
      "\n",
      "Epoch 01797: loss did not improve\n",
      "Epoch 1798/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.9087e-05\n",
      "\n",
      "Epoch 01798: loss did not improve\n",
      "Epoch 1799/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.1123e-05\n",
      "\n",
      "Epoch 01799: loss did not improve\n",
      "Epoch 1800/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.0928e-05\n",
      "\n",
      "Epoch 01800: loss did not improve\n",
      "Epoch 1801/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.0284e-05\n",
      "\n",
      "Epoch 01801: loss did not improve\n",
      "Epoch 1802/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9329e-05\n",
      "\n",
      "Epoch 01802: loss did not improve\n",
      "Epoch 1803/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 6.1284e-05\n",
      "\n",
      "Epoch 01803: loss did not improve\n",
      "Epoch 1804/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0959e-05\n",
      "\n",
      "Epoch 01804: loss did not improve\n",
      "Epoch 1805/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.9452e-05\n",
      "\n",
      "Epoch 01805: loss did not improve\n",
      "Epoch 1806/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8758e-05\n",
      "\n",
      "Epoch 01806: loss did not improve\n",
      "Epoch 1807/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9028e-05\n",
      "\n",
      "Epoch 01807: loss did not improve\n",
      "Epoch 1808/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8946e-05\n",
      "\n",
      "Epoch 01808: loss did not improve\n",
      "Epoch 1809/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.8562e-05\n",
      "\n",
      "Epoch 01809: loss did not improve\n",
      "Epoch 1810/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.8521e-05\n",
      "\n",
      "Epoch 01810: loss did not improve\n",
      "Epoch 1811/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.0065e-05\n",
      "\n",
      "Epoch 01811: loss did not improve\n",
      "Epoch 1812/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.1403e-05\n",
      "\n",
      "Epoch 01812: loss did not improve\n",
      "Epoch 1813/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.9317e-05\n",
      "\n",
      "Epoch 01813: loss did not improve\n",
      "Epoch 1814/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.9581e-05\n",
      "\n",
      "Epoch 01814: loss did not improve\n",
      "Epoch 1815/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.9720e-05\n",
      "\n",
      "Epoch 01815: loss did not improve\n",
      "Epoch 1816/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 5.9800e-05\n",
      "\n",
      "Epoch 01816: loss did not improve\n",
      "Epoch 1817/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.8913e-05\n",
      "\n",
      "Epoch 01817: loss did not improve\n",
      "Epoch 1818/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8351e-05\n",
      "\n",
      "Epoch 01818: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1819/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.8572e-05\n",
      "\n",
      "Epoch 01819: loss did not improve\n",
      "Epoch 1820/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.9156e-05\n",
      "\n",
      "Epoch 01820: loss did not improve\n",
      "Epoch 1821/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9112e-05\n",
      "\n",
      "Epoch 01821: loss did not improve\n",
      "Epoch 1822/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.2216e-05\n",
      "\n",
      "Epoch 01822: loss did not improve\n",
      "Epoch 1823/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.0397e-05\n",
      "\n",
      "Epoch 01823: loss did not improve\n",
      "Epoch 1824/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.8853e-05\n",
      "\n",
      "Epoch 01824: loss did not improve\n",
      "Epoch 1825/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.0204e-05\n",
      "\n",
      "Epoch 01825: loss did not improve\n",
      "Epoch 1826/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0741e-05\n",
      "\n",
      "Epoch 01826: loss did not improve\n",
      "Epoch 1827/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1737e-05\n",
      "\n",
      "Epoch 01827: loss did not improve\n",
      "Epoch 1828/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.3252e-05\n",
      "\n",
      "Epoch 01828: loss did not improve\n",
      "Epoch 1829/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.3629e-05\n",
      "\n",
      "Epoch 01829: loss did not improve\n",
      "Epoch 1830/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.1661e-05\n",
      "\n",
      "Epoch 01830: loss did not improve\n",
      "Epoch 1831/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9589e-05\n",
      "\n",
      "Epoch 01831: loss did not improve\n",
      "Epoch 1832/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.1730e-05\n",
      "\n",
      "Epoch 01832: loss did not improve\n",
      "Epoch 1833/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 6.3027e-05\n",
      "\n",
      "Epoch 01833: loss did not improve\n",
      "Epoch 1834/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9700e-05\n",
      "\n",
      "Epoch 01834: loss did not improve\n",
      "Epoch 1835/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.0305e-05\n",
      "\n",
      "Epoch 01835: loss did not improve\n",
      "Epoch 1836/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 5.9797e-05\n",
      "\n",
      "Epoch 01836: loss did not improve\n",
      "Epoch 1837/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.0456e-05\n",
      "\n",
      "Epoch 01837: loss did not improve\n",
      "Epoch 1838/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.1080e-05\n",
      "\n",
      "Epoch 01838: loss did not improve\n",
      "Epoch 1839/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.0214e-05\n",
      "\n",
      "Epoch 01839: loss did not improve\n",
      "Epoch 1840/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.0151e-05\n",
      "\n",
      "Epoch 01840: loss did not improve\n",
      "Epoch 1841/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.0390e-05\n",
      "\n",
      "Epoch 01841: loss did not improve\n",
      "Epoch 1842/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0495e-05\n",
      "\n",
      "Epoch 01842: loss did not improve\n",
      "Epoch 1843/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.0659e-05\n",
      "\n",
      "Epoch 01843: loss did not improve\n",
      "Epoch 1844/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.0388e-05\n",
      "\n",
      "Epoch 01844: loss did not improve\n",
      "Epoch 1845/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9658e-05\n",
      "\n",
      "Epoch 01845: loss did not improve\n",
      "Epoch 1846/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9168e-05\n",
      "\n",
      "Epoch 01846: loss did not improve\n",
      "Epoch 1847/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.2619e-05\n",
      "\n",
      "Epoch 01847: loss did not improve\n",
      "Epoch 1848/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.5171e-05\n",
      "\n",
      "Epoch 01848: loss did not improve\n",
      "Epoch 1849/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.2448e-05\n",
      "\n",
      "Epoch 01849: loss did not improve\n",
      "Epoch 1850/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.2211e-05\n",
      "\n",
      "Epoch 01850: loss did not improve\n",
      "Epoch 1851/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.9652e-05\n",
      "\n",
      "Epoch 01851: loss did not improve\n",
      "Epoch 1852/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8310e-05\n",
      "\n",
      "Epoch 01852: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1853/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.8546e-05\n",
      "\n",
      "Epoch 01853: loss did not improve\n",
      "Epoch 1854/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.9956e-05\n",
      "\n",
      "Epoch 01854: loss did not improve\n",
      "Epoch 1855/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 5.9790e-05\n",
      "\n",
      "Epoch 01855: loss did not improve\n",
      "Epoch 1856/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.0606e-05\n",
      "\n",
      "Epoch 01856: loss did not improve\n",
      "Epoch 1857/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.0029e-05\n",
      "\n",
      "Epoch 01857: loss did not improve\n",
      "Epoch 1858/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.9214e-05\n",
      "\n",
      "Epoch 01858: loss did not improve\n",
      "Epoch 1859/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0121e-05\n",
      "\n",
      "Epoch 01859: loss did not improve\n",
      "Epoch 1860/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1318e-05\n",
      "\n",
      "Epoch 01860: loss did not improve\n",
      "Epoch 1861/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.2238e-05\n",
      "\n",
      "Epoch 01861: loss did not improve\n",
      "Epoch 1862/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.2210e-05\n",
      "\n",
      "Epoch 01862: loss did not improve\n",
      "Epoch 1863/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.8921e-05\n",
      "\n",
      "Epoch 01863: loss did not improve\n",
      "Epoch 1864/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8756e-05\n",
      "\n",
      "Epoch 01864: loss did not improve\n",
      "Epoch 1865/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.9932e-05\n",
      "\n",
      "Epoch 01865: loss did not improve\n",
      "Epoch 1866/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.9183e-05\n",
      "\n",
      "Epoch 01866: loss did not improve\n",
      "Epoch 1867/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 5.9645e-05\n",
      "\n",
      "Epoch 01867: loss did not improve\n",
      "Epoch 1868/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 5.9061e-05\n",
      "\n",
      "Epoch 01868: loss did not improve\n",
      "Epoch 1869/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8983e-05\n",
      "\n",
      "Epoch 01869: loss did not improve\n",
      "Epoch 1870/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 5.9540e-05\n",
      "\n",
      "Epoch 01870: loss did not improve\n",
      "Epoch 1871/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.8422e-05\n",
      "\n",
      "Epoch 01871: loss did not improve\n",
      "Epoch 1872/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 5.8254e-05\n",
      "\n",
      "Epoch 01872: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1873/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 5.8825e-05\n",
      "\n",
      "Epoch 01873: loss did not improve\n",
      "Epoch 1874/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.9847e-05\n",
      "\n",
      "Epoch 01874: loss did not improve\n",
      "Epoch 1875/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8950e-05\n",
      "\n",
      "Epoch 01875: loss did not improve\n",
      "Epoch 1876/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.8754e-05\n",
      "\n",
      "Epoch 01876: loss did not improve\n",
      "Epoch 1877/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9040e-05\n",
      "\n",
      "Epoch 01877: loss did not improve\n",
      "Epoch 1878/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.9192e-05\n",
      "\n",
      "Epoch 01878: loss did not improve\n",
      "Epoch 1879/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.8669e-05\n",
      "\n",
      "Epoch 01879: loss did not improve\n",
      "Epoch 1880/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8250e-05\n",
      "\n",
      "Epoch 01880: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1881/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.9799e-05\n",
      "\n",
      "Epoch 01881: loss did not improve\n",
      "Epoch 1882/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9599e-05\n",
      "\n",
      "Epoch 01882: loss did not improve\n",
      "Epoch 1883/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.8360e-05\n",
      "\n",
      "Epoch 01883: loss did not improve\n",
      "Epoch 1884/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 5.9114e-05\n",
      "\n",
      "Epoch 01884: loss did not improve\n",
      "Epoch 1885/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.9735e-05\n",
      "\n",
      "Epoch 01885: loss did not improve\n",
      "Epoch 1886/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.0996e-05\n",
      "\n",
      "Epoch 01886: loss did not improve\n",
      "Epoch 1887/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.1745e-05\n",
      "\n",
      "Epoch 01887: loss did not improve\n",
      "Epoch 1888/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.4220e-05\n",
      "\n",
      "Epoch 01888: loss did not improve\n",
      "Epoch 1889/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.3509e-05\n",
      "\n",
      "Epoch 01889: loss did not improve\n",
      "Epoch 1890/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.1034e-05\n",
      "\n",
      "Epoch 01890: loss did not improve\n",
      "Epoch 1891/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.2072e-05\n",
      "\n",
      "Epoch 01891: loss did not improve\n",
      "Epoch 1892/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.2655e-05\n",
      "\n",
      "Epoch 01892: loss did not improve\n",
      "Epoch 1893/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.1747e-05\n",
      "\n",
      "Epoch 01893: loss did not improve\n",
      "Epoch 1894/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.0655e-05\n",
      "\n",
      "Epoch 01894: loss did not improve\n",
      "Epoch 1895/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.2250e-05\n",
      "\n",
      "Epoch 01895: loss did not improve\n",
      "Epoch 1896/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 6.0220e-05\n",
      "\n",
      "Epoch 01896: loss did not improve\n",
      "Epoch 1897/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9624e-05\n",
      "\n",
      "Epoch 01897: loss did not improve\n",
      "Epoch 1898/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.0016e-05\n",
      "\n",
      "Epoch 01898: loss did not improve\n",
      "Epoch 1899/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8323e-05\n",
      "\n",
      "Epoch 01899: loss did not improve\n",
      "Epoch 1900/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.8363e-05\n",
      "\n",
      "Epoch 01900: loss did not improve\n",
      "Epoch 1901/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 5.9417e-05\n",
      "\n",
      "Epoch 01901: loss did not improve\n",
      "Epoch 1902/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.0714e-05\n",
      "\n",
      "Epoch 01902: loss did not improve\n",
      "Epoch 1903/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 6.1022e-05\n",
      "\n",
      "Epoch 01903: loss did not improve\n",
      "Epoch 1904/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.0374e-05\n",
      "\n",
      "Epoch 01904: loss did not improve\n",
      "Epoch 1905/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9038e-05\n",
      "\n",
      "Epoch 01905: loss did not improve\n",
      "Epoch 1906/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9005e-05\n",
      "\n",
      "Epoch 01906: loss did not improve\n",
      "Epoch 1907/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9024e-05\n",
      "\n",
      "Epoch 01907: loss did not improve\n",
      "Epoch 1908/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9853e-05\n",
      "\n",
      "Epoch 01908: loss did not improve\n",
      "Epoch 1909/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.1733e-05\n",
      "\n",
      "Epoch 01909: loss did not improve\n",
      "Epoch 1910/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.2533e-05\n",
      "\n",
      "Epoch 01910: loss did not improve\n",
      "Epoch 1911/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0837e-05\n",
      "\n",
      "Epoch 01911: loss did not improve\n",
      "Epoch 1912/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9724e-05\n",
      "\n",
      "Epoch 01912: loss did not improve\n",
      "Epoch 1913/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.8618e-05\n",
      "\n",
      "Epoch 01913: loss did not improve\n",
      "Epoch 1914/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.8430e-05\n",
      "\n",
      "Epoch 01914: loss did not improve\n",
      "Epoch 1915/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8551e-05\n",
      "\n",
      "Epoch 01915: loss did not improve\n",
      "Epoch 1916/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.9118e-05\n",
      "\n",
      "Epoch 01916: loss did not improve\n",
      "Epoch 1917/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.0959e-05\n",
      "\n",
      "Epoch 01917: loss did not improve\n",
      "Epoch 1918/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.0369e-05\n",
      "\n",
      "Epoch 01918: loss did not improve\n",
      "Epoch 1919/2000\n",
      "2014/2014 [==============================] - 0s 33us/step - loss: 6.0571e-05\n",
      "\n",
      "Epoch 01919: loss did not improve\n",
      "Epoch 1920/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 6.0688e-05\n",
      "\n",
      "Epoch 01920: loss did not improve\n",
      "Epoch 1921/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8924e-05\n",
      "\n",
      "Epoch 01921: loss did not improve\n",
      "Epoch 1922/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9159e-05\n",
      "\n",
      "Epoch 01922: loss did not improve\n",
      "Epoch 1923/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9796e-05\n",
      "\n",
      "Epoch 01923: loss did not improve\n",
      "Epoch 1924/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 6.0309e-05\n",
      "\n",
      "Epoch 01924: loss did not improve\n",
      "Epoch 1925/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9275e-05\n",
      "\n",
      "Epoch 01925: loss did not improve\n",
      "Epoch 1926/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9928e-05\n",
      "\n",
      "Epoch 01926: loss did not improve\n",
      "Epoch 1927/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.8816e-05\n",
      "\n",
      "Epoch 01927: loss did not improve\n",
      "Epoch 1928/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8822e-05\n",
      "\n",
      "Epoch 01928: loss did not improve\n",
      "Epoch 1929/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9326e-05\n",
      "\n",
      "Epoch 01929: loss did not improve\n",
      "Epoch 1930/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 5.8619e-05\n",
      "\n",
      "Epoch 01930: loss did not improve\n",
      "Epoch 1931/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.8633e-05\n",
      "\n",
      "Epoch 01931: loss did not improve\n",
      "Epoch 1932/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.8242e-05\n",
      "\n",
      "Epoch 01932: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1933/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 5.8442e-05\n",
      "\n",
      "Epoch 01933: loss did not improve\n",
      "Epoch 1934/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8450e-05\n",
      "\n",
      "Epoch 01934: loss did not improve\n",
      "Epoch 1935/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.9290e-05\n",
      "\n",
      "Epoch 01935: loss did not improve\n",
      "Epoch 1936/2000\n",
      "2014/2014 [==============================] - 0s 37us/step - loss: 5.9407e-05\n",
      "\n",
      "Epoch 01936: loss did not improve\n",
      "Epoch 1937/2000\n",
      "2014/2014 [==============================] - 0s 26us/step - loss: 5.8832e-05\n",
      "\n",
      "Epoch 01937: loss did not improve\n",
      "Epoch 1938/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.8701e-05\n",
      "\n",
      "Epoch 01938: loss did not improve\n",
      "Epoch 1939/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8135e-05\n",
      "\n",
      "Epoch 01939: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1940/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.8800e-05\n",
      "\n",
      "Epoch 01940: loss did not improve\n",
      "Epoch 1941/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.8273e-05\n",
      "\n",
      "Epoch 01941: loss did not improve\n",
      "Epoch 1942/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.8976e-05\n",
      "\n",
      "Epoch 01942: loss did not improve\n",
      "Epoch 1943/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.8390e-05\n",
      "\n",
      "Epoch 01943: loss did not improve\n",
      "Epoch 1944/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.8669e-05\n",
      "\n",
      "Epoch 01944: loss did not improve\n",
      "Epoch 1945/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.8498e-05\n",
      "\n",
      "Epoch 01945: loss did not improve\n",
      "Epoch 1946/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9383e-05\n",
      "\n",
      "Epoch 01946: loss did not improve\n",
      "Epoch 1947/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.8505e-05\n",
      "\n",
      "Epoch 01947: loss did not improve\n",
      "Epoch 1948/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9904e-05\n",
      "\n",
      "Epoch 01948: loss did not improve\n",
      "Epoch 1949/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.8191e-05\n",
      "\n",
      "Epoch 01949: loss did not improve\n",
      "Epoch 1950/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8552e-05\n",
      "\n",
      "Epoch 01950: loss did not improve\n",
      "Epoch 1951/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.8701e-05\n",
      "\n",
      "Epoch 01951: loss did not improve\n",
      "Epoch 1952/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.8858e-05\n",
      "\n",
      "Epoch 01952: loss did not improve\n",
      "Epoch 1953/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 6.1165e-05\n",
      "\n",
      "Epoch 01953: loss did not improve\n",
      "Epoch 1954/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.9183e-05\n",
      "\n",
      "Epoch 01954: loss did not improve\n",
      "Epoch 1955/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8626e-05\n",
      "\n",
      "Epoch 01955: loss did not improve\n",
      "Epoch 1956/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 6.0199e-05\n",
      "\n",
      "Epoch 01956: loss did not improve\n",
      "Epoch 1957/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9937e-05\n",
      "\n",
      "Epoch 01957: loss did not improve\n",
      "Epoch 1958/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9882e-05\n",
      "\n",
      "Epoch 01958: loss did not improve\n",
      "Epoch 1959/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9567e-05\n",
      "\n",
      "Epoch 01959: loss did not improve\n",
      "Epoch 1960/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8389e-05\n",
      "\n",
      "Epoch 01960: loss did not improve\n",
      "Epoch 1961/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9349e-05\n",
      "\n",
      "Epoch 01961: loss did not improve\n",
      "Epoch 1962/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.8694e-05\n",
      "\n",
      "Epoch 01962: loss did not improve\n",
      "Epoch 1963/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.8347e-05\n",
      "\n",
      "Epoch 01963: loss did not improve\n",
      "Epoch 1964/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.9108e-05\n",
      "\n",
      "Epoch 01964: loss did not improve\n",
      "Epoch 1965/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.8975e-05\n",
      "\n",
      "Epoch 01965: loss did not improve\n",
      "Epoch 1966/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.8344e-05\n",
      "\n",
      "Epoch 01966: loss did not improve\n",
      "Epoch 1967/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.8634e-05\n",
      "\n",
      "Epoch 01967: loss did not improve\n",
      "Epoch 1968/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.8569e-05\n",
      "\n",
      "Epoch 01968: loss did not improve\n",
      "Epoch 1969/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8416e-05\n",
      "\n",
      "Epoch 01969: loss did not improve\n",
      "Epoch 1970/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 5.8044e-05\n",
      "\n",
      "Epoch 01970: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1971/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.8108e-05\n",
      "\n",
      "Epoch 01971: loss did not improve\n",
      "Epoch 1972/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.9044e-05\n",
      "\n",
      "Epoch 01972: loss did not improve\n",
      "Epoch 1973/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.7984e-05\n",
      "\n",
      "Epoch 01973: loss improved from 0.00006 to 0.00006, saving model to Test32-B512-LB7-D10.hdf5\n",
      "Epoch 1974/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8535e-05\n",
      "\n",
      "Epoch 01974: loss did not improve\n",
      "Epoch 1975/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8281e-05\n",
      "\n",
      "Epoch 01975: loss did not improve\n",
      "Epoch 1976/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.8167e-05\n",
      "\n",
      "Epoch 01976: loss did not improve\n",
      "Epoch 1977/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.8030e-05\n",
      "\n",
      "Epoch 01977: loss did not improve\n",
      "Epoch 1978/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8071e-05\n",
      "\n",
      "Epoch 01978: loss did not improve\n",
      "Epoch 1979/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.9082e-05\n",
      "\n",
      "Epoch 01979: loss did not improve\n",
      "Epoch 1980/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8612e-05\n",
      "\n",
      "Epoch 01980: loss did not improve\n",
      "Epoch 1981/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.8816e-05\n",
      "\n",
      "Epoch 01981: loss did not improve\n",
      "Epoch 1982/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9209e-05\n",
      "\n",
      "Epoch 01982: loss did not improve\n",
      "Epoch 1983/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.9620e-05\n",
      "\n",
      "Epoch 01983: loss did not improve\n",
      "Epoch 1984/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9533e-05\n",
      "\n",
      "Epoch 01984: loss did not improve\n",
      "Epoch 1985/2000\n",
      "2014/2014 [==============================] - 0s 32us/step - loss: 5.8741e-05\n",
      "\n",
      "Epoch 01985: loss did not improve\n",
      "Epoch 1986/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.8183e-05\n",
      "\n",
      "Epoch 01986: loss did not improve\n",
      "Epoch 1987/2000\n",
      "2014/2014 [==============================] - 0s 34us/step - loss: 5.8719e-05\n",
      "\n",
      "Epoch 01987: loss did not improve\n",
      "Epoch 1988/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.9060e-05\n",
      "\n",
      "Epoch 01988: loss did not improve\n",
      "Epoch 1989/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8263e-05\n",
      "\n",
      "Epoch 01989: loss did not improve\n",
      "Epoch 1990/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.8087e-05\n",
      "\n",
      "Epoch 01990: loss did not improve\n",
      "Epoch 1991/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.8362e-05\n",
      "\n",
      "Epoch 01991: loss did not improve\n",
      "Epoch 1992/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.9503e-05\n",
      "\n",
      "Epoch 01992: loss did not improve\n",
      "Epoch 1993/2000\n",
      "2014/2014 [==============================] - 0s 29us/step - loss: 5.9111e-05\n",
      "\n",
      "Epoch 01993: loss did not improve\n",
      "Epoch 1994/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.8062e-05\n",
      "\n",
      "Epoch 01994: loss did not improve\n",
      "Epoch 1995/2000\n",
      "2014/2014 [==============================] - 0s 27us/step - loss: 5.8721e-05\n",
      "\n",
      "Epoch 01995: loss did not improve\n",
      "Epoch 1996/2000\n",
      "2014/2014 [==============================] - 0s 28us/step - loss: 5.9073e-05\n",
      "\n",
      "Epoch 01996: loss did not improve\n",
      "Epoch 1997/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.8018e-05\n",
      "\n",
      "Epoch 01997: loss did not improve\n",
      "Epoch 1998/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 5.8815e-05\n",
      "\n",
      "Epoch 01998: loss did not improve\n",
      "Epoch 1999/2000\n",
      "2014/2014 [==============================] - 0s 30us/step - loss: 5.8907e-05\n",
      "\n",
      "Epoch 01999: loss did not improve\n",
      "Epoch 2000/2000\n",
      "2014/2014 [==============================] - 0s 31us/step - loss: 6.0176e-05\n",
      "\n",
      "Epoch 02000: loss did not improve\n"
     ]
    }
   ],
   "source": [
    "model3= Sequential()\n",
    "model3.add(LSTM(32,input_shape=(sequence,1)))\n",
    "model3.add(Dense(1))\n",
    "model3.add(Activation('linear'))\n",
    "model3.compile(optimizer = \"adam\", loss = 'mean_squared_error')\n",
    "\n",
    "checkpoint3 = ModelCheckpoint(\"Test32-B512-LB7-D10.hdf5\", monitor='loss', verbose=1, save_best_only=True)\n",
    "\n",
    "history3 = model3.fit(X_train3, y_train3, epochs=2000, batch_size=512,verbose=1, callbacks=[checkpoint3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: 17.39 RMSE\n",
      "Test Error: 20.74 RMSE\n",
      "----------------------------------------\n",
      "Train Accuracy: 82.61 RMSE\n",
      "Test Accuracy: 79.26 RMSE\n"
     ]
    }
   ],
   "source": [
    "trainPredict3 = model3.predict(X_train3)\n",
    "testPredict3 = model3.predict(X_test3)\n",
    "\n",
    "trainPredict3 = sc.inverse_transform(trainPredict3)\n",
    "trainY3 = sc.inverse_transform([y_train3])\n",
    "testPredict3 = sc.inverse_transform(testPredict3)\n",
    "testY3 = sc.inverse_transform([y_test3])\n",
    "\n",
    "trainError3 = math.sqrt(mean_squared_error(trainY3[0], trainPredict3[:,0]))\n",
    "testError3 = math.sqrt(mean_squared_error(testY3[0], testPredict3[:,0]))\n",
    "\n",
    "print('Train Error: %.2f RMSE' % (trainError3))\n",
    "print('Test Error: %.2f RMSE' % (testError3))\n",
    "print(\"----------------------------------------\")\n",
    "print('Train Accuracy: %.2f RMSE' % (100-trainError3))\n",
    "print('Test Accuracy: %.2f RMSE' % (100-testError3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testY3 = np.array(testY3).reshape(-1, 1)\n",
    "\n",
    "plt.plot(testPredict3, 'b', label = 'Predicted Price')\n",
    "plt.plot(testY3, 'r', label = 'Actual Price')\n",
    "plt.xlabel('Time in Days')\n",
    "plt.ylabel('Value of Stocks')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history3.history[\"loss\"])\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
