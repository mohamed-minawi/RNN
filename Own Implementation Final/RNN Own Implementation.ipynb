{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from rnn import Model\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importData(path):\n",
    "    data = []\n",
    "    with open(path, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if 'S&P 500' not in row:\n",
    "                data.append(float(row[1]))\n",
    "    return data\n",
    "\n",
    "def preprocessData(data):\n",
    "\n",
    "    train_size = int(len(data) * 0.8)\n",
    "    test_size = len(data) - train_size\n",
    "    train = data[0:train_size]\n",
    "    test = data[train_size:len(data)]  \n",
    "\n",
    "    X_train = [[x]for x in train[:-1]]\n",
    "    y_train = [[x]for x in train[1:]]\n",
    "\n",
    "    X_test = [[x] for x in test[:-1]]\n",
    "    y_test = [[x] for x in test[1:]]\n",
    "    \n",
    "    return np.array(X_train), np.array(y_train) , np.array(X_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dim = 3000\n",
    "hidden_dim = 200\n",
    "data = importData(\"data.csv\")\n",
    "\n",
    "X_train, y_train , X_test, y_test = preprocessData(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN = Model(max_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-12 02:10:47: Loss after num_examples_seen=0 epoch=0: 8.001470\n",
      "2018-05-12 02:10:50: Loss after num_examples_seen=114 epoch=1: 7.999701\n",
      "2018-05-12 02:10:53: Loss after num_examples_seen=228 epoch=2: 7.997931\n",
      "2018-05-12 02:10:56: Loss after num_examples_seen=342 epoch=3: 7.996160\n",
      "2018-05-12 02:11:00: Loss after num_examples_seen=456 epoch=4: 7.994387\n",
      "2018-05-12 02:11:03: Loss after num_examples_seen=570 epoch=5: 7.992612\n",
      "2018-05-12 02:11:06: Loss after num_examples_seen=684 epoch=6: 7.990834\n",
      "2018-05-12 02:11:08: Loss after num_examples_seen=798 epoch=7: 7.989054\n",
      "2018-05-12 02:11:11: Loss after num_examples_seen=912 epoch=8: 7.987270\n",
      "2018-05-12 02:11:14: Loss after num_examples_seen=1026 epoch=9: 7.985482\n",
      "2018-05-12 02:11:17: Loss after num_examples_seen=1140 epoch=10: 7.983691\n",
      "2018-05-12 02:11:21: Loss after num_examples_seen=1254 epoch=11: 7.981895\n",
      "2018-05-12 02:11:23: Loss after num_examples_seen=1368 epoch=12: 7.980094\n",
      "2018-05-12 02:11:26: Loss after num_examples_seen=1482 epoch=13: 7.978289\n",
      "2018-05-12 02:11:29: Loss after num_examples_seen=1596 epoch=14: 7.976478\n",
      "2018-05-12 02:11:32: Loss after num_examples_seen=1710 epoch=15: 7.974661\n",
      "2018-05-12 02:11:35: Loss after num_examples_seen=1824 epoch=16: 7.972838\n",
      "2018-05-12 02:11:38: Loss after num_examples_seen=1938 epoch=17: 7.971008\n",
      "2018-05-12 02:11:41: Loss after num_examples_seen=2052 epoch=18: 7.969172\n",
      "2018-05-12 02:11:44: Loss after num_examples_seen=2166 epoch=19: 7.967328\n",
      "2018-05-12 02:11:47: Loss after num_examples_seen=2280 epoch=20: 7.965477\n",
      "2018-05-12 02:11:50: Loss after num_examples_seen=2394 epoch=21: 7.963617\n",
      "2018-05-12 02:11:53: Loss after num_examples_seen=2508 epoch=22: 7.961749\n",
      "2018-05-12 02:11:56: Loss after num_examples_seen=2622 epoch=23: 7.959872\n",
      "2018-05-12 02:11:59: Loss after num_examples_seen=2736 epoch=24: 7.957986\n",
      "2018-05-12 02:12:02: Loss after num_examples_seen=2850 epoch=25: 7.956091\n",
      "2018-05-12 02:12:05: Loss after num_examples_seen=2964 epoch=26: 7.954185\n",
      "2018-05-12 02:12:08: Loss after num_examples_seen=3078 epoch=27: 7.952270\n",
      "2018-05-12 02:12:11: Loss after num_examples_seen=3192 epoch=28: 7.950343\n",
      "2018-05-12 02:12:14: Loss after num_examples_seen=3306 epoch=29: 7.948405\n",
      "2018-05-12 02:12:17: Loss after num_examples_seen=3420 epoch=30: 7.946456\n",
      "2018-05-12 02:12:20: Loss after num_examples_seen=3534 epoch=31: 7.944494\n",
      "2018-05-12 02:12:23: Loss after num_examples_seen=3648 epoch=32: 7.942521\n",
      "2018-05-12 02:12:26: Loss after num_examples_seen=3762 epoch=33: 7.940534\n",
      "2018-05-12 02:12:29: Loss after num_examples_seen=3876 epoch=34: 7.938534\n",
      "2018-05-12 02:12:33: Loss after num_examples_seen=3990 epoch=35: 7.936521\n",
      "2018-05-12 02:12:36: Loss after num_examples_seen=4104 epoch=36: 7.934494\n",
      "2018-05-12 02:12:38: Loss after num_examples_seen=4218 epoch=37: 7.932452\n",
      "2018-05-12 02:12:41: Loss after num_examples_seen=4332 epoch=38: 7.930395\n",
      "2018-05-12 02:12:44: Loss after num_examples_seen=4446 epoch=39: 7.928323\n",
      "2018-05-12 02:12:47: Loss after num_examples_seen=4560 epoch=40: 7.926235\n",
      "2018-05-12 02:12:50: Loss after num_examples_seen=4674 epoch=41: 7.924131\n",
      "2018-05-12 02:12:53: Loss after num_examples_seen=4788 epoch=42: 7.922010\n",
      "2018-05-12 02:12:56: Loss after num_examples_seen=4902 epoch=43: 7.919872\n",
      "2018-05-12 02:13:00: Loss after num_examples_seen=5016 epoch=44: 7.917716\n",
      "2018-05-12 02:13:03: Loss after num_examples_seen=5130 epoch=45: 7.915543\n",
      "2018-05-12 02:13:06: Loss after num_examples_seen=5244 epoch=46: 7.913351\n",
      "2018-05-12 02:13:09: Loss after num_examples_seen=5358 epoch=47: 7.911139\n",
      "2018-05-12 02:13:12: Loss after num_examples_seen=5472 epoch=48: 7.908909\n",
      "2018-05-12 02:13:15: Loss after num_examples_seen=5586 epoch=49: 7.906658\n",
      "2018-05-12 02:13:18: Loss after num_examples_seen=5700 epoch=50: 7.904387\n",
      "2018-05-12 02:13:21: Loss after num_examples_seen=5814 epoch=51: 7.902095\n",
      "2018-05-12 02:13:23: Loss after num_examples_seen=5928 epoch=52: 7.899781\n",
      "2018-05-12 02:13:26: Loss after num_examples_seen=6042 epoch=53: 7.897446\n",
      "2018-05-12 02:13:29: Loss after num_examples_seen=6156 epoch=54: 7.895088\n",
      "2018-05-12 02:13:33: Loss after num_examples_seen=6270 epoch=55: 7.892707\n",
      "2018-05-12 02:13:36: Loss after num_examples_seen=6384 epoch=56: 7.890302\n",
      "2018-05-12 02:13:39: Loss after num_examples_seen=6498 epoch=57: 7.887874\n",
      "2018-05-12 02:13:42: Loss after num_examples_seen=6612 epoch=58: 7.885421\n",
      "2018-05-12 02:13:45: Loss after num_examples_seen=6726 epoch=59: 7.882942\n",
      "2018-05-12 02:13:48: Loss after num_examples_seen=6840 epoch=60: 7.880438\n",
      "2018-05-12 02:13:51: Loss after num_examples_seen=6954 epoch=61: 7.877908\n",
      "2018-05-12 02:13:54: Loss after num_examples_seen=7068 epoch=62: 7.875351\n",
      "2018-05-12 02:13:57: Loss after num_examples_seen=7182 epoch=63: 7.872766\n",
      "2018-05-12 02:14:00: Loss after num_examples_seen=7296 epoch=64: 7.870153\n",
      "2018-05-12 02:14:03: Loss after num_examples_seen=7410 epoch=65: 7.867512\n",
      "2018-05-12 02:14:06: Loss after num_examples_seen=7524 epoch=66: 7.864842\n",
      "2018-05-12 02:14:09: Loss after num_examples_seen=7638 epoch=67: 7.862141\n",
      "2018-05-12 02:14:11: Loss after num_examples_seen=7752 epoch=68: 7.859410\n",
      "2018-05-12 02:14:14: Loss after num_examples_seen=7866 epoch=69: 7.856648\n",
      "2018-05-12 02:14:17: Loss after num_examples_seen=7980 epoch=70: 7.853855\n",
      "2018-05-12 02:14:20: Loss after num_examples_seen=8094 epoch=71: 7.851029\n",
      "2018-05-12 02:14:23: Loss after num_examples_seen=8208 epoch=72: 7.848170\n",
      "2018-05-12 02:14:26: Loss after num_examples_seen=8322 epoch=73: 7.845277\n",
      "2018-05-12 02:14:29: Loss after num_examples_seen=8436 epoch=74: 7.842350\n",
      "2018-05-12 02:14:32: Loss after num_examples_seen=8550 epoch=75: 7.839388\n",
      "2018-05-12 02:14:35: Loss after num_examples_seen=8664 epoch=76: 7.836390\n",
      "2018-05-12 02:14:38: Loss after num_examples_seen=8778 epoch=77: 7.833356\n",
      "2018-05-12 02:14:41: Loss after num_examples_seen=8892 epoch=78: 7.830284\n",
      "2018-05-12 02:14:44: Loss after num_examples_seen=9006 epoch=79: 7.827175\n",
      "2018-05-12 02:14:47: Loss after num_examples_seen=9120 epoch=80: 7.824026\n",
      "2018-05-12 02:14:50: Loss after num_examples_seen=9234 epoch=81: 7.820839\n",
      "2018-05-12 02:14:53: Loss after num_examples_seen=9348 epoch=82: 7.817611\n",
      "2018-05-12 02:14:56: Loss after num_examples_seen=9462 epoch=83: 7.814343\n",
      "2018-05-12 02:14:59: Loss after num_examples_seen=9576 epoch=84: 7.811032\n",
      "2018-05-12 02:15:02: Loss after num_examples_seen=9690 epoch=85: 7.807679\n",
      "2018-05-12 02:15:05: Loss after num_examples_seen=9804 epoch=86: 7.804283\n",
      "2018-05-12 02:15:08: Loss after num_examples_seen=9918 epoch=87: 7.800842\n",
      "2018-05-12 02:15:11: Loss after num_examples_seen=10032 epoch=88: 7.797357\n",
      "2018-05-12 02:15:14: Loss after num_examples_seen=10146 epoch=89: 7.793826\n",
      "2018-05-12 02:15:17: Loss after num_examples_seen=10260 epoch=90: 7.790247\n",
      "2018-05-12 02:15:20: Loss after num_examples_seen=10374 epoch=91: 7.786622\n",
      "2018-05-12 02:15:23: Loss after num_examples_seen=10488 epoch=92: 7.782948\n",
      "2018-05-12 02:15:26: Loss after num_examples_seen=10602 epoch=93: 7.779224\n",
      "2018-05-12 02:15:29: Loss after num_examples_seen=10716 epoch=94: 7.775450\n",
      "2018-05-12 02:15:32: Loss after num_examples_seen=10830 epoch=95: 7.771625\n",
      "2018-05-12 02:15:35: Loss after num_examples_seen=10944 epoch=96: 7.767747\n",
      "2018-05-12 02:15:38: Loss after num_examples_seen=11058 epoch=97: 7.763817\n",
      "2018-05-12 02:15:42: Loss after num_examples_seen=11172 epoch=98: 7.759832\n",
      "2018-05-12 02:15:45: Loss after num_examples_seen=11286 epoch=99: 7.755792\n",
      "2018-05-12 02:15:48: Loss after num_examples_seen=11400 epoch=100: 7.751695\n",
      "2018-05-12 02:15:51: Loss after num_examples_seen=11514 epoch=101: 7.747542\n",
      "2018-05-12 02:15:54: Loss after num_examples_seen=11628 epoch=102: 7.743330\n",
      "2018-05-12 02:15:57: Loss after num_examples_seen=11742 epoch=103: 7.739059\n",
      "2018-05-12 02:16:00: Loss after num_examples_seen=11856 epoch=104: 7.734727\n",
      "2018-05-12 02:16:03: Loss after num_examples_seen=11970 epoch=105: 7.730334\n",
      "2018-05-12 02:16:06: Loss after num_examples_seen=12084 epoch=106: 7.725879\n",
      "2018-05-12 02:16:09: Loss after num_examples_seen=12198 epoch=107: 7.721359\n",
      "2018-05-12 02:16:12: Loss after num_examples_seen=12312 epoch=108: 7.716774\n",
      "2018-05-12 02:16:15: Loss after num_examples_seen=12426 epoch=109: 7.712124\n",
      "2018-05-12 02:16:18: Loss after num_examples_seen=12540 epoch=110: 7.707405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-12 02:16:22: Loss after num_examples_seen=12654 epoch=111: 7.702619\n",
      "2018-05-12 02:16:25: Loss after num_examples_seen=12768 epoch=112: 7.697762\n",
      "2018-05-12 02:16:28: Loss after num_examples_seen=12882 epoch=113: 7.692835\n",
      "2018-05-12 02:16:31: Loss after num_examples_seen=12996 epoch=114: 7.687835\n",
      "2018-05-12 02:16:34: Loss after num_examples_seen=13110 epoch=115: 7.682761\n",
      "2018-05-12 02:16:37: Loss after num_examples_seen=13224 epoch=116: 7.677612\n",
      "2018-05-12 02:16:40: Loss after num_examples_seen=13338 epoch=117: 7.672387\n",
      "2018-05-12 02:16:43: Loss after num_examples_seen=13452 epoch=118: 7.667085\n",
      "2018-05-12 02:16:46: Loss after num_examples_seen=13566 epoch=119: 7.661703\n",
      "2018-05-12 02:16:49: Loss after num_examples_seen=13680 epoch=120: 7.656241\n",
      "2018-05-12 02:16:52: Loss after num_examples_seen=13794 epoch=121: 7.650696\n",
      "2018-05-12 02:16:56: Loss after num_examples_seen=13908 epoch=122: 7.645068\n",
      "2018-05-12 02:16:59: Loss after num_examples_seen=14022 epoch=123: 7.639356\n",
      "2018-05-12 02:17:02: Loss after num_examples_seen=14136 epoch=124: 7.633557\n",
      "2018-05-12 02:17:05: Loss after num_examples_seen=14250 epoch=125: 7.627669\n",
      "2018-05-12 02:17:08: Loss after num_examples_seen=14364 epoch=126: 7.621693\n",
      "2018-05-12 02:17:11: Loss after num_examples_seen=14478 epoch=127: 7.615625\n",
      "2018-05-12 02:17:15: Loss after num_examples_seen=14592 epoch=128: 7.609464\n",
      "2018-05-12 02:17:18: Loss after num_examples_seen=14706 epoch=129: 7.603209\n",
      "2018-05-12 02:17:21: Loss after num_examples_seen=14820 epoch=130: 7.596858\n",
      "2018-05-12 02:17:24: Loss after num_examples_seen=14934 epoch=131: 7.590409\n",
      "2018-05-12 02:17:27: Loss after num_examples_seen=15048 epoch=132: 7.583860\n",
      "2018-05-12 02:17:30: Loss after num_examples_seen=15162 epoch=133: 7.577210\n",
      "2018-05-12 02:17:33: Loss after num_examples_seen=15276 epoch=134: 7.570457\n",
      "2018-05-12 02:17:36: Loss after num_examples_seen=15390 epoch=135: 7.563599\n",
      "2018-05-12 02:17:40: Loss after num_examples_seen=15504 epoch=136: 7.556634\n",
      "2018-05-12 02:17:42: Loss after num_examples_seen=15618 epoch=137: 7.549561\n",
      "2018-05-12 02:17:46: Loss after num_examples_seen=15732 epoch=138: 7.542376\n",
      "2018-05-12 02:17:49: Loss after num_examples_seen=15846 epoch=139: 7.535080\n",
      "2018-05-12 02:17:52: Loss after num_examples_seen=15960 epoch=140: 7.527669\n",
      "2018-05-12 02:17:55: Loss after num_examples_seen=16074 epoch=141: 7.520141\n",
      "2018-05-12 02:17:58: Loss after num_examples_seen=16188 epoch=142: 7.512495\n",
      "2018-05-12 02:18:01: Loss after num_examples_seen=16302 epoch=143: 7.504728\n",
      "2018-05-12 02:18:05: Loss after num_examples_seen=16416 epoch=144: 7.496838\n",
      "2018-05-12 02:18:08: Loss after num_examples_seen=16530 epoch=145: 7.488823\n",
      "2018-05-12 02:18:11: Loss after num_examples_seen=16644 epoch=146: 7.480682\n",
      "2018-05-12 02:18:14: Loss after num_examples_seen=16758 epoch=147: 7.472411\n",
      "2018-05-12 02:18:17: Loss after num_examples_seen=16872 epoch=148: 7.464008\n",
      "2018-05-12 02:18:20: Loss after num_examples_seen=16986 epoch=149: 7.455472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 8.001469699275807),\n",
       " (114, 7.999701126733744),\n",
       " (228, 7.997931436822509),\n",
       " (342, 7.996160273349397),\n",
       " (456, 7.994387279753587),\n",
       " (570, 7.992612099005507),\n",
       " (684, 7.9908343735060345),\n",
       " (798, 7.98905374498553),\n",
       " (912, 7.9872698544026175),\n",
       " (1026, 7.985482341842751),\n",
       " (1140, 7.9836908464164855),\n",
       " (1254, 7.981895006157401),\n",
       " (1368, 7.980094457919686),\n",
       " (1482, 7.978288837275351),\n",
       " (1596, 7.976477778410959),\n",
       " (1710, 7.974660914023911),\n",
       " (1824, 7.972837875218264),\n",
       " (1938, 7.971008291399972),\n",
       " (2052, 7.96917179017154),\n",
       " (2166, 7.967327997226122),\n",
       " (2280, 7.965476536240904),\n",
       " (2394, 7.963617028769861),\n",
       " (2508, 7.961749094135747),\n",
       " (2622, 7.959872349321376),\n",
       " (2736, 7.957986408860014),\n",
       " (2850, 7.956090884725068),\n",
       " (2964, 7.954185386218762),\n",
       " (3078, 7.952269519860017),\n",
       " (3192, 7.95034288927132),\n",
       " (3306, 7.948405095064595),\n",
       " (3420, 7.9464557347260945),\n",
       " (3534, 7.94449440250018),\n",
       " (3648, 7.942520689272023),\n",
       " (3762, 7.940534182449136),\n",
       " (3876, 7.938534465841724),\n",
       " (3990, 7.936521119541809),\n",
       " (4104, 7.934493719801083),\n",
       " (4218, 7.932451838907466),\n",
       " (4332, 7.9303950450602585),\n",
       " (4446, 7.928322902243965),\n",
       " (4560, 7.926234970100639),\n",
       " (4674, 7.924130803800729),\n",
       " (4788, 7.922009953912463),\n",
       " (4902, 7.9198719662696),\n",
       " (5016, 7.917716381837593),\n",
       " (5130, 7.915542736578085),\n",
       " (5244, 7.913350561311761),\n",
       " (5358, 7.911139381579327),\n",
       " (5472, 7.90890871750081),\n",
       " (5586, 7.906658083632961),\n",
       " (5700, 7.9043869888247995),\n",
       " (5814, 7.902094936071161),\n",
       " (5928, 7.899781422364344),\n",
       " (6042, 7.897445938543665),\n",
       " (6156, 7.895087969142952),\n",
       " (6270, 7.892706992235901),\n",
       " (6384, 7.890302479279255),\n",
       " (6498, 7.887873894953781),\n",
       " (6612, 7.885420697002897),\n",
       " (6726, 7.882942336069035),\n",
       " (6840, 7.880438255527575),\n",
       " (6954, 7.87790789131837),\n",
       " (7068, 7.875350671774778),\n",
       " (7182, 7.872766017450104),\n",
       " (7296, 7.870153340941542),\n",
       " (7410, 7.867512046711365),\n",
       " (7524, 7.864841530905478),\n",
       " (7638, 7.862141181169179),\n",
       " (7752, 7.859410376460128),\n",
       " (7866, 7.856648486858424),\n",
       " (7980, 7.853854873373753),\n",
       " (8094, 7.851028887749592),\n",
       " (8208, 7.848169872264317),\n",
       " (8322, 7.845277159529266),\n",
       " (8436, 7.842350072283605),\n",
       " (8550, 7.839387923186025),\n",
       " (8664, 7.8363900146031105),\n",
       " (8778, 7.833355638394459),\n",
       " (8892, 7.830284075694336),\n",
       " (9006, 7.827174596689934),\n",
       " (9120, 7.824026460396124),\n",
       " (9234, 7.820838914426613),\n",
       " (9348, 7.817611194761537),\n",
       " (9462, 7.814342525511326),\n",
       " (9576, 7.811032118676838),\n",
       " (9690, 7.8076791739057585),\n",
       " (9804, 7.80428287824506),\n",
       " (9918, 7.800842405889612),\n",
       " (10032, 7.797356917926816),\n",
       " (10146, 7.793825562077204),\n",
       " (10260, 7.79024747243098),\n",
       " (10374, 7.786621769180409),\n",
       " (10488, 7.782947558348049),\n",
       " (10602, 7.779223931510695),\n",
       " (10716, 7.775449965519113),\n",
       " (10830, 7.771624722213361),\n",
       " (10944, 7.767747248133784),\n",
       " (11058, 7.7638165742274925),\n",
       " (11172, 7.759831715550498),\n",
       " (11286, 7.755791670965167),\n",
       " (11400, 7.751695422833274),\n",
       " (11514, 7.747541936704341),\n",
       " (11628, 7.743330160999386),\n",
       " (11742, 7.739059026690077),\n",
       " (11856, 7.7347274469730625),\n",
       " (11970, 7.730334316939755),\n",
       " (12084, 7.725878513241266),\n",
       " (12198, 7.721358893748649),\n",
       " (12312, 7.716774297208435),\n",
       " (12426, 7.712123542893354),\n",
       " (12540, 7.707405430248379),\n",
       " (12654, 7.702618738532024),\n",
       " (12768, 7.697762226452935),\n",
       " (12882, 7.6928346318018495),\n",
       " (12996, 7.687834671078884),\n",
       " (13110, 7.682761039116259),\n",
       " (13224, 7.677612408696602),\n",
       " (13338, 7.672387430166677),\n",
       " (13452, 7.6670847310469235),\n",
       " (13566, 7.661702915636675),\n",
       " (13680, 7.656240564615363),\n",
       " (13794, 7.650696234639734),\n",
       " (13908, 7.645068457937339),\n",
       " (14022, 7.639355741896409),\n",
       " (14136, 7.63355656865242),\n",
       " (14250, 7.627669394671591),\n",
       " (14364, 7.621692650331518),\n",
       " (14478, 7.6156247394994026),\n",
       " (14592, 7.609464039108156),\n",
       " (14706, 7.603208898730813),\n",
       " (14820, 7.596857640153717),\n",
       " (14934, 7.590408556949043),\n",
       " (15048, 7.583859914047166),\n",
       " (15162, 7.57720994730966),\n",
       " (15276, 7.570456863103483),\n",
       " (15390, 7.5635988378773815),\n",
       " (15504, 7.556634017741275),\n",
       " (15618, 7.549560518049807),\n",
       " (15732, 7.542376422991058),\n",
       " (15846, 7.535079785181922),\n",
       " (15960, 7.527668625271449),\n",
       " (16074, 7.5201409315538985),\n",
       " (16188, 7.512494659593308),\n",
       " (16302, 7.504727731861673),\n",
       " (16416, 7.4968380373930295),\n",
       " (16530, 7.488823431456123),\n",
       " (16644, 7.480681735248546),\n",
       " (16758, 7.472410735615728),\n",
       " (16872, 7.464008184798428),\n",
       " (16986, 7.455471800213082)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN.train(X_train[1900:], y_train[1900:], learning_rate=0.005, nepoch=150, evaluate_loss_after=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testPredict = RNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: 1252.94 RMSE\n",
      "----------------------------------------\n",
      "Test Accuracy: -1152.94 RMSE\n"
     ]
    }
   ],
   "source": [
    "testError = math.sqrt(mean_squared_error(y_test, testPredict))\n",
    "\n",
    "print('Test Error: %.2f RMSE' % (testError))\n",
    "print(\"----------------------------------------\")\n",
    "print('Test Accuracy: %.2f RMSE' % (100-testError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[489, 1433, 2298, 2606, 744] [[2639.4 ]\n",
      " [2666.94]\n",
      " [2669.91]\n",
      " [2648.05]\n",
      " [2654.8 ]]\n"
     ]
    }
   ],
   "source": [
    "print(testPredict[-5:], y_test[-5:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
